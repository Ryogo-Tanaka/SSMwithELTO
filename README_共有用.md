# Deep Fictitious Instrumental Variables (DFIV) - ã‚³ãƒ¼ãƒ‰å®Ÿè£…ã‚¬ã‚¤ãƒ‰

Deep Fictitious Instrumental Variables (DFIV) ã‚’ç”¨ã„ãŸçŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

---

## ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```
SSMwithELTO/
â”œâ”€â”€ configs/                          # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â”œâ”€â”€ quad_image_reconstruction_config.yaml     # ç”»åƒå†æ§‹æˆç”¨è¨­å®š
â”‚   â””â”€â”€ quad_target_prediction_config.yaml        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆäºˆæ¸¬ç”¨è¨­å®š
â”‚
â”œâ”€â”€ src/                              # ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰
â”‚   â”œâ”€â”€ models/                       # ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
â”‚   â”‚   â”œâ”€â”€ encoder.py               # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€Factory
â”‚   â”‚   â”œâ”€â”€ decoder.py               # ãƒ‡ã‚³ãƒ¼ãƒ€Factory
â”‚   â”‚   â”œâ”€â”€ inference_model.py       # æ¨è«–ãƒ¢ãƒ‡ãƒ«
â”‚   â”‚   â””â”€â”€ architectures/
â”‚   â”‚       â””â”€â”€ rkn.py               # RKN CNN Encoder/Decoder
â”‚   â”‚
â”‚   â”œâ”€â”€ ssm/                         # çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ã‚³ã‚¢
â”‚   â”‚   â”œâ”€â”€ realization.py           # ç¢ºç‡çš„å®Ÿç¾ï¼ˆçŠ¶æ…‹æ¨å®šï¼‰
â”‚   â”‚   â”œâ”€â”€ cross_fitting.py         # ã‚¯ãƒ­ã‚¹ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ df_state_layer.py        # DF-Aï¼ˆçŠ¶æ…‹å±¤ï¼‰
â”‚   â”‚   â”œâ”€â”€ df_observation_layer.py  # DF-Bï¼ˆè¦³æ¸¬å±¤ï¼‰
â”‚   â”‚   â””â”€â”€ observation.py           # CMEè¦³æ¸¬ãƒ¢ãƒ‡ãƒ«
â”‚   â”‚
â”‚   â”œâ”€â”€ training/                    # å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
â”‚   â”‚   â””â”€â”€ two_stage_trainer.py     # 2æ®µéšå­¦ç¿’ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼
â”‚   â”‚
â”‚   â”œâ”€â”€ inference/                   # æ¨è«–ãƒ»Kalmanï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
â”‚   â”‚   â”œâ”€â”€ kalman_filter.py         # Kalmanãƒ•ã‚£ãƒ«ã‚¿
â”‚   â”‚   â”œâ”€â”€ noise_covariance.py      # ãƒã‚¤ã‚ºå…±åˆ†æ•£æ¨å®š
â”‚   â”‚   â””â”€â”€ state_estimator.py       # çŠ¶æ…‹æ¨å®šå™¨
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/                  # è©•ä¾¡ãƒ»åˆ†æ
â”‚   â”‚   â”œâ”€â”€ metrics.py               # è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
â”‚   â”‚   â””â”€â”€ mode_decomposition.py    # ãƒ¢ãƒ¼ãƒ‰åˆ†è§£åˆ†æ
â”‚   â”‚
â”‚   â””â”€â”€ utils/                       # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
â”‚       â”œâ”€â”€ data_loader.py           # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
â”‚       â””â”€â”€ gpu_utils.py             # GPUé¸æŠ
â”‚
â””â”€â”€ data/                            # ãƒ‡ãƒ¼ã‚¿æ ¼ç´ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    â””â”€â”€ your_dataset/
        â””â”€â”€ your_data.npz            # .npzå½¢å¼ã§é…ç½®
```

---

## ğŸ“Š ãƒ‡ãƒ¼ã‚¿é…ç½®ãƒ»å½¢å¼

### ãƒ‡ãƒ¼ã‚¿é…ç½®
```
data/
â””â”€â”€ your_dataset/         # ä»»æ„ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå
    â””â”€â”€ your_data.npz     # NumPyåœ§ç¸®å½¢å¼
```

### ãƒ‡ãƒ¼ã‚¿å½¢å¼ï¼ˆ.npzãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ï¼‰

#### **å†æ§‹æˆãƒ¢ãƒ¼ãƒ‰**
```python
# å¿…é ˆã‚­ãƒ¼: 'y'
np.savez(
    'data/your_dataset/your_data.npz',
    y=observation_data  # shape: (N, D)
)

# N: ã‚µãƒ³ãƒ—ãƒ«æ•°
# D: è¦³æ¸¬æ¬¡å…ƒæ•°ï¼ˆç”»åƒãªã‚‰flattenå¾Œã®æ¬¡å…ƒï¼‰
```

**ç”»åƒãƒ‡ãƒ¼ã‚¿ã®ä¾‹**:
```python
# å…ƒãƒ‡ãƒ¼ã‚¿: (1500, 48, 48, 1) - 1500æšã®48x48ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒ
# ä¿å­˜å½¢å¼: (1500, 2304) - flattenã—ã¦ä¿å­˜
# ã¾ãŸã¯ (1500, 48, 48, 1) - 4æ¬¡å…ƒã®ã¾ã¾ä¿å­˜ï¼ˆè‡ªå‹•ã§flattenï¼‰

import numpy as np
images = np.random.rand(1500, 48, 48, 1)  # ä¾‹: ãƒ©ãƒ³ãƒ€ãƒ ç”»åƒ
np.savez('data/your_dataset/images.npz', y=images)
```

**æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®ä¾‹**:
```python
# å…ƒãƒ‡ãƒ¼ã‚¿: (1000, 10) - 1000æ™‚ç‚¹ã®10æ¬¡å…ƒæ™‚ç³»åˆ—
timeseries = np.random.rand(1000, 10)
np.savez('data/your_dataset/timeseries.npz', y=timeseries)
```

#### **ã‚¿ãƒ¼ã‚²ãƒƒãƒˆäºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰**
```python
# å¿…é ˆã‚­ãƒ¼: 'y', 'target'
np.savez(
    'data/your_dataset/your_data.npz',
    y=observation_data,  # shape: (N, D)
    target=target_data   # shape: (N, T)
)

# T: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ¬¡å…ƒæ•°
```

**ä¾‹: ç”»åƒã‹ã‚‰ã®çŠ¶æ…‹äºˆæ¸¬**:
```python
images = np.random.rand(1500, 48, 48, 1)     # è¦³æ¸¬ç”»åƒ
states = np.random.rand(1500, 8)             # åˆ¶å¾¡çŠ¶æ…‹ï¼ˆ8æ¬¡å…ƒï¼‰
np.savez('data/your_dataset/control.npz', y=images, target=states)
```

### ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿è‡ªå‹•å‡¦ç†
```python
# src/utils/data_loader.pyãŒè‡ªå‹•å®Ÿè¡Œ
data_dict = load_experimental_data_with_architecture(
    data_path="data/your_dataset/your_data.npz",
    config=config
)

# å‡ºåŠ›å½¢å¼:
# {
#   'train': torch.Tensor (N_train, D),
#   'val': torch.Tensor (N_val, D),
#   'test': torch.Tensor (N_test, D),
#   'metadata': DataMetadata,
#   'targets': {  # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆäºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰æ™‚ã®ã¿
#       'train': torch.Tensor (N_train, T),
#       'val': torch.Tensor (N_val, T),
#       'test': torch.Tensor (N_test, T)
#   }
# }
```

**è‡ªå‹•å‡¦ç†å†…å®¹**:
1. `.npz`èª­ã¿è¾¼ã¿
2. 4æ¬¡å…ƒç”»åƒãƒ‡ãƒ¼ã‚¿ã¯è‡ªå‹•flatten: (N, H, W, C) â†’ (N, H*W*C)
3. train/val/teståˆ†å‰²ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®æ¯”ç‡ã«å¾“ã†ï¼‰
4. PyTorch Tensorå¤‰æ›

---

## ğŸ”„ å­¦ç¿’ãƒ•ãƒ­ãƒ¼

### å…¨ä½“ãƒ•ãƒ­ãƒ¼
```
ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ â†’ ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼åˆæœŸåŒ– â†’ çµ±åˆå­¦ç¿’ â†’ è©•ä¾¡
```

### Phase-1: DFå±¤å­¦ç¿’ï¼ˆå„ã‚¨ãƒãƒƒã‚¯ï¼‰

#### **ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿æº–å‚™**
```
_prepare_data(Y_train)
  â†“
1. ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
   encoder: (N, D_obs) â†’ (N, d_m)
   ä¾‹: (1050, 2304) â†’ (1050, 50)

2. çŠ¶æ…‹æ¨å®š
   realization.estimate_states(): (N, d_m) â†’ (N-h, r)
   ä¾‹: (1050, 50) â†’ (1030, 30)
   â€» h=éå»çª“é•·, r=çŠ¶æ…‹æ¬¡å…ƒ
```

**ä½¿ç”¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«**:
- `src/models/encoder.py`: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€Factory
- `src/models/architectures/rkn.py`: RKN CNNå®Ÿè£…
- `src/ssm/realization.py`: ç¢ºç‡çš„å®Ÿç¾

**ç¢ºç‡çš„å®Ÿç¾ã®è©³ç´°**:
```python
# src/ssm/realization.py::StochasticRealizationWithEncoder
fit(Y, encoder)
  â†“ M = encoder(Y): (N, D_obs) â†’ (N, d_m)
  â†“ ãƒ©ã‚°å…±åˆ†æ•£æ¨å®š: Cov(M_t, M_{t-Ï„})
  â†“ ç‰¹å¾´å†™åƒ: averaging/linear/mlp
  â†“ SVDåˆ†è§£: A, Cè¡Œåˆ—å–å¾—

estimate_states(Y)
  â†“ M = encoder(Y)
  â†“ éå»çª“ã§Hankelè¡Œåˆ—æ§‹æˆ: (N, h*d_m)
  â†“ X = hankel @ realization_matrix
  â†“ å‡ºåŠ›: (N-h, r)
```

#### **ã‚¹ãƒ†ãƒƒãƒ—2: DF-Aå­¦ç¿’ï¼ˆçŠ¶æ…‹å±¤ï¼‰**
```
_train_df_a_epoch(X_states)
  â†“
for iter in T1_iterations:
    # Stage-1: V_Aæ¨å®š + Ï†_Î¸æ›´æ–°
    Î¦ = Ï†_Î¸(X): (N, r) â†’ (N, d_A)
    V_A^{(-k)} = Ridge(Î¦_{-k}^+, Î¦_{-k}^-)  # Kå€‹æ¨å®š
    loss = ||Î¦^+ - V_A^{(-k)} Î¦^-||Â² + Î»_A ||V_A||Â²
    Ï†_Î¸å‹¾é…æ›´æ–°

for iter in T2_iterations:
    # Stage-2: U_Aæ¨å®š + Ï†_Î¸æ›´æ–°
    åŒæ§˜ã®å‡¦ç†
```

**ä½¿ç”¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«**:
- `src/ssm/df_state_layer.py`: DF-Aå®Ÿè£…
- `src/ssm/cross_fitting.py`: ã‚¯ãƒ­ã‚¹ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°

**ã‚¯ãƒ­ã‚¹ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã®è©³ç´°**:
```python
# src/ssm/cross_fitting.py
CrossFittingManager.create_blocks(data, n_blocks=5)
  â†“ æ™‚ç³»åˆ—ã‚’5å€‹ã®é€£ç¶šãƒ–ãƒ­ãƒƒã‚¯ã«åˆ†å‰²

TwoStageCrossFitter.cross_fit_stage1(phi_minus, phi_plus)
  â†“ for k in range(K):
      è¨“ç·´: blocks[â‰ k] ã§V_kæ¨å®š
      äºˆæ¸¬: block[k] ã§H_cf_k = V_k @ Î¦_k^-
  â†“ å‡ºåŠ›: V_A_list=[V_1,...,V_K], H_cf
```

#### **ã‚¹ãƒ†ãƒƒãƒ—3: DF-Bå­¦ç¿’ï¼ˆè¦³æ¸¬å±¤ï¼‰**
```
_train_df_b_epoch(X_states, M_features)
  â†“
for iter in T1_iterations:
    # Stage-1: V_Bæ¨å®š + Ï†_Î¸æ›´æ–°
    Î¨ = Ïˆ_Ï‰(M): (N, d_m) â†’ (N, d_B)
    V_B^{(-k)} = Ridge(Î¨_{-k}^+, Î¨_{-k}^-)
    loss = ||Î¨^+ - V_B^{(-k)} Î¨^-||Â² + Î»_B ||V_B||Â²
    Ï†_Î¸å‹¾é…æ›´æ–°

for iter in T2_iterations:
    # Stage-2: U_Bæ¨å®š + Ïˆ_Ï‰æ›´æ–°
    åŒæ§˜ã®å‡¦ç†ï¼ˆÏˆ_Ï‰æ›´æ–°ï¼‰
```

**ä½¿ç”¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«**:
- `src/ssm/df_observation_layer.py`: DF-Bå®Ÿè£…

---

### Phase-2: End-to-endå­¦ç¿’ï¼ˆwarmupå¾Œï¼‰

```
_train_integrated_phase2_epoch(Y_train)
  â†“
1. æ¨è«–ãƒ‘ã‚¹
   M = encoder(Y): (N, D_obs) â†’ (N, d_m)
   X_hat = realization.estimate_states(M): (N, d_m) â†’ (N-h, r)
   X_hat_pred = U_A^T V_A Ï†_Î¸(X_hat): (N-h, r) â†’ (N-h-1, r)
   M_hat = U_B^T V_B Ïˆ_Ï‰(X_hat_pred): (N-h-1, r) â†’ (N-h-1, d_m)
   Y_hat = decoder(M_hat): (N-h-1, d_m) â†’ (N-h-1, D_obs)

2. æå¤±è¨ˆç®—
   L_rec = ||Y[h:] - Y_hat||Â²
   L_cca = -Î£_i Ï_i  # æ­£æº–ç›¸é–¢ä¿‚æ•°
   L_total = L_rec + Î»_cca * L_cca

3. å‹¾é…æ›´æ–°
   encoder, decoderã®ã¿æ›´æ–°
   DFå±¤ï¼ˆV_A, U_A, V_B, U_Bï¼‰ã¯å›ºå®š
```

**ä½¿ç”¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«**:
- `src/models/decoder.py`: ãƒ‡ã‚³ãƒ¼ãƒ€Factory
- `src/loss.py`: CCAæå¤±

---

## âš™ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«

### åŸºæœ¬æ§‹é€ 
```yaml
experiment:
  mode: "reconstruction"  # ã¾ãŸã¯ "target_prediction"

data:
  train_ratio: 0.7        # å­¦ç¿’:æ¤œè¨¼:ãƒ†ã‚¹ãƒˆ = 7:2:1
  val_ratio: 0.2
  test_ratio: 0.1
  image_shape: [48, 48, 1]  # ç”»åƒã®å ´åˆã®ã¿

model:
  encoder:
    type: "rkn"           # rknEncoderä½¿ç”¨
    feature_dim: 50       # d_m: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å‡ºåŠ›æ¬¡å…ƒ
    conv_channels: [32, 64]

  decoder:
    type: "rkn"           # rknDecoderä½¿ç”¨
    feature_dim: 50       # d_m: ãƒ‡ã‚³ãƒ¼ãƒ€å…¥åŠ›æ¬¡å…ƒ
    conv_channels: [64, 32, 1]

training:
  epochs: 10
  T1_iterations: 5        # DF Stage-1åå¾©æ•°
  T2_iterations: 5        # DF Stage-2åå¾©æ•°
  phase1_warmup_epochs: 5 # Phase-2é–‹å§‹ã‚¨ãƒãƒƒã‚¯

  lr_phi: 1e-3            # Ï†_Î¸å­¦ç¿’ç‡
  lr_psi: 1e-3            # Ïˆ_Ï‰å­¦ç¿’ç‡
  lr_encoder: 1e-3        # encoderå­¦ç¿’ç‡
  lr_decoder: 1e-3        # decoderå­¦ç¿’ç‡

ssm:
  realization:
    past_horizon: 20      # h: éå»çª“é•·
    rank: 30              # r: çŠ¶æ…‹æ¬¡å…ƒæ•°
    encoder_output_dim: 50  # d_mï¼ˆmodel.encoder.feature_dimã¨ä¸€è‡´ï¼‰
    feature_mapping:
      type: "mlp"         # averaging/linear/mlp
      hidden_dims: [32]

  df_state:
    feature_dim: 50       # d_A: çŠ¶æ…‹ç‰¹å¾´æ¬¡å…ƒ
    lambda_A: 1e-3        # V_Aæ­£å‰‡åŒ–
    lambda_B: 1e-3        # U_Aæ­£å‰‡åŒ–
    cross_fitting:
      n_blocks: 5         # K: ãƒ–ãƒ­ãƒƒã‚¯æ•°

  df_observation:
    obs_feature_dim: 25         # d_B: è¦³æ¸¬ç‰¹å¾´æ¬¡å…ƒ
    multivariate_feature_dim: 50  # d_mï¼ˆencoderå‡ºåŠ›æ¬¡å…ƒï¼‰
    lambda_B: 1e-3        # V_Bæ­£å‰‡åŒ–
    lambda_dB: 1e-3       # U_Bæ­£å‰‡åŒ–
```

### ã‚¿ãƒ¼ã‚²ãƒƒãƒˆäºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰
```yaml
experiment:
  mode: "target_prediction"

model:
  target_decoder:
    type: "rkn"
    feature_dim: 50       # d_m
    state_dim: 8          # T: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ¬¡å…ƒ
    activation: "relu"
    output_activation: "tanh"

training:
  experiment_mode: "target_prediction"
  target_loss_weight: 1.0
  reconstruction_loss_weight: 0.0
```

---

## ğŸš€ åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•

### ã‚³ãƒ¼ãƒ‰ä¾‹
```python
import torch
import numpy as np
from src.utils.data_loader import load_experimental_data_with_architecture
from src.training.two_stage_trainer import TwoStageTrainer
from src.utils.config import load_cfg

# 1. ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆäº‹å‰ã«.npzãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆï¼‰
# data/your_dataset/your_data.npz ã‚’é…ç½®

# 2. è¨­å®šèª­ã¿è¾¼ã¿
config = load_cfg("configs/quad_image_reconstruction_config.yaml")

# 3. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
data_dict = load_experimental_data_with_architecture(
    "data/your_dataset/your_data.npz",
    config
)

# 4. ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼åˆæœŸåŒ–
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
trainer = TwoStageTrainer(
    config=config,
    device=device,
    output_dir="results/your_experiment"
)

# 5. å­¦ç¿’å®Ÿè¡Œ
trainer.train_integrated(
    data_dict['train'],
    data_dict['val']
)

# 6. è©•ä¾¡
from src.evaluation.metrics import compute_all_metrics
metrics = trainer.evaluate(data_dict['test'])
print(f"RMSE: {metrics['rmse']:.4f}")
print(f"PSNR: {metrics['psnr']:.4f}")
```

---

## ğŸ“ˆ å‡ºåŠ›ä¾‹

### å­¦ç¿’ãƒ­ã‚°ï¼ˆã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ï¼‰
```
=====
Epoch 1/10
=====
Phase-1å­¦ç¿’
  DF-A Stage-1: loss=0.0234
  DF-A Stage-2: loss=0.0198
  DF-B Stage-1: loss=0.0156
  DF-B Stage-2: loss=0.0142
Phase-2å­¦ç¿’
  Rec loss=0.0876, CCA loss=0.0023, Total=0.0899
Validation RMSE: 0.1234

=====
Epoch 6/10
=====
Phase-1å­¦ç¿’
  DF-A Stage-1: loss=0.0089
  DF-A Stage-2: loss=0.0076
  DF-B Stage-1: loss=0.0062
  DF-B Stage-2: loss=0.0055
Phase-2å­¦ç¿’
  Rec loss=0.0245, CCA loss=0.0008, Total=0.0253
Validation RMSE: 0.0567
```

### ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ 
```
results/your_experiment/
â”œâ”€â”€ final_model.pth              # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
â”œâ”€â”€ training_history.json        # å­¦ç¿’å±¥æ­´
â”œâ”€â”€ evaluation_results.json      # è©•ä¾¡çµæœ
â””â”€â”€ plots/
    â”œâ”€â”€ training_curves.png      # å­¦ç¿’æ›²ç·š
    â”œâ”€â”€ reconstruction_samples.png  # å†æ§‹æˆã‚µãƒ³ãƒ—ãƒ«
    â””â”€â”€ spectrum_analysis.png    # ã‚¹ãƒšã‚¯ãƒˆãƒ«åˆ†æ
```

### ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹
```python
# final_model.pth ã®å†…å®¹
checkpoint = torch.load('results/your_experiment/final_model.pth')

checkpoint.keys():
# ['config', 'model_state_dict', 'training_state']

checkpoint['model_state_dict'].keys():
# ['encoder', 'decoder', 'df_state', 'df_obs']

checkpoint['config']:
# {
#   'ssm': {'realization': {...}, 'df_state': {...}, 'df_observation': {...}},
#   'model': {'encoder': {...}, 'decoder': {...}}
# }
```

### è©•ä¾¡çµæœï¼ˆJSONï¼‰
```json
{
  "reconstruction_metrics": {
    "rmse": 0.0567,
    "psnr": 28.34,
    "temporal_correlation": 0.956
  },
  "mode_decomposition": {
    "spectral_radius": 0.892,
    "n_stable_modes": 28,
    "n_dominant_modes": 5
  }
}
```

---

## ğŸ”§ ã‚ªãƒ—ã‚·ãƒ§ãƒ³æ©Ÿèƒ½

### Kalmanãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
```python
trainer = TwoStageTrainer(
    config=config,
    device=device,
    use_kalman_filtering=True  # ä¸ç¢ºå®Ÿæ€§å®šé‡åŒ–
)
```

**ä½¿ç”¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«**:
- `src/inference/kalman_filter.py`
- `src/inference/noise_covariance.py`
- `src/inference/state_estimator.py`

**å‡ºåŠ›**: çŠ¶æ…‹æ¨å®šå€¤ã®å¹³å‡ãƒ»å…±åˆ†æ•£

---

## ğŸ“ ä¸»è¦ãªæ•°å¼

### DF-A Stage-1æå¤±
```
L_Stage1 = Î£_k ||Î¦_k^+ - V_A^{(-k)} Î¦_k^-||Â² + Î»_A ||V_A^{(-k)}||Â²
```

### DF-B Stage-1æå¤±
```
L_Stage1 = Î£_k ||Î¨_k^+ - V_B^{(-k)} Î¨_k^-||Â² + Î»_B ||V_B^{(-k)}||Â²
```

### Phase-2ç·åˆæå¤±
```
L_total = L_reconstruction + Î»_cca * L_cca
```

### æ¨è«–ãƒ‘ã‚¹
```
Y â†’ encoder â†’ M â†’ realization â†’ XÌ‚
XÌ‚ â†’ Ï†_Î¸ â†’ Î¦ â†’ (U_A^T V_A) â†’ Î¦_pred â†’ XÌ‚_pred
XÌ‚_pred â†’ Ïˆ_Ï‰ â†’ Î¨ â†’ (U_B^T V_B) â†’ Î¨_pred â†’ MÌ‚
MÌ‚ â†’ decoder â†’ Å¶
```

---

## ğŸ“ å®Ÿè£…ã®ç‰¹å¾´

1. **ã‚¯ãƒ­ã‚¹ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°**: æ™‚ç³»åˆ—é€£ç¶šãƒ–ãƒ­ãƒƒã‚¯åˆ†å‰²ã§out-of-foldæ¨å®š
2. **å‹¾é…ä¼æ’­**: Ridgeè§£ï¼ˆV_A, U_Aç­‰ï¼‰ã‚’é€šã˜ãŸå‹¾é…ä¼æ’­å®Ÿè£…
3. **çµ±åˆå­¦ç¿’**: Phase-1/Phase-2ã‚’å„ã‚¨ãƒãƒƒã‚¯ã§é€£ç¶šå®Ÿè¡Œ
4. **å¤šå¤‰é‡å¯¾å¿œ**: DF-Bå¤šå¤‰é‡è¦³æ¸¬å¯¾å¿œ
5. **ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­è¨ˆ**: Factoryãƒ‘ã‚¿ãƒ¼ãƒ³ã§æ‹¡å¼µæ€§ç¢ºä¿

---

## ğŸ“š å‚è€ƒè³‡æ–™

- è©³ç´°å®šå¼åŒ–: `_prompt/Theory_and_Formulation.md`
- å®Ÿè£…ã‚¬ã‚¤ãƒ‰: `_prompt/Code_Implementation_Guide.md`
- ã‚³ãƒ¼ãƒ‰ãƒ•ãƒ­ãƒ¼: `_prompt/CODE_FLOW_ANALYSIS.md`
