#!/usr/bin/env python3
# _tests/test_integration.py
"""
ææ¡ˆæ‰‹æ³•ã®çµ±åˆãƒ†ã‚¹ãƒˆï¼ˆä¿®æ­£å¾Œå®Ÿè£…å¯¾å¿œç‰ˆï¼‰

ä¿®æ­£å†…å®¹:
- TwoStageTrainerã‚¯ãƒ©ã‚¹ã«å¯¾å¿œ
- æ–°ã—ã„DF-A/DF-B APIã«å¯¾å¿œ
- Phase-1/Phase-2å­¦ç¿’ãƒ•ãƒ­ãƒ¼ã«å¯¾å¿œ
- è©³ç´°ãªå‹•ä½œç¢ºèªæ©Ÿèƒ½è¿½åŠ 

å®Ÿè¡Œæ–¹æ³•:
  cd SSMwithELTO
  python _tests/test_integration.py --quick    # é«˜é€Ÿãƒ†ã‚¹ãƒˆ
  python _tests/test_integration.py --full     # å®Œå…¨ãƒ†ã‚¹ãƒˆ
  python _tests/test_integration.py --debug    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰
"""

import argparse
import sys
import os
import torch
import numpy as np
import yaml
import tempfile
import traceback
from pathlib import Path
from typing import Dict, Any, Tuple, Optional

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ã®è¨­å®š
TEST_DIR = Path(__file__).parent
PROJECT_ROOT = TEST_DIR.parent
sys.path.insert(0, str(PROJECT_ROOT))
sys.path.insert(0, str(PROJECT_ROOT / 'src'))

def check_dependencies():
    """ä¾å­˜é–¢ä¿‚ã®ç¢ºèª"""
    print("=== ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯ ===")
    required_modules = [
        'torch', 'numpy', 'yaml', 'matplotlib', 'pandas'
    ]
    
    missing = []
    for module in required_modules:
        try:
            __import__(module)
            print(f"âœ“ {module}")
        except ImportError:
            missing.append(module)
            print(f"âœ— {module}")
    
    if missing:
        print(f"âŒ ä¸è¶³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: {missing}")
        print("pip install torch numpy pyyaml matplotlib pandas ã§è§£æ±ºã§ãã¾ã™")
        return False
    
    print("âœ“ å…¨ä¾å­˜é–¢ä¿‚OK")
    return True

def check_project_structure():
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã®ç¢ºèª"""
    print("=== ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ãƒã‚§ãƒƒã‚¯ ===")
    
    required_paths = [
        PROJECT_ROOT / 'src',
        PROJECT_ROOT / 'src' / 'models',
        PROJECT_ROOT / 'src' / 'ssm',
        PROJECT_ROOT / 'src' / 'training',
        PROJECT_ROOT / 'configs',
    ]
    
    missing_paths = []
    for path in required_paths:
        if path.exists():
            print(f"âœ“ {path.relative_to(PROJECT_ROOT)}")
        else:
            missing_paths.append(path)
            print(f"âœ— {path.relative_to(PROJECT_ROOT)}")
    
    if missing_paths:
        print(f"âŒ ä¸è¶³ãƒ‘ã‚¹: {[str(p.relative_to(PROJECT_ROOT)) for p in missing_paths]}")
        return False
    
    print("âœ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ OK")
    return True

def generate_synthetic_data(config: Dict[str, Any]) -> torch.Tensor:
    """è¨­å®šã«åŸºã¥ãåˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
    d = config['model']['encoder']['input_dim']
    h = config['ssm']['realization']['past_horizon']
    
    # æœ€å°å¿…è¦é•· + ãƒãƒ¼ã‚¸ãƒ³
    min_T = 2 * h + 50
    T = max(min_T, 200)
    
    torch.manual_seed(42)
    t = torch.linspace(0, 4*np.pi, T)
    Y = torch.zeros(T, d)
    
    # å„æ¬¡å…ƒã‚’ç•°ãªã‚‹ç‰¹æ€§ã§ç”Ÿæˆ
    for i in range(d):
        # åŸºæœ¬å‘¨æœŸæˆåˆ†
        freq = 0.5 + i * 0.3
        phase = i * np.pi / 4
        signal = torch.sin(freq * t + phase)
        
        # ARæˆåˆ†
        ar_coeff = 0.2 + i * 0.1
        noise = 0.1 * torch.randn(T)
        
        Y[:, i] = signal + noise
        
        # ARé …è¿½åŠ 
        for tau in range(1, T):
            Y[tau, i] += ar_coeff * Y[tau-1, i] * 0.5
    
    # æ­£è¦åŒ–
    Y = (Y - Y.mean(dim=0, keepdim=True)) / (Y.std(dim=0, keepdim=True) + 1e-8)
    
    print(f"âœ“ åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ: shape={Y.shape}, range=({Y.min():.2f}, {Y.max():.2f})")
    return Y

def test_individual_components(config: Dict[str, Any], Y: torch.Tensor, verbose: bool = True) -> Dict[str, bool]:
    """å€‹åˆ¥ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ãƒ†ã‚¹ãƒˆï¼ˆä¿®æ­£å¾Œå®Ÿè£…å¯¾å¿œï¼‰"""
    results = {}
    
    if verbose:
        print("\n=== å€‹åˆ¥ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãƒ†ã‚¹ãƒˆ ===")
    
    # 1. ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ†ã‚¹ãƒˆ
    try:
        from src.models.architectures.tcn import tcnEncoder
        encoder = tcnEncoder(**config['model']['encoder'])
        
        # ä¿®æ­£: 3æ¬¡å…ƒå…¥åŠ›ã«å¯¾å¿œ
        Y_batch = Y.unsqueeze(0)  # (T, d) -> (1, T, d)
        m_output = encoder(Y_batch)  # (1, T, 1)
        m_series = m_output.squeeze()  # (T,)
        
        results['encoder'] = True
        if verbose:
            print(f"âœ“ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€: {Y.shape} -> {m_series.shape}")
            print(f"  ç‰¹å¾´é‡çµ±è¨ˆ: mean={m_series.mean():.4f}, std={m_series.std():.4f}")
    
    except Exception as e:
        results['encoder'] = False
        if verbose:
            print(f"âœ— ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚¨ãƒ©ãƒ¼: {e}")
        return results
    
    # 2. ç¢ºç‡çš„å®Ÿç¾ãƒ†ã‚¹ãƒˆ
    try:
        from src.ssm.realization import Realization
        realization = Realization(**config['ssm']['realization'])
        
        m_input = m_series.unsqueeze(1)  # (T,) -> (T, 1)
        realization.fit(m_input)
        X_states = realization.filter(m_input)
        
        results['realization'] = True
        if verbose:
            print(f"âœ“ ç¢ºç‡çš„å®Ÿç¾: {m_input.shape} -> {X_states.shape}")
            if hasattr(realization, '_L_vals') and realization._L_vals is not None:
                singular_values_for_display = realization._L_vals.detach().cpu().numpy()
                print(f"  ç‰¹ç•°å€¤: {singular_values_for_display}")
    
    except Exception as e:
        results['realization'] = False
        if verbose:
            print(f"âœ— ç¢ºç‡çš„å®Ÿç¾ã‚¨ãƒ©ãƒ¼: {e}")
        return results
    
    # 3. DF-A ãƒ†ã‚¹ãƒˆ
    try:
        from src.ssm.df_state_layer import DFStateLayer
        
        _, r = X_states.shape
        df_state = DFStateLayer(
            state_dim=r,
            **config['ssm']['df_state']
        )
        
        # Stage-1ã®ã¿ãƒ†ã‚¹ãƒˆ
        optimizer_phi = torch.optim.Adam(df_state.phi_theta.parameters(), lr=1e-3)
        metrics = df_state.train_stage1_with_gradients(X_states, optimizer_phi)
        
        results['df_state'] = True
        if verbose:
            print(f"âœ“ DF-A: Stage-1 loss={metrics['stage1_loss']:.4f}")
    
    except Exception as e:
        results['df_state'] = False
        if verbose:
            print(f"âœ— DF-A ã‚¨ãƒ©ãƒ¼: {e}")
        return results
    
    # 4. DF-B ãƒ†ã‚¹ãƒˆ
    try:
        from src.ssm.df_observation_layer import DFObservationLayer
        
        df_obs = DFObservationLayer(
            df_state_layer=df_state,
            **config['ssm']['df_observation']
        )
        
        # çŠ¶æ…‹äºˆæ¸¬ã‚’å–å¾—
        X_hat_states = df_state.predict_sequence(X_states)
        
        optimizer_phi = torch.optim.Adam(df_state.phi_theta.parameters(), lr=1e-3)
        metrics = df_obs.train_stage1_with_gradients(
            X_hat_states, m_series, optimizer_phi, fix_psi_omega=True
        )
        
        results['df_observation'] = True
        if verbose:
            print(f"âœ“ DF-B: Stage-1 loss={metrics['stage1_loss']:.4f}")
    
    except Exception as e:
        results['df_observation'] = False
        if verbose:
            print(f"âœ— DF-B ã‚¨ãƒ©ãƒ¼: {e}")
        return results
    
    # 5. ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ†ã‚¹ãƒˆ
    try:
        from src.models.architectures.tcn import tcnDecoder
        decoder = tcnDecoder(**config['model']['decoder'])
        
        # ãƒ€ãƒŸãƒ¼å…¥åŠ›ã§ãƒ†ã‚¹ãƒˆ
        dummy_input = torch.randn(1, 10, 1)  # (batch, time, features)
        decoded_output = decoder(dummy_input)
        
        results['decoder'] = True
        if verbose:
            print(f"âœ“ ãƒ‡ã‚³ãƒ¼ãƒ€: {dummy_input.shape} -> {decoded_output.shape}")
    
    except Exception as e:
        results['decoder'] = False
        if verbose:
            print(f"âœ— ãƒ‡ã‚³ãƒ¼ãƒ€ã‚¨ãƒ©ãƒ¼: {e}")
    
    return results

def test_two_stage_trainer(config_path: str, quick: bool = False, verbose: bool = True) -> bool:
    """TwoStageTrainerã‚’ç”¨ã„ãŸçµ±åˆãƒ†ã‚¹ãƒˆ"""
    if verbose:
        print("\n=== TwoStageTrainerçµ±åˆãƒ†ã‚¹ãƒˆ ===")
    
    try:
        # è¨­å®šèª­ã¿è¾¼ã¿
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
        
        # ã‚¯ã‚¤ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰è¨­å®š
        if quick:
            config['training']['phase1_epochs'] = 2
            config['training']['phase2_epochs'] = 2
            config['training']['T1_iterations'] = 2
            config['training']['T2_iterations'] = 1
        
        # ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        Y = generate_synthetic_data(config)
        
        # å€‹åˆ¥ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        component_results = test_individual_components(config, Y, verbose)
        
        failed_components = [k for k, v in component_results.items() if not v]
        if failed_components:
            if verbose:
                print(f"âœ— å¤±æ•—ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ: {failed_components}")
            return False
        
        # TwoStageTrainerçµ±åˆãƒ†ã‚¹ãƒˆ
        if verbose:
            print("\n--- TwoStageTrainerçµ±åˆãƒ†ã‚¹ãƒˆ ---")
        
        from src.training.two_stage_trainer import TwoStageTrainer, TrainingConfig
        from src.models.architectures.tcn import tcnEncoder, tcnDecoder
        from src.ssm.realization import Realization
        
        with tempfile.TemporaryDirectory() as temp_dir:
            # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
            encoder = tcnEncoder(**config['model']['encoder'])
            decoder = tcnDecoder(**config['model']['decoder'])
            realization = Realization(**config['ssm']['realization'])
            
            # ãƒ‡ãƒã‚¤ã‚¹ï¼ˆCPUã§å®‰å…¨ã«ï¼‰
            device = torch.device('cpu')
            
            # å­¦ç¿’è¨­å®š
            training_config = TrainingConfig(**config['training'])
            
            # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ä½œæˆ
            trainer = TwoStageTrainer(
                encoder=encoder,
                decoder=decoder,
                realization=realization,
                df_state_config=config['ssm']['df_state'],
                df_obs_config=config['ssm']['df_observation'],
                training_config=training_config,
                device=device,
                output_dir=temp_dir
            )
            
            # Phase-1å­¦ç¿’
            if verbose:
                print("Phase-1å­¦ç¿’å®Ÿè¡Œä¸­...")
            
            phase1_results = trainer.train_phase1(Y)
            
            if verbose:
                print(f"âœ“ Phase-1å®Œäº†: {len(phase1_results)}ã‚¨ãƒãƒƒã‚¯")
                
                # æœ€çµ‚æå¤±è¡¨ç¤º
                if phase1_results:
                    final_metrics = phase1_results[-1]
                    df_a_loss = final_metrics.get('df_a_stage1_loss', 'N/A')
                    df_b_loss = final_metrics.get('df_b_stage1_loss', 'N/A')
                    print(f"  æœ€çµ‚æå¤± - DF-A: {df_a_loss}, DF-B: {df_b_loss}")
            
            # Phase-2å­¦ç¿’ï¼ˆã‚¯ã‚¤ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§ã¯çœç•¥å¯èƒ½ï¼‰
            if not quick:
                if verbose:
                    print("Phase-2å­¦ç¿’å®Ÿè¡Œä¸­...")
                
                phase2_results = trainer.train_phase2(Y)
                
                if verbose:
                    print(f"âœ“ Phase-2å®Œäº†: {len(phase2_results)}ã‚¨ãƒãƒƒã‚¯")
                    if phase2_results:
                        final_loss = phase2_results[-1]['total_loss']
                        print(f"  æœ€çµ‚æå¤±: {final_loss:.4f}")
            
            # äºˆæ¸¬ãƒ†ã‚¹ãƒˆ
            try:
                Y_test = Y[-30:]
                predictions = trainer.predict(Y_test, forecast_steps=3)
                
                if verbose:
                    print(f"âœ“ äºˆæ¸¬ãƒ†ã‚¹ãƒˆå®Œäº†: {predictions.shape}")
                    print(f"  äºˆæ¸¬ç¯„å›²: ({predictions.min():.3f}, {predictions.max():.3f})")
            
            except Exception as e:
                if verbose:
                    print(f"âš  äºˆæ¸¬ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ï¼ˆéè‡´å‘½çš„ï¼‰: {e}")
        
        return True
        
    except Exception as e:
        if verbose:
            print(f"âœ— çµ±åˆãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            if len(str(e)) < 200:  # çŸ­ã„ã‚¨ãƒ©ãƒ¼ã®ã¿è©³ç´°è¡¨ç¤º
                traceback.print_exc()
        return False

def test_learning_flow_analysis(config_path: str, verbose: bool = True) -> bool:
    """å­¦ç¿’ãƒ•ãƒ­ãƒ¼ã®è©³ç´°åˆ†æãƒ†ã‚¹ãƒˆ"""
    if verbose:
        print("\n=== å­¦ç¿’ãƒ•ãƒ­ãƒ¼åˆ†æãƒ†ã‚¹ãƒˆ ===")
    
    try:
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
        
        # å°è¦æ¨¡è¨­å®š
        config['training']['phase1_epochs'] = 3
        config['training']['phase2_epochs'] = 2
        
        Y = generate_synthetic_data(config)
        
        from src.training.two_stage_trainer import TwoStageTrainer, TrainingConfig
        from src.models.architectures.tcn import tcnEncoder, tcnDecoder
        from src.ssm.realization import Realization
        
        with tempfile.TemporaryDirectory() as temp_dir:
            # ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼åˆæœŸåŒ–
            encoder = tcnEncoder(**config['model']['encoder'])
            decoder = tcnDecoder(**config['model']['decoder'])
            realization = Realization(**config['ssm']['realization'])
            training_config = TrainingConfig(**config['training'])
            
            trainer = TwoStageTrainer(
                encoder=encoder,
                decoder=decoder,
                realization=realization,
                df_state_config=config['ssm']['df_state'],
                df_obs_config=config['ssm']['df_observation'],
                training_config=training_config,
                device=torch.device('cpu'),
                output_dir=temp_dir
            )
            
            # æ™‚é–“å¯¾å¿œãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹åŒ–
            trainer.enable_time_alignment_debug()
            
            # Phase-1ã®è©³ç´°åˆ†æ
            if verbose:
                print("Phase-1è©³ç´°åˆ†æå®Ÿè¡Œä¸­...")
            
            phase1_results = trainer.train_phase1(Y)
            
            # å­¦ç¿’å±¥æ­´åˆ†æ
            if phase1_results:
                # æå¤±æ¨ç§»åˆ†æ
                df_a_losses = [m.get('df_a_stage1_loss') for m in phase1_results if 'df_a_stage1_loss' in m]
                df_b_losses = [m.get('df_b_stage1_loss') for m in phase1_results if 'df_b_stage1_loss' in m]
                
                if verbose:
                    print(f"âœ“ DF-Aæå¤±æ¨ç§»: {len(df_a_losses)}å€‹ã®ã‚¨ãƒãƒƒã‚¯")
                    if df_a_losses:
                        print(f"  åˆæœŸæå¤±: {df_a_losses[0]:.4f} -> æœ€çµ‚æå¤±: {df_a_losses[-1]:.4f}")
                    
                    print(f"âœ“ DF-Bæå¤±æ¨ç§»: {len(df_b_losses)}å€‹ã®ã‚¨ãƒãƒƒã‚¯")
                    if df_b_losses:
                        print(f"  åˆæœŸæå¤±: {df_b_losses[0]:.4f} -> æœ€çµ‚æå¤±: {df_b_losses[-1]:.4f}")
            
            # Phase-2åˆ†æ
            if verbose:
                print("Phase-2è©³ç´°åˆ†æå®Ÿè¡Œä¸­...")
            
            phase2_results = trainer.train_phase2(Y)
            
            if phase2_results:
                total_losses = [r['total_loss'] for r in phase2_results]
                rec_losses = [r['rec_loss'] for r in phase2_results]
                
                if verbose:
                    print(f"âœ“ Phase-2æå¤±æ¨ç§»: {len(total_losses)}å€‹ã®ã‚¨ãƒãƒƒã‚¯")
                    if total_losses:
                        print(f"  ç·æå¤±: {total_losses[0]:.4f} -> {total_losses[-1]:.4f}")
                        print(f"  å†æ§‹æˆæå¤±: {rec_losses[0]:.4f} -> {rec_losses[-1]:.4f}")
            
            # å­¦ç¿’ã‚µãƒãƒªå–å¾—
            summary = trainer.get_training_summary()
            if verbose:
                print(f"âœ“ å­¦ç¿’ã‚µãƒãƒªå–å¾—å®Œäº†")
                print(f"  å­¦ç¿’å®Œäº†: {summary['training_complete']}")
                print(f"  ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(summary['model_info'].values())}")
        
        return True
        
    except Exception as e:
        if verbose:
            print(f"âœ— å­¦ç¿’ãƒ•ãƒ­ãƒ¼åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            traceback.print_exc()
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(description="ææ¡ˆæ‰‹æ³•çµ±åˆãƒ†ã‚¹ãƒˆï¼ˆä¿®æ­£å¾Œå®Ÿè£…å¯¾å¿œç‰ˆï¼‰")
    parser.add_argument('--quick', action='store_true', help='é«˜é€Ÿãƒ†ã‚¹ãƒˆï¼ˆçŸ­ç¸®ç‰ˆï¼‰')
    parser.add_argument('--full', action='store_true', help='å®Œå…¨ãƒ†ã‚¹ãƒˆ')
    parser.add_argument('--debug', action='store_true', help='ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ï¼ˆè©³ç´°å‡ºåŠ›ï¼‰')
    parser.add_argument('--analysis', action='store_true', help='å­¦ç¿’ãƒ•ãƒ­ãƒ¼åˆ†æãƒ†ã‚¹ãƒˆ')
    parser.add_argument('--config', type=str, default='_tests/test_config.yaml', 
                       help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    args = parser.parse_args()
    
    # ãƒ¢ãƒ¼ãƒ‰è¨­å®š
    if args.debug:
        verbose = True
        torch.autograd.set_detect_anomaly(True)
        print("ğŸ”§ ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: è©³ç´°å‡ºåŠ›ãƒ»ç•°å¸¸æ¤œå‡ºæœ‰åŠ¹")
    else:
        verbose = not args.quick
    
    if args.quick:
        print("ğŸš€ é«˜é€Ÿãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰")
    elif args.full:
        print("ğŸ¯ å®Œå…¨ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰")
    elif args.analysis:
        print("ğŸ“Š å­¦ç¿’ãƒ•ãƒ­ãƒ¼åˆ†æãƒ¢ãƒ¼ãƒ‰")
    
    print("ææ¡ˆæ‰‹æ³• çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹ï¼ˆä¿®æ­£å¾Œå®Ÿè£…å¯¾å¿œç‰ˆï¼‰")
    print("=" * 60)
    
    # ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
    if not check_dependencies():
        return 1
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ãƒã‚§ãƒƒã‚¯
    if not check_project_structure():
        return 1
    
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
    config_path = Path(args.config)
    if not config_path.is_absolute():
        config_path = PROJECT_ROOT / config_path
        
    if not config_path.exists():
        print(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}")
        print("_tests/test_config.yaml ã‚’ä½œæˆã—ã¦ãã ã•ã„")
        return 1
    
    print(f"ğŸ“‹ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: {config_path.relative_to(PROJECT_ROOT)}")
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    try:
        success = True
        
        # åŸºæœ¬çµ±åˆãƒ†ã‚¹ãƒˆ
        if args.analysis:
            success = test_learning_flow_analysis(str(config_path), verbose)
        else:
            success = test_two_stage_trainer(str(config_path), args.quick, verbose)
        
        print("\n" + "=" * 60)
        if success:
            print("ğŸ‰ çµ±åˆãƒ†ã‚¹ãƒˆæˆåŠŸï¼")
            print("ä¿®æ­£å¾Œå®Ÿè£…ã®åŸºæœ¬å‹•ä½œç¢ºèªå®Œäº†ã€‚")
            
            if args.quick:
                print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
                print("  python _tests/test_integration.py --full     # å®Œå…¨ãƒ†ã‚¹ãƒˆ")
                print("  python _tests/test_integration.py --analysis # å­¦ç¿’ãƒ•ãƒ­ãƒ¼åˆ†æ")
                print("  python main_two_stage.py --config configs/config_two_stage_experiment.yaml")
            
            return 0
        else:
            print("âŒ çµ±åˆãƒ†ã‚¹ãƒˆå¤±æ•—")
            print("ä¸Šè¨˜ã®ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã—ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            
            if not verbose:
                print("\nè©³ç´°ç¢ºèª:")
                print("  python _tests/test_integration.py --debug")
            
            return 1
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ ãƒ†ã‚¹ãƒˆä¸­æ–­")
        return 1
    except Exception as e:
        print(f"\nğŸ’¥ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        if args.debug:
            traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit(main())