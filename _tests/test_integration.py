#!/usr/bin/env python3
# _tests/test_integration.py
"""
ææ¡ˆæ‰‹æ³•ã®çµ±åˆãƒ†ã‚¹ãƒˆ

å®Ÿè¡Œæ–¹æ³•:
  cd SSMwithELTO
  python _tests/test_integration.py --quick    # é«˜é€Ÿãƒ†ã‚¹ãƒˆ
  python _tests/test_integration.py --full     # å®Œå…¨ãƒ†ã‚¹ãƒˆ
  python _tests/test_integration.py --debug    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰
"""

import argparse
import sys
import os
import torch
import numpy as np
import yaml
import tempfile
import traceback
from pathlib import Path
from typing import Dict, Any, Tuple, Optional

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ã®è¨­å®š
TEST_DIR = Path(__file__).parent
PROJECT_ROOT = TEST_DIR.parent
sys.path.insert(0, str(PROJECT_ROOT))
sys.path.insert(0, str(PROJECT_ROOT / 'src'))

def check_dependencies():
    """ä¾å­˜é–¢ä¿‚ã®ç¢ºèª"""
    print("=== ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯ ===")
    required_modules = [
        'torch', 'numpy', 'yaml', 'matplotlib', 'pandas'
    ]
    
    missing = []
    for module in required_modules:
        try:
            __import__(module)
            print(f"âœ“ {module}")
        except ImportError:
            missing.append(module)
            print(f"âœ— {module}")
    
    if missing:
        print(f"\nâŒ ä¸è¶³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: {missing}")
        print("pip install torch numpy pyyaml matplotlib pandas ã§è§£æ±ºã§ãã¾ã™")
        return False
    
    print("âœ“ å…¨ä¾å­˜é–¢ä¿‚OK")
    return True

def check_project_structure():
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã®ç¢ºèª"""
    print("=== ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ãƒã‚§ãƒƒã‚¯ ===")
    
    required_paths = [
        PROJECT_ROOT / 'src',
        PROJECT_ROOT / 'src' / 'models',
        PROJECT_ROOT / 'src' / 'ssm',
        PROJECT_ROOT / 'src' / 'training',
        PROJECT_ROOT / 'configs',
    ]
    
    missing_paths = []
    for path in required_paths:
        if path.exists():
            print(f"âœ“ {path.relative_to(PROJECT_ROOT)}")
        else:
            missing_paths.append(path)
            print(f"âœ— {path.relative_to(PROJECT_ROOT)}")
    
    if missing_paths:
        print(f"\nâŒ ä¸è¶³ãƒ‘ã‚¹: {[str(p.relative_to(PROJECT_ROOT)) for p in missing_paths]}")
        return False
    
    print("âœ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ OK")
    return True

def generate_synthetic_data(config: Dict[str, Any]) -> torch.Tensor:
    """è¨­å®šã«åŸºã¥ãåˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
    d = config['model']['encoder']['input_dim']
    h = config['ssm']['realization']['past_horizon']
    
    # æœ€å°å¿…è¦é•· + ãƒãƒ¼ã‚¸ãƒ³
    min_T = 2 * h + 50
    T = max(min_T, 200)
    
    torch.manual_seed(42)
    t = torch.linspace(0, 4*np.pi, T)
    Y = torch.zeros(T, d)
    
    # å„æ¬¡å…ƒã‚’ç•°ãªã‚‹ç‰¹æ€§ã§ç”Ÿæˆ
    for i in range(d):
        # åŸºæœ¬å‘¨æœŸæˆåˆ†
        freq = 0.5 + i * 0.3
        phase = i * np.pi / 4
        signal = torch.sin(freq * t + phase)
        
        # ARæˆåˆ†
        ar_coeff = 0.2 + i * 0.1
        noise = 0.1 * torch.randn(T)
        
        Y[:, i] = signal + noise
        
        # ARé …è¿½åŠ 
        for tau in range(1, T):
            Y[tau, i] += ar_coeff * Y[tau-1, i] * 0.5
    
    # æ­£è¦åŒ–
    Y = (Y - Y.mean(dim=0, keepdim=True)) / (Y.std(dim=0, keepdim=True) + 1e-8)
    
    print(f"âœ“ åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ: shape={Y.shape}, range=({Y.min():.2f}, {Y.max():.2f})")
    return Y

def test_individual_components(config: Dict[str, Any], Y: torch.Tensor, verbose: bool = True) -> Dict[str, bool]:
    """å€‹åˆ¥ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ãƒ†ã‚¹ãƒˆ"""
    results = {}
    
    if verbose:
        print("\n=== å€‹åˆ¥ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãƒ†ã‚¹ãƒˆ ===")
    
    # 1. ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ†ã‚¹ãƒˆ
    try:
        from src.models.architectures.tcn import tcnEncoder
        encoder = tcnEncoder(**config['model']['encoder'])
        
        Y_batch = Y.unsqueeze(0)
        m_output = encoder(Y_batch)
        m_series = m_output.squeeze()
        
        if m_series.dim() == 2 and m_series.size(1) == 1:
            m_series = m_series.squeeze(1)
        
        results['encoder'] = True
        if verbose:
            print(f"âœ“ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€: {Y.shape} -> {m_series.shape}")
            print(f"  ç‰¹å¾´é‡çµ±è¨ˆ: mean={m_series.mean():.4f}, std={m_series.std():.4f}")
    
    except Exception as e:
        results['encoder'] = False
        if verbose:
            print(f"âœ— ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚¨ãƒ©ãƒ¼: {e}")
        return results
    
    # 2. ç¢ºç‡çš„å®Ÿç¾ãƒ†ã‚¹ãƒˆ
    try:
        from src.ssm.realization import Realization
        realization = Realization(**config['ssm']['realization'])
        
        m_input = m_series.unsqueeze(1) if m_series.dim() == 1 else m_series
        realization.fit(m_input)
        X_states = realization.filter(m_input)
        
        results['realization'] = True
        if verbose:
            print(f"âœ“ ç¢ºç‡çš„å®Ÿç¾: {m_input.shape} -> {X_states.shape}")
            if hasattr(realization, '_L_vals') and realization._L_vals is not None:
                print(f"  ç‰¹ç•°å€¤: {realization._L_vals.cpu().numpy()}")
    
    except Exception as e:
        results['realization'] = False
        if verbose:
            print(f"âœ— ç¢ºç‡çš„å®Ÿç¾ã‚¨ãƒ©ãƒ¼: {e}")
        return results
    
    # 3. DF-A ãƒ†ã‚¹ãƒˆ
    try:
        from src.ssm.df_state_layer import DFStateLayer
        
        _, r = X_states.shape
        df_state = DFStateLayer(
            state_dim=r,
            **config['ssm']['df_state']
        )
        
        # Stage-1ã®ã¿ãƒ†ã‚¹ãƒˆ
        optimizer_phi = torch.optim.Adam(df_state.phi_theta.parameters(), lr=1e-3)
        metrics = df_state.train_stage1_with_gradients(X_states, optimizer_phi)
        
        results['df_state'] = True
        if verbose:
            print(f"âœ“ DF-A: Stage-1 loss={metrics['stage1_loss']:.4f}")
    
    except Exception as e:
        results['df_state'] = False
        if verbose:
            print(f"âœ— DF-A ã‚¨ãƒ©ãƒ¼: {e}")
        return results
    
    # 4. DF-B ãƒ†ã‚¹ãƒˆ
    try:
        from src.ssm.df_observation_layer import DFObservationLayer
        
        df_obs = DFObservationLayer(
            df_state_layer=df_state,
            **config['ssm']['df_observation']
        )
        
        # ç°¡å˜ãªäºˆæ¸¬ãƒ†ã‚¹ãƒˆ
        X_hat_states = df_state.predict_sequence(X_states)
        
        optimizer_psi = torch.optim.Adam(df_obs.psi_omega.parameters(), lr=1e-3)
        metrics = df_obs.train_stage1_with_gradients(
            X_hat_states, m_series, optimizer_phi, fix_psi_omega=True
        )
        
        results['df_observation'] = True
        if verbose:
            print(f"âœ“ DF-B: Stage-1 loss={metrics['stage1_loss']:.4f}")
    
    except Exception as e:
        results['df_observation'] = False
        if verbose:
            print(f"âœ— DF-B ã‚¨ãƒ©ãƒ¼: {e}")
        return results
    
    # 5. ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ†ã‚¹ãƒˆ
    try:
        from src.models.architectures.tcn import tcnDecoder
        decoder = tcnDecoder(**config['model']['decoder'])
        
        # ãƒ€ãƒŸãƒ¼å…¥åŠ›ã§ãƒ†ã‚¹ãƒˆ
        dummy_input = torch.randn(1, 10, 1)  # (batch, time, features)
        decoded_output = decoder(dummy_input)
        
        results['decoder'] = True
        if verbose:
            print(f"âœ“ ãƒ‡ã‚³ãƒ¼ãƒ€: {dummy_input.shape} -> {decoded_output.shape}")
    
    except Exception as e:
        results['decoder'] = False
        if verbose:
            print(f"âœ— ãƒ‡ã‚³ãƒ¼ãƒ€ã‚¨ãƒ©ãƒ¼: {e}")
    
    return results

def test_integration_pipeline(config_path: str, quick: bool = False, verbose: bool = True) -> bool:
    """çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ"""
    if verbose:
        print("\n=== çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ ===")
    
    try:
        # è¨­å®šèª­ã¿è¾¼ã¿
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
        
        # ã‚¯ã‚¤ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§ã¯æ›´ã«çŸ­ç¸®
        if quick:
            config['training']['phase1_epochs'] = 2
            config['training']['phase2_epochs'] = 2
            config['training']['T1_iterations'] = 2
            config['training']['T2_iterations'] = 1
        
        # ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        Y = generate_synthetic_data(config)
        
        # å€‹åˆ¥ãƒ†ã‚¹ãƒˆ
        component_results = test_individual_components(config, Y, verbose)
        
        failed_components = [k for k, v in component_results.items() if not v]
        if failed_components:
            if verbose:
                print(f"âœ— å¤±æ•—ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ: {failed_components}")
            return False
        
        # å®Œå…¨çµ±åˆãƒ†ã‚¹ãƒˆ
        if verbose:
            print("\n--- å®Œå…¨çµ±åˆãƒ†ã‚¹ãƒˆ ---")
        
        from src.training.two_stage_trainer import TwoStageTrainer, TrainingConfig
        from src.models.architectures.tcn import tcnEncoder, tcnDecoder
        from src.ssm.realization import Realization
        
        with tempfile.TemporaryDirectory() as temp_dir:
            # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
            encoder = tcnEncoder(**config['model']['encoder'])
            decoder = tcnDecoder(**config['model']['decoder'])
            realization = Realization(**config['ssm']['realization'])
            
            # ãƒ‡ãƒã‚¤ã‚¹ï¼ˆCPUã§å®‰å…¨ã«ï¼‰
            device = torch.device('cpu')
            
            # å­¦ç¿’è¨­å®š
            training_config = TrainingConfig(**config['training'])
            
            # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ä½œæˆ
            trainer = TwoStageTrainer(
                encoder=encoder,
                decoder=decoder,
                realization=realization,
                df_state_config=config['ssm']['df_state'],
                df_obs_config=config['ssm']['df_observation'],
                training_config=training_config,
                device=device,
                output_dir=temp_dir
            )
            
            # Phase-1å­¦ç¿’
            if verbose:
                print("Phase-1å­¦ç¿’å®Ÿè¡Œä¸­...")
            
            phase1_results = trainer.train_phase1(Y)
            
            if verbose:
                print(f"âœ“ Phase-1å®Œäº†: {len(phase1_results)}ã‚¨ãƒãƒƒã‚¯")
                
                # æœ€çµ‚æå¤±è¡¨ç¤º
                if phase1_results:
                    final_metrics = phase1_results[-1]
                    df_a_loss = final_metrics.get('df_a_stage1_loss', 'N/A')
                    df_b_loss = final_metrics.get('df_b_stage1_loss', 'N/A')
                    print(f"  æœ€çµ‚æå¤± - DF-A: {df_a_loss}, DF-B: {df_b_loss}")
            
            # Phase-2å­¦ç¿’ï¼ˆã‚¯ã‚¤ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§ã¯çœç•¥ï¼‰
            if not quick:
                if verbose:
                    print("Phase-2å­¦ç¿’å®Ÿè¡Œä¸­...")
                
                phase2_results = trainer.train_phase2(Y)
                
                if verbose:
                    print(f"âœ“ Phase-2å®Œäº†: {len(phase2_results)}ã‚¨ãƒãƒƒã‚¯")
                    if phase2_results:
                        final_loss = phase2_results[-1]['total_loss']
                        print(f"  æœ€çµ‚æå¤±: {final_loss:.4f}")
            
            # äºˆæ¸¬ãƒ†ã‚¹ãƒˆ
            try:
                Y_test = Y[-30:]
                predictions = trainer.predict(Y_test, forecast_steps=3)
                
                if verbose:
                    print(f"âœ“ äºˆæ¸¬ãƒ†ã‚¹ãƒˆå®Œäº†: {predictions.shape}")
                    print(f"  äºˆæ¸¬ç¯„å›²: ({predictions.min():.3f}, {predictions.max():.3f})")
            
            except Exception as e:
                if verbose:
                    print(f"âš  äºˆæ¸¬ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ï¼ˆéè‡´å‘½çš„ï¼‰: {e}")
        
        return True
        
    except Exception as e:
        if verbose:
            print(f"âœ— çµ±åˆãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            if len(str(e)) < 200:  # çŸ­ã„ã‚¨ãƒ©ãƒ¼ã®ã¿è©³ç´°è¡¨ç¤º
                traceback.print_exc()
        return False

def main():
    parser = argparse.ArgumentParser(description="ææ¡ˆæ‰‹æ³•çµ±åˆãƒ†ã‚¹ãƒˆ")
    parser.add_argument('--quick', action='store_true', help='é«˜é€Ÿãƒ†ã‚¹ãƒˆï¼ˆçŸ­ç¸®ç‰ˆï¼‰')
    parser.add_argument('--full', action='store_true', help='å®Œå…¨ãƒ†ã‚¹ãƒˆ')
    parser.add_argument('--debug', action='store_true', help='ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ï¼ˆè©³ç´°å‡ºåŠ›ï¼‰')
    parser.add_argument('--config', type=str, default='_tests/test_config.yaml', 
                       help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    args = parser.parse_args()
    
    # ãƒ¢ãƒ¼ãƒ‰è¨­å®š
    if args.debug:
        verbose = True
        torch.autograd.set_detect_anomaly(True)
        print("ğŸ”§ ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: è©³ç´°å‡ºåŠ›ãƒ»ç•°å¸¸æ¤œå‡ºæœ‰åŠ¹")
    else:
        verbose = not args.quick
    
    if args.quick:
        print("ğŸš€ é«˜é€Ÿãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰")
    elif args.full:
        print("ğŸ¯ å®Œå…¨ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰")
    
    print("ææ¡ˆæ‰‹æ³• çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 50)
    
    # ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
    if not check_dependencies():
        return 1
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ãƒã‚§ãƒƒã‚¯
    if not check_project_structure():
        return 1
    
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
    config_path = Path(args.config)
    if not config_path.is_absolute():
        config_path = PROJECT_ROOT / config_path
        
    if not config_path.exists():
        print(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}")
        print("_tests/test_config.yaml ã‚’ä½œæˆã—ã¦ãã ã•ã„")
        return 1
    
    print(f"ğŸ“‹ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: {config_path.relative_to(PROJECT_ROOT)}")
    
    # çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    try:
        success = test_integration_pipeline(str(config_path), args.quick, verbose)
        
        print("\n" + "=" * 50)
        if success:
            print("ğŸ‰ çµ±åˆãƒ†ã‚¹ãƒˆæˆåŠŸï¼")
            print("æœ¬æ ¼å®Ÿé¨“ã®æº–å‚™ãŒã§ãã¾ã—ãŸã€‚")
            
            if args.quick:
                print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
                print("  python _tests/test_integration.py --full  # å®Œå…¨ãƒ†ã‚¹ãƒˆ")
                print("  python main_two_stage.py --config configs/config_two_stage_experiment.yaml --data data/sim_complex.npz --output results/exp1")
            
            return 0
        else:
            print("âŒ çµ±åˆãƒ†ã‚¹ãƒˆå¤±æ•—")
            print("ä¸Šè¨˜ã®ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã—ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            
            if not verbose:
                print("\nè©³ç´°ç¢ºèª:")
                print("  python _tests/test_integration.py --debug")
            
            return 1
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ ãƒ†ã‚¹ãƒˆä¸­æ–­")
        return 1
    except Exception as e:
        print(f"\nğŸ’¥ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        if args.debug:
            traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit(main())