# configs/inference_config.yaml
# 推論専用設定ファイル

# ==========================================
# モデル読み込み設定
# ==========================================
model:
  trained_model_path: "models/trained_model.pth"
  device: "auto"  # "cpu", "cuda", "auto"

# ==========================================
# フィルタリング設定
# ==========================================
filtering:
  # ノイズ推定設定
  noise_estimation:
    method: "residual_based"  # 式45-46
    gamma_Q: 1.0e-6          # Q行列正則化
    gamma_R: 1.0e-6          # R行列正則化
    use_calibration: true    # キャリブレーションデータ使用

  # 初期化設定
  initialization:
    method: "data_driven"    # 初期状態推定法 ("data_driven" | "zero")
    n_init_samples: 50       # 初期化用サンプル数

# ==========================================
# ストリーミング設定
# ==========================================
streaming:
  buffer_size: 100           # 内部バッファサイズ
  batch_processing: false    # バッチ処理フラグ
  anomaly_detection: true    # 異常検知有効化
  anomaly_threshold: 3.0     # 異常検知閾値（標準偏差倍数）

# ==========================================
# 数値安定性設定
# ==========================================
numerical:
  condition_threshold: 1.0e12  # 条件数閾値
  min_eigenvalue: 1.0e-8       # 最小固有値
  jitter: 1.0e-6               # ジッター項

# ==========================================
# 出力設定
# ==========================================
output:
  save_states: true          # 状態系列保存
  save_covariances: false    # 共分散保存（メモリ節約）
  save_likelihoods: true     # 尤度保存

---
# configs/config_with_inference.yaml  
# 学習+推論統合設定

# 既存の学習設定を継承
<<: *training_config

# ==========================================
# 推論拡張設定
# ==========================================
inference:
  # モデル読み込み設定
  model:
    trained_model_path: "models/trained_model.pth"
    device: "auto"

  # フィルタリング設定
  filtering:
    noise_estimation:
      method: "residual_based"
      gamma_Q: 1.0e-6
      gamma_R: 1.0e-6
      use_calibration: true
    initialization:
      method: "data_driven"
      n_init_samples: 50

  # ストリーミング設定
  streaming:
    buffer_size: 100
    batch_processing: false
    anomaly_detection: true
    anomaly_threshold: 3.0

  # 数値安定性設定
  numerical:
    condition_threshold: 1.0e12
    min_eigenvalue: 1.0e-8
    jitter: 1.0e-6

  # 出力設定
  output:
    save_states: true
    save_covariances: false
    save_likelihoods: true

# ==========================================
# 学習後の自動推論設定
# ==========================================
post_training:
  auto_inference_setup: true     # 推論環境自動セットアップ
  calibration_ratio: 0.1         # 学習データの一部をキャリブレーション用に
  save_inference_ready: true     # 推論用モデル自動保存

# ==========================================
# Kalman Filtering統合設定
# ==========================================
training:
  # 既存設定を継承
  <<: *base_training

  # Kalman拡張
  kalman_filtering:
    enabled: true               # Kalman Filtering有効化
    start_after_epoch: 10       # Phase-1の何エポック後に開始
    calibration_ratio: 0.1      # キャリブレーション用データ比率
    fallback_on_failure: true   # 失敗時のフォールバック

---
# configs/deployment_config.yaml
# デプロイメント用設定

# ==========================================
# 本番環境設定
# ==========================================
deployment:
  # 環境設定
  environment: "production"    # "development" | "staging" | "production" 
  device: "cpu"               # 本番環境では通常CPU
  max_memory_mb: 1024         # 最大メモリ使用量

  # パフォーマンス設定
  performance:
    batch_size: 1             # リアルタイム処理用
    threading: false          # マルチスレッド無効
    optimization: "speed"     # "speed" | "memory"

  # ロギング設定
  logging:
    level: "INFO"             # "DEBUG" | "INFO" | "WARNING" | "ERROR"
    save_diagnostics: true    # 診断情報保存
    log_file: "inference.log"

  # セキュリティ設定
  security:
    validate_inputs: true     # 入力検証
    sanitize_outputs: true    # 出力サニタイズ
    rate_limiting: true       # レート制限

# ==========================================
# API設定
# ==========================================
api:
  # エンドポイント設定
  endpoints:
    health_check: "/health"
    batch_inference: "/inference/batch"
    streaming_inference: "/inference/stream"
    predictions: "/predictions"

  # タイムアウト設定
  timeouts:
    request_timeout: 30       # リクエストタイムアウト（秒）
    processing_timeout: 60    # 処理タイムアウト（秒）

  # レスポンス設定
  response:
    include_uncertainty: true  # 不確実性情報含む
    include_diagnostics: false # 診断情報含む（本番では無効）
    format: "json"            # "json" | "npz" | "hdf5"

---
# configs/development_config.yaml
# 開発・デバッグ用設定

# ==========================================
# 開発環境設定
# ==========================================
development:
  # デバッグ設定
  debug:
    enabled: true
    verbose_logging: true
    save_intermediate: true   # 中間結果保存
    validate_numerics: true   # 数値検証

  # テスト設定
  testing:
    run_diagnostics: true     # 診断テスト実行
    benchmark_performance: true # パフォーマンステスト
    validate_algorithms: true  # アルゴリズム検証

  # 可視化設定
  visualization:
    auto_plot: true          # 自動プロット生成
    save_plots: true         # プロット保存
    plot_format: "png"       # プロット形式

# ==========================================
# 実験設定
# ==========================================
experiments:
  # パラメータスイープ
  parameter_sweep:
    enabled: false
    parameters:
      gamma_Q: [1e-7, 1e-6, 1e-5]
      gamma_R: [1e-7, 1e-6, 1e-5]
      anomaly_threshold: [2.0, 3.0, 4.0]

  # 比較実験
  comparison:
    methods: ["deterministic", "kalman", "both"]
    metrics: ["mse", "likelihood", "coverage"]
    cross_validation: true

# ==========================================
# プロファイリング設定
# ==========================================
profiling:
  enabled: true
  memory_profiling: true
  time_profiling: true
  gpu_profiling: false      # 開発環境ではCPUのみ

---
# configs/quick_test_config.yaml
# クイックテスト用最小設定

# 最小限の設定（テスト・デバッグ用）
model:
  encoder:
    input_dim: 7
    channels: 32      # 小さくして高速化
    layers: 3

  decoder:
    output_dim: 7
    hidden: 32

ssm:
  realization:
    past_horizon: 10  # 小さくして高速化
    rank: 3

  df_state:
    feature_dim: 16   # 小さくして高速化

  df_observation:
    obs_feature_dim: 8

training:
  phase1:
    epochs: 5         # 少なくして高速化
    T1_iterations: 2
    T2_iterations: 1

  phase2:
    epochs: 5

  kalman_filtering:
    enabled: true
    calibration_ratio: 0.2  # 多めに確保

inference:
  filtering:
    noise_estimation:
      gamma_Q: 1.0e-5  # 大きめで安定化
      gamma_R: 1.0e-5

  streaming:
    buffer_size: 20   # 小さくしてメモリ節約

  numerical:
    jitter: 1.0e-5    # 大きめで安定化

---
# configs/benchmarking_config.yaml
# ベンチマーク・評価用設定

benchmarking:
  # データセット設定
  datasets:
    - name: "ETTm1"
      path: "data/ETTm1.npz"
      split_ratio: [0.7, 0.2, 0.1]  # train/val/test
    - name: "ETTh1"
      path: "data/ETTh1.npz"
      split_ratio: [0.7, 0.2, 0.1]

  # 評価指標
  metrics:
    forecasting:
      - "mse"
      - "mae"
      - "mape"
      - "smape"
    uncertainty:
      - "coverage_95"
      - "interval_width"
      - "calibration_error"
    computational:
      - "inference_time"
      - "memory_usage"
      - "throughput"

  # 比較手法
  baselines:
    - "deterministic_realization"
    - "linear_kalman"
    - "extended_kalman"
    - "particle_filter"

  # 実験設定
  experiments:
    forecast_horizons: [1, 6, 12, 24, 48]
    noise_levels: [0.01, 0.05, 0.1, 0.2]
    sequence_lengths: [100, 500, 1000, 2000]

  # 出力設定
  output:
    save_results: true
    result_format: "json"
    create_report: true
    report_format: "html"