# ===== src/training/two_stage_trainer.py å®Œå…¨ä¿®æ­£ç‰ˆ =====
# ä¿®æ­£1-4çµ±åˆ: æ™‚é–“èª¿æ•´ + è¨ˆç®—ã‚°ãƒ©ãƒ•åˆ†é›¢ + ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°

"""
TwoStageTrainer: ææ¡ˆæ‰‹æ³•ã®2æ®µéšå­¦ç¿’æˆ¦ç•¥å®Ÿè£…

Phase-1: DF-A/DF-B ã® Stage-1/Stage-2 äº¤äº’å­¦ç¿’
Phase-2: End-to-end å¾®èª¿æ•´

å­¦ç¿’æˆ¦ç•¥:
**DF-A (State Layer)**:
for epoch in Phase1:
  for t = 1 to T1:  # Stage-1
    V_A^{(-k)} = é–‰å½¢å¼è§£(Î¦_minus, Î¦_plus, Ï•_Î¸å›ºå®š)
    Ï•_Î¸ â† Ï•_Î¸ - Î±âˆ‡L1(V_A^{(-k)}, Ï•_Î¸)  # Ï•_Î¸æ›´æ–°
 
  for t = 1 to T2:  # Stage-2
    U_A = é–‰å½¢å¼è§£(H^{(cf)}_A, X_+)        # U_Aæ›´æ–°ï¼ˆé–‰å½¢å¼è§£ã®ã¿ï¼‰

**DF-B (Observation Layer)**:
for epoch in Phase1:
  for t = 1 to T1:  # Stage-1
    V_B = é–‰å½¢å¼è§£(Î¦_prev, Î¨_curr)       # V_Bè¨ˆç®—ï¼ˆÏˆ_Ï‰å›ºå®šï¼‰
    Ï•_Î¸ â† Ï•_Î¸ - Î±âˆ‡L1(V_B, Ï•_Î¸)         # Ï•_Î¸æ›´æ–°ï¼ˆÏˆ_Ï‰å›ºå®šï¼‰
 
  for t = 1 to T2:  # Stage-2 
    u_B = é–‰å½¢å¼è§£(H^{(cf)}_B, m)        # u_Bè¨ˆç®—ï¼ˆÏ•_Î¸å›ºå®šï¼‰
    Ïˆ_Ï‰ â† Ïˆ_Ï‰ - Î±âˆ‡L2(u_B, Ïˆ_Ï‰)         # Ïˆ_Ï‰æ›´æ–°ï¼ˆÏ•_Î¸å›ºå®šï¼‰

Phase-2: End-to-endå¾®èª¿æ•´
for epoch in Phase2:
  # æ¨è«–ãƒ‘ã‚¹å›ºå®š
  xÌ‚_{t|t-1} = U_A^T V_A Ï•_Î¸(x_{t-1})
  mÌ‚_{t|t-1} = u_B^T V_B Ï•_Î¸(xÌ‚_{t|t-1})
  Å·_{t|t-1} = g_Î±(mÌ‚_{t|t-1})
 
  # æå¤±
  L_total = L_rec + Î»_c L_cca
 
  # é¸æŠçš„æ›´æ–°
  (u_Î·, g_Î±, Ï•_Î¸, Ïˆ_Ï‰).backward()
"""

import numpy as np
import torch
import torch.nn as nn
from typing import Dict, Any, Optional, List, Tuple
import warnings
from pathlib import Path
import json
import csv
from dataclasses import dataclass
from enum import Enum
import gc

# ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from ..ssm.df_state_layer import DFStateLayer
from ..ssm.df_observation_layer import DFObservationLayer
from ..ssm.realization import Realization, RealizationError
from ..models.architectures.tcn import tcnEncoder, tcnDecoder


class TrainingPhase(Enum):
    """å­¦ç¿’ãƒ•ã‚§ãƒ¼ã‚ºã®å®šç¾©"""
    PHASE1_DF_A = "phase1_df_a"
    PHASE1_DF_B = "phase1_df_b"
    PHASE2_E2E = "phase2_e2e"


@dataclass
class TrainingConfig:
    """å­¦ç¿’è¨­å®šã®æ§‹é€ åŒ–"""
    # Phase-1è¨­å®š
    phase1_epochs: int = 50
    T1_iterations: int = 10  # Stage-1åå¾©æ•°
    T2_iterations: int = 5   # Stage-2åå¾©æ•°
    df_a_warmup_epochs: int = 5  # DF-Bã‚’é–‹å§‹ã™ã‚‹å‰ã®DF-Aã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
    
    # Phase-2è¨­å®š
    phase2_epochs: int = 100
    lambda_cca: float = 0.1
    update_strategy: str = "all"  # "all" or "encoder_decoder_only"
    
    # å­¦ç¿’ç‡
    lr_phi: float = 1e-3     # Ï†_Î¸ (çŠ¶æ…‹ç‰¹å¾´) å­¦ç¿’ç‡
    lr_psi: float = 1e-3     # Ïˆ_Ï‰ (è¦³æ¸¬ç‰¹å¾´) å­¦ç¿’ç‡
    lr_encoder: float = 1e-4 # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å­¦ç¿’ç‡
    lr_decoder: float = 1e-4 # ãƒ‡ã‚³ãƒ¼ãƒ€å­¦ç¿’ç‡
    
    # ãƒ­ã‚°ãƒ»ä¿å­˜è¨­å®š
    log_interval: int = 5    # ãƒ­ã‚°å‡ºåŠ›é–“éš”ï¼ˆã‚¨ãƒãƒƒã‚¯ï¼‰
    save_interval: int = 10  # ãƒ¢ãƒ‡ãƒ«ä¿å­˜é–“éš”ï¼ˆã‚¨ãƒãƒƒã‚¯ï¼‰
    verbose: bool = True     # è©³ç´°ãƒ­ã‚°
    
    def __post_init__(self):
        """åˆæœŸåŒ–å¾Œã®å‹å¤‰æ›ã¨æ¤œè¨¼"""
        # æ•°å€¤å‹ã®ç¢ºå®Ÿãªå¤‰æ›ï¼ˆYAMLèª­ã¿è¾¼ã¿å¯¾ç­–ï¼‰
        self.phase1_epochs = int(self.phase1_epochs)
        self.T1_iterations = int(self.T1_iterations)
        self.T2_iterations = int(self.T2_iterations)
        self.df_a_warmup_epochs = int(self.df_a_warmup_epochs)
        self.phase2_epochs = int(self.phase2_epochs)
        self.log_interval = int(self.log_interval)
        self.save_interval = int(self.save_interval)
        
        # å­¦ç¿’ç‡ã®å‹å¤‰æ›
        self.lr_phi = float(self.lr_phi)
        self.lr_psi = float(self.lr_psi)
        self.lr_encoder = float(self.lr_encoder)
        self.lr_decoder = float(self.lr_decoder)
        self.lambda_cca = float(self.lambda_cca)
        
        # æ–‡å­—åˆ—å‹ã®æ­£è¦åŒ–
        self.update_strategy = str(self.update_strategy)
        
        # çœŸå½å€¤ã®å¤‰æ›ï¼ˆ"true"/"false"æ–‡å­—åˆ—å¯¾ç­–ï¼‰
        if isinstance(self.verbose, str):
            self.verbose = self.verbose.lower() in ('true', '1', 'yes', 'on')
        else:
            self.verbose = bool(self.verbose)

    @classmethod
    def from_nested_dict(cls, config_dict: Dict[str, Any]) -> 'TrainingConfig':
        """å…¥ã‚Œå­è¨­å®šè¾æ›¸ã‹ã‚‰å¹³å¦ãªTrainingConfigã‚’ä½œæˆ"""
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
        phase1_config = config_dict.get('phase1', {})
        phase2_config = config_dict.get('phase2', {})
        
        return cls(
            # Phase-1è¨­å®š
            phase1_epochs=phase1_config.get('epochs', 50),
            T1_iterations=phase1_config.get('T1_iterations', 10),
            T2_iterations=phase1_config.get('T2_iterations', 5),
            df_a_warmup_epochs=phase1_config.get('df_a', {}).get('warmup_epochs', 5),
            
            # Phase-2è¨­å®š
            phase2_epochs=phase2_config.get('epochs', 100),
            lambda_cca=phase2_config.get('lambda_cca', 0.1),
            update_strategy=phase2_config.get('update_strategy', "all"),
            
            # å­¦ç¿’ç‡ï¼ˆPhase-2å†…ã¾ãŸã¯ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã‹ã‚‰å–å¾—ï¼‰
            lr_phi=phase2_config.get('lr_phi', phase1_config.get('df_a', {}).get('lr', 1e-3)),
            lr_psi=phase2_config.get('lr_psi', phase1_config.get('df_b', {}).get('lr', 1e-3)),
            lr_encoder=phase2_config.get('lr_encoder', 1e-4),
            lr_decoder=phase2_config.get('lr_decoder', 1e-4),
            
            # ãƒ­ã‚°ãƒ»ä¿å­˜è¨­å®šï¼ˆãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã‹ã‚‰ï¼‰
            log_interval=config_dict.get('log_interval', 5),
            save_interval=config_dict.get('checkpoint', {}).get('save_every', 10),
            verbose=config_dict.get('verbose', True)
        )


class TrainingLogger:
    """å­¦ç¿’ãƒ­ã‚°ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    def __init__(self, output_dir: Path):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        self.phase1_csv_path = self.output_dir / 'phase1_training.csv'
        self.phase2_csv_path = self.output_dir / 'phase2_training.csv'
        
        # ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿
        self.phase1_logs = []
        self.phase2_logs = []
        
        # CSVåˆæœŸåŒ–
        self._initialize_csv_files()
    
    def _initialize_csv_files(self):
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ˜ãƒƒãƒ€ãƒ¼åˆæœŸåŒ–"""
        # Phase-1 CSV
        with open(self.phase1_csv_path, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([
                'epoch', 'phase', 'stage', 'iteration', 'loss', 
                'lr_phi', 'lr_psi'
            ])
        
        # Phase-2 CSV
        with open(self.phase2_csv_path, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([
                'epoch', 'total_loss', 'rec_loss', 'cca_loss',
                'lr_encoder', 'lr_decoder', 'lr_phi', 'lr_psi'
            ])
    
    def log_phase1(self, epoch: int, phase: TrainingPhase, stage: str, 
                   iteration: int, metrics: Dict[str, float], 
                   learning_rates: Dict[str, float]):
        """Phase-1ãƒ­ã‚°è¨˜éŒ²"""
        log_entry = {
            'epoch': epoch,
            'phase': phase.value,
            'stage': stage,
            'iteration': iteration,
            'metrics': metrics,
            'learning_rates': learning_rates
        }
        
        self.phase1_logs.append(log_entry)
        
        # CSVæ›¸ãè¾¼ã¿
        with open(self.phase1_csv_path, 'a', newline='') as f:
            writer = csv.writer(f)
            loss_value = metrics.get('stage1_loss') or metrics.get('stage2_loss', '')
            writer.writerow([
                epoch, phase.value, stage, iteration, loss_value,
                learning_rates.get('lr_phi', ''),
                learning_rates.get('lr_psi', '')
            ])
    
    def log_phase2(self, epoch: int, total_loss: float, rec_loss: float, 
                   cca_loss: float, learning_rates: Dict[str, float]):
        """Phase-2ãƒ­ã‚°è¨˜éŒ²"""
        log_entry = {
            'epoch': epoch,
            'total_loss': total_loss,
            'rec_loss': rec_loss,
            'cca_loss': cca_loss,
            'learning_rates': learning_rates
        }
        
        self.phase2_logs.append(log_entry)
        
        # CSVæ›¸ãè¾¼ã¿
        with open(self.phase2_csv_path, 'a', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([
                epoch, total_loss, rec_loss, cca_loss,
                learning_rates.get('lr_encoder', ''),
                learning_rates.get('lr_decoder', ''),
                learning_rates.get('lr_phi', ''),
                learning_rates.get('lr_psi', '')
            ])
    
    def save_summary(self):
        """å­¦ç¿’ã‚µãƒãƒªã‚’JSONã§ä¿å­˜"""
        summary = {
            'phase1_summary': {
                'total_epochs': len(set(log['epoch'] for log in self.phase1_logs)),
                'total_iterations': len(self.phase1_logs),
                'final_metrics': self.phase1_logs[-1]['metrics'] if self.phase1_logs else {}
            },
            'phase2_summary': {
                'total_epochs': len(self.phase2_logs),
                'final_loss': self.phase2_logs[-1]['total_loss'] if self.phase2_logs else None
            }
        }
        
        with open(self.output_dir / 'training_summary.json', 'w') as f:
            json.dump(summary, f, indent=2)


class TwoStageTrainer:
    """
    ææ¡ˆæ‰‹æ³•ã®2æ®µéšå­¦ç¿’æˆ¦ç•¥ã‚’å®Ÿè¡Œã™ã‚‹ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹
    
    çµ±åˆçš„ãªå­¦ç¿’ç®¡ç†:
    1. Phase-1: DF-A/DF-B ã®å”èª¿å­¦ç¿’
    2. Phase-2: End-to-endå¾®èª¿æ•´
    3. å­¦ç¿’éç¨‹ã®è©³ç´°ãƒ­ã‚°ãƒ»å¯è¦–åŒ–
    4. æ™‚é–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª¿æ•´ã¨ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
    """
    
    def __init__(self, encoder: nn.Module = None, decoder: nn.Module = None, realization: Realization = None,
                 df_state_config: Dict[str, Any] = None, df_obs_config: Dict[str, Any] = None,
                 training_config: TrainingConfig = None, device: torch.device = None, output_dir: str = None,
                 use_kalman_filtering: bool = True,
                calibration_ratio: float = 0.1,
                auto_inference_setup: bool = True,
                config: Dict[str, Any] = None):
        
        # configå¼•æ•°ãŒæ¸¡ã•ã‚ŒãŸå ´åˆã¯è¨­å®šã‹ã‚‰åˆæœŸåŒ–
        if config is not None:
            self._init_from_config(config, device, output_dir, use_kalman_filtering)
        else:
            # å¾“æ¥ã®å€‹åˆ¥å¼•æ•°ã‹ã‚‰ã®åˆæœŸåŒ–
            self._init_from_args(encoder, decoder, realization, df_state_config, df_obs_config,
                               training_config, device, output_dir, use_kalman_filtering,
                               calibration_ratio, auto_inference_setup)
    
    def _init_from_config(self, config: Dict[str, Any], device: torch.device, output_dir: str, 
                         use_kalman_filtering: bool):
        """è¨­å®šè¾æ›¸ã‹ã‚‰ã®åˆæœŸåŒ–"""
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        encoder = tcnEncoder(**config['model']['encoder'])
        decoder = tcnDecoder(**config['model']['decoder'])
        realization = Realization(**config['ssm']['realization'])
        
        # è¨­å®šå¤‰æ›
        training_config = TrainingConfig.from_nested_dict(config['training'])
        
        # å€‹åˆ¥å¼•æ•°ã§ã®åˆæœŸåŒ–ã«å§”è­²
        self._init_from_args(encoder, decoder, realization,
                           config['ssm']['df_state'], config['ssm']['df_observation'],
                           training_config, device, output_dir, use_kalman_filtering)

    @classmethod
    def from_trained_model(cls, model_path: str, device: torch.device = None,
                          output_dir: str = None) -> 'TwoStageTrainer':
        """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰æ¨è«–å°‚ç”¨ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¸è¦ï¼‰"""
        if device is None:
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        if output_dir is None:
            output_dir = 'temp_inference'

        # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        checkpoint = torch.load(model_path, map_location=device)
        if 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
        else:
            state_dict = checkpoint

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰æ§‹é€ æ¤œå‡º
        encoder_config = cls._detect_encoder_structure(state_dict.get('encoder', {}))
        decoder_config = cls._detect_decoder_structure(state_dict.get('decoder', {}))

        # æ¤œå‡ºã•ã‚ŒãŸæ§‹é€ ã§ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        encoder = tcnEncoder(**encoder_config)
        decoder = tcnDecoder(**decoder_config)

        # æœ€å°é™ã®è¨­å®šã§åˆæœŸåŒ–
        realization = Realization(past_horizon=10, rank=3)
        df_state_config = {'feature_dim': 16}
        df_obs_config = {'obs_feature_dim': 8}
        training_config = TrainingConfig()

        # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        instance = cls._init_from_args_direct(
            encoder, decoder, realization, df_state_config, df_obs_config,
            training_config, device, output_dir, use_kalman_filtering=False
        )

        # é‡ã¿ã‚’èª­ã¿è¾¼ã¿
        instance.encoder.load_state_dict(state_dict.get('encoder', {}))
        instance.decoder.load_state_dict(state_dict.get('decoder', {}))

        return instance

    @classmethod
    def _detect_encoder_structure(cls, encoder_dict: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰æ§‹é€ æ¤œå‡º"""
        # channelsæ¤œå‡º
        channels = 32  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        if 'in_proj.weight' in encoder_dict:
            channels = encoder_dict['in_proj.weight'].shape[0]

        # layersæ¤œå‡º
        layers = 3  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        tcn_layers = [int(k.split('.')[1]) for k in encoder_dict.keys()
                     if k.startswith('tcn.') and '.conv.weight' in k]
        if tcn_layers:
            layers = max(tcn_layers) + 1

        # input_dimæ¤œå‡º
        input_dim = 6  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        if 'in_proj.weight' in encoder_dict:
            input_dim = encoder_dict['in_proj.weight'].shape[1]

        return {
            'input_dim': input_dim,
            'channels': channels,
            'layers': layers,
            'kernel_size': 3,
            'activation': 'GELU',
            'dropout': 0.1
        }

    @classmethod
    def _detect_decoder_structure(cls, decoder_dict: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰æ§‹é€ æ¤œå‡º"""
        # output_dimæ¤œå‡º
        output_dim = 6  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        if 'out_proj.weight' in decoder_dict:
            output_dim = decoder_dict['out_proj.weight'].shape[0]

        # hiddenæ¤œå‡º
        hidden = 32  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        if 'takens_proj.weight' in decoder_dict:
            hidden = decoder_dict['takens_proj.weight'].shape[0]

        return {
            'output_dim': output_dim,
            'window': 8,
            'tau': 1,
            'hidden': hidden,
            'ma_kernel': 16,
            'gru_hidden': 16,
            'activation': 'GELU',
            'dropout': 0.1
        }

    @classmethod
    def _init_from_args_direct(cls, encoder, decoder, realization, df_state_config,
                              df_obs_config, training_config, device, output_dir,
                              use_kalman_filtering):
        """ç›´æ¥åˆæœŸåŒ–ï¼ˆã‚¯ãƒ©ã‚¹ãƒ¡ã‚½ãƒƒãƒ‰ç”¨ï¼‰"""
        instance = cls.__new__(cls)
        instance._init_from_args(encoder, decoder, realization, df_state_config,
                               df_obs_config, training_config, device, output_dir,
                               use_kalman_filtering, calibration_ratio=0.1,
                               auto_inference_setup=False)
        return instance
    
    def _init_from_args(self, encoder: nn.Module, decoder: nn.Module, realization: Realization,
                       df_state_config: Dict[str, Any], df_obs_config: Dict[str, Any],
                       training_config: TrainingConfig, device: torch.device, output_dir: str,
                       use_kalman_filtering: bool, calibration_ratio: float = 0.1,
                       auto_inference_setup: bool = True):
        """å€‹åˆ¥å¼•æ•°ã‹ã‚‰ã®åˆæœŸåŒ–"""
        # åŸºæœ¬è¨­å®š
        self.encoder = encoder.to(device)
        self.decoder = decoder.to(device)
        self.realization = realization
        self.config = training_config
        self.device = device
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # **ä¿®æ­£4: æ™‚é–“èª¿æ•´ç”¨ã®çŠ¶æ…‹ç®¡ç†**
        self._last_X_states_length = None  # çŠ¶æ…‹ç³»åˆ—é•·ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        
        # ===== è¿½åŠ ï¼šKalmané–¢é€£è¨­å®š =====
        self.use_kalman_filtering = use_kalman_filtering
        self.calibration_ratio = calibration_ratio
        self.auto_inference_setup = auto_inference_setup
        
        # ===== è¿½åŠ ï¼šKalmanç”¨ãƒ‡ãƒ¼ã‚¿ =====
        self.calibration_data: Optional[torch.Tensor] = None
        self.inference_model: Optional[Any] = None

        # DF layersè¨­å®šä¿å­˜
        self.df_state_config = df_state_config
        self.df_obs_config = df_obs_config
        
        # å­¦ç¿’çŠ¶æ…‹
        self.df_state = None
        self.df_obs = None
        self.optimizers = {}
        self.current_epoch = 0
        self.phase1_complete = False
        
        # å­¦ç¿’å±¥æ­´
        self.training_history = {
            'phase1_metrics': [],
            'phase2_losses': []
        }
        
        # ä¸€æ™‚ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        self._temp_data = {}
        
        # ãƒ­ã‚°ç®¡ç†
        self.logger = TrainingLogger(self.output_dir)
        
        print(f"TwoStageTraineråˆæœŸåŒ–å®Œäº†: {device}")
    
    def _initialize_df_layers(self, X_states: torch.Tensor):
        """DF layersåˆæœŸåŒ–ï¼ˆGPUçµ±ä¸€ç‰ˆï¼‰"""
        # DF-AåˆæœŸåŒ–
        _, r = X_states.shape
        self.df_state = DFStateLayer(
            state_dim=r,
            feature_dim=self.df_state_config['feature_dim'],
            lambda_A=self.df_state_config['lambda_A'],
            lambda_B=self.df_state_config['lambda_B'],
            feature_net_config=self.df_state_config.get('feature_net'),
            cross_fitting_config=self.df_state_config.get('cross_fitting')
        )
        
        # DF-Aã®å†…éƒ¨ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’GPUã«ç§»å‹•
        self.df_state.phi_theta = self.df_state.phi_theta.to(self.device)
        
        # DF-BåˆæœŸåŒ–
        self.df_obs = DFObservationLayer(
            df_state_layer=self.df_state,
            obs_feature_dim=self.df_obs_config['obs_feature_dim'],
            lambda_B=self.df_obs_config['lambda_B'],
            lambda_dB=self.df_obs_config['lambda_dB'],
            obs_net_config=self.df_obs_config.get('obs_net'),
            cross_fitting_config=self.df_obs_config.get('cross_fitting')
        )
        # DF-Bã®å†…éƒ¨ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’GPUã«ç§»å‹•
        self.df_obs.psi_omega = self.df_obs.psi_omega.to(self.device)
        
        print(f"DF layersåˆæœŸåŒ–å®Œäº†: state_dim={r}")
    
    def _initialize_optimizers(self):
        """æœ€é©åŒ–å™¨åˆæœŸåŒ–"""
        # Phase-1ç”¨ã®å€‹åˆ¥æœ€é©åŒ–å™¨
        self.optimizers['phi'] = torch.optim.Adam(
            self.df_state.phi_theta.parameters(), 
            lr=self.config.lr_phi
        )
        
        self.optimizers['psi'] = torch.optim.Adam(
            self.df_obs.psi_omega.parameters(), 
            lr=self.config.lr_psi
        )
        
        # Phase-2ç”¨ã®çµ±åˆæœ€é©åŒ–å™¨
        if self.config.update_strategy == "all":
            # å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°
            phase2_params = list(self.encoder.parameters()) + \
                           list(self.decoder.parameters()) + \
                           list(self.df_state.phi_theta.parameters()) + \
                           list(self.df_obs.psi_omega.parameters())
        else:
            # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ»ãƒ‡ã‚³ãƒ¼ãƒ€ã®ã¿æ›´æ–°
            phase2_params = list(self.encoder.parameters()) + \
                           list(self.decoder.parameters())
        
        self.optimizers['e2e'] = torch.optim.Adam([
            {'params': self.encoder.parameters(), 'lr': self.config.lr_encoder},
            {'params': self.decoder.parameters(), 'lr': self.config.lr_decoder},
            {'params': self.df_state.phi_theta.parameters(), 'lr': self.config.lr_phi},
            {'params': self.df_obs.psi_omega.parameters(), 'lr': self.config.lr_psi}
        ])
        
        print("æœ€é©åŒ–å™¨åˆæœŸåŒ–å®Œäº†")
    
    def _prepare_data(self, Y_train: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        **ä¿®æ­£4çµ±åˆ**: ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆçŠ¶æ…‹ç³»åˆ—é•·ã®è¨˜éŒ²ä»˜ãï¼‰
        """
        # 1. ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰: y_t â†’ m_t
        # ãƒãƒƒãƒæ¬¡å…ƒè¿½åŠ : (T, d) -> (1, T, d)

        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’GPUã«ç§»å‹•
        Y_train = self._ensure_device(Y_train)

        m_tensor = self.encoder(Y_train.unsqueeze(0))  # (1, T, 1)
        m_series = m_tensor.squeeze()  # (T,)
        
        if m_series.dim() == 0:  # ã‚¹ã‚«ãƒ©ãƒ¼ã®å ´åˆ
            m_series = m_series.unsqueeze(0)
        
        # ===== è¿½åŠ ï¼šã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿åˆ†å‰² =====
        if hasattr(self, 'use_kalman_filtering') and self.use_kalman_filtering:
            n_calib = int(Y_train.size(0) * getattr(self, 'calibration_ratio', 0.1))
            self.calibration_data = Y_train[:n_calib].clone()
            if self.config.verbose:
                print(f"Calibration data prepared: {self.calibration_data.shape}")
        
        if self.config.verbose:
            print(f"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å®Œäº†: {Y_train.shape} -> {m_series.shape}")
        
        # 2. ç¢ºç‡çš„å®Ÿç¾: m_t â†’ x_t
        try:
            self.realization.fit(m_series.unsqueeze(1))  # (T,) -> (T, 1)
        except RealizationError as e:
            print(f"âš ï¸ RealizationErrorç™ºç”Ÿ: {e}")
            # RealizationErrorã‚’ä¸Šä½ã«å†æŠ•ã’ã—ã¦å®Œå…¨ã‚¨ãƒãƒƒã‚¯ã‚¹ã‚­ãƒƒãƒ—ã‚’å®Ÿè¡Œ
            raise RealizationError(f"Phase1 realization failed: {e}") from e

        # ===== è¿½åŠ ï¼šKalmanä½¿ç”¨æ™‚ã®åˆ†å²å‡¦ç† =====
        if (hasattr(self, 'use_kalman_filtering') and self.use_kalman_filtering and 
            hasattr(self, 'phase1_complete') and self.phase1_complete and
            hasattr(self, 'df_state') and self.df_state is not None and
            hasattr(self, 'df_obs') and self.df_obs is not None):
            
            try:
                X_means, X_covariances = self.realization.filter_with_kalman(
                    m_series, self.df_state, self.df_obs
                )
                if self.config.verbose:
                    print(f"Kalman filtering applied: {X_means.shape}")
                
                # ===== é‡è¦ï¼šå…±åˆ†æ•£ã¯å†…éƒ¨ä¿å­˜ã€æˆ»ã‚Šå€¤ã¯æ—¢å­˜å½¢å¼ =====
                self._last_covariances = X_covariances  # æ–°ã—ã„å†…éƒ¨å±æ€§
                X_states = X_means  # æ—¢å­˜å¤‰æ•°åã§è¿”ã™
                
            except Exception as e:
                warnings.warn(f"Kalman filtering failed, using deterministic: {e}")
                X_states = self.realization.filter(m_series.unsqueeze(1))
                self._last_covariances = None
        else:
            # å¾“æ¥ã®æ±ºå®šçš„æ¨å®š
            X_states = self.realization.filter(m_series.unsqueeze(1))  # (T_eff, r)
            self._last_covariances = None
        
        # **ä¿®æ­£4: çŠ¶æ…‹ç³»åˆ—é•·ã‚’è¨˜éŒ²ï¼ˆæ™‚é–“èª¿æ•´ç”¨ï¼‰**
        self._last_X_states_length = X_states.size(0)
        
        if self.config.verbose:
            print(f"çŠ¶æ…‹æ¨å®šå®Œäº†: {m_series.shape} -> {X_states.shape}")
        
        # ä¸€æ™‚ä¿å­˜
        self._temp_data = {
            'Y_train': Y_train,
            'm_series': m_series,
            'X_states': X_states
        }
        
        return m_series, X_states
    
    def train_phase1(self, Y_train: torch.Tensor) -> Dict[str, Any]:
        """
        Phase-1: DF-A/DF-B ã®å”èª¿å­¦ç¿’
        
        Args:
            Y_train: è¨“ç·´è¦³æ¸¬ç³»åˆ— (T, d)
            
        Returns:
            Phase-1ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        """
        print("\n=== Phase-1: DFå­¦ç¿’é–‹å§‹ ===")
        
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        m_series, X_states = self._prepare_data(Y_train)
        
        # DF layersåˆæœŸåŒ–
        self._initialize_df_layers(X_states)
        self._initialize_optimizers()
        
        # Phase-1å­¦ç¿’ãƒ«ãƒ¼ãƒ—
        for epoch in range(self.config.phase1_epochs):
            self.current_epoch = epoch
            epoch_metrics = {}
            
            # DF-Aå­¦ç¿’
            df_a_metrics = self._train_df_a_epoch(X_states, epoch)
            epoch_metrics.update(df_a_metrics)
            
            # DF-Bå­¦ç¿’ï¼ˆã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å¾Œï¼‰
            if epoch >= self.config.df_a_warmup_epochs:
                df_b_metrics = self._train_df_b_epoch(X_states, m_series, epoch)
                epoch_metrics.update(df_b_metrics)
            
            # ãƒ­ã‚°è¨˜éŒ²
            self.training_history['phase1_metrics'].append(epoch_metrics)
            
            # ãƒ­ã‚°å‡ºåŠ›
            if epoch % self.config.log_interval == 0 and self.config.verbose:
                self._print_phase1_progress(epoch, epoch_metrics)
            
            # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
            if epoch % self.config.save_interval == 0:
                self._save_checkpoint(epoch, TrainingPhase.PHASE1_DF_A)
        
        # Phase-1å®Œäº†å¾Œ: DFLayerã®fit()ã§V_A/V_B/U_A/u_Bã‚’è¨ˆç®—
        print("ğŸ”„ æœ€çµ‚ä½œç”¨ç´ ï¼ˆV_A/V_B/U_A/u_Bï¼‰è¨ˆç®—ä¸­...")
        self._compute_final_operators(Y_train)

        self.phase1_complete = True
        print("Phase-1 å­¦ç¿’å®Œäº†")

        return self.training_history['phase1_metrics']

    def _compute_final_operators(self, Y_train: torch.Tensor):
        """Phase-1å®Œäº†å¾Œã«æœ€çµ‚ä½œç”¨ç´ V_A/V_B/U_A/u_Bã‚’è¨ˆç®—"""
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        m_series, X_states = self._prepare_data(Y_train)

        # DFStateLayerç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™
        with torch.no_grad():
            # çŠ¶æ…‹ç‰¹å¾´é‡è¨ˆç®—: Ï†_Î¸(x_t)
            Phi_full = self.df_state.phi_theta(X_states)  # (T, d_A)

            # æ™‚é–“ã‚·ãƒ•ãƒˆã—ãŸãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆå…ƒã®å­¦ç¿’ã¨åŒã˜æ™‚é–“å¯¾å¿œï¼‰
            Phi_minus = Phi_full[:-1]  # Ï†(x_{t-1}): t=0,...,T-2
            Phi_plus = Phi_full[1:]    # Ï†(x_t): t=1,...,T-1
            X_plus = X_states[1:]      # x_{t}: t=1,...,T-1 (å…ƒã®å­¦ç¿’ã¨åŒã˜)

        # DF-A: V_A, U_Aè¨ˆç®—
        print("  ğŸ”„ DF-Aä½œç”¨ç´ ï¼ˆV_A/U_Aï¼‰è¨ˆç®—ä¸­...")
        if hasattr(self.df_state, 'cf_config') and self.df_state.cf_config:
            self.df_state._fit_with_cross_fitting(Phi_minus, Phi_plus, X_plus, verbose=True)
        else:
            self.df_state._fit_without_cross_fitting(Phi_minus, Phi_plus, X_plus, verbose=True)

        print(f"  âœ… V_A shape: {self.df_state.V_A.shape}, U_A shape: {self.df_state.U_A.shape}")

        # DFObservationLayerç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆDF-Aã®çµæœã‚’ä½¿ç”¨ï¼‰
        if hasattr(self, 'df_obs') and self.df_obs is not None:
            print("  ğŸ”„ DF-Bä½œç”¨ç´ ï¼ˆV_B/u_Bï¼‰è¨ˆç®—ä¸­...")

            # DF-Aã«ã‚ˆã‚‹1ã‚¹ãƒ†ãƒƒãƒ—äºˆæ¸¬ã¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å‡ºåŠ›ã®æ­£ã—ã„ä½¿ç”¨
            with torch.no_grad():
                # 1ã‚¹ãƒ†ãƒƒãƒ—äºˆæ¸¬: xÌ‚_{t|t-1} = U_A^T V_A Ï†(x_{t-1})
                X_pred = (self.df_state.U_A.T @ (self.df_state.V_A @ Phi_minus.T)).T  # (T-1, d_x)
                # äºˆæ¸¬ã‚’ç‰¹å¾´é‡åŒ–: Ï†_Î¸(xÌ‚_{t|t-1})
                Phi_pred = self.df_state.phi_theta(X_pred)  # (T-1, d_A)

                # realizationã®æ™‚é–“çŸ­ç¸®ã‚’è€ƒæ…®ã—ãŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å‡ºåŠ›ã®å–å¾—
                # realization: T -> T_eff = T - 2*h + 1ã®çŸ­ç¸®
                h = self.realization.h
                T_states = X_states.shape[0]  # realizationå¾Œã®çŠ¶æ…‹ç³»åˆ—é•·

                # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å‡ºåŠ›h_tã®æ­£ã—ã„ç¯„å›²ï¼ˆrealizationã¨åŒã˜æ™‚é–“ç¯„å›²ï¼‰
                H_curr = m_series[h:h+T_states]  # h_t: realizationç¯„å›²ã¨ä¸€è‡´

                # è¦³æ¸¬ç‰¹å¾´é‡: Ïˆ_Ï‰(h_t)
                Psi_curr = self.df_obs.psi_omega(H_curr.unsqueeze(-1))  # (T_states, d_B)

                # åŒæ™‚åˆ»ã®è¦³æ¸¬
                m_curr = m_series[h:h+T_states]  # m_t

                # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºèª¿æ•´ï¼ˆæœ€å°ã‚µã‚¤ã‚ºã«åˆã‚ã›ã‚‹ï¼‰
                min_size = min(Phi_pred.shape[0], Psi_curr.shape[0], m_curr.shape[0])
                Phi_pred = Phi_pred[:min_size]  # Ï†_Î¸(xÌ‚_{t|t-1})
                Psi_curr = Psi_curr[:min_size]  # Ïˆ_Ï‰(h_t)
                m_curr = m_curr[:min_size]     # m_t

            print(f"    ğŸ“Š DF-Bå­¦ç¿’ãƒ‡ãƒ¼ã‚¿: Phi_pred={Phi_pred.shape}, Psi_curr={Psi_curr.shape}, m_curr={m_curr.shape}")
            print(f"    ğŸ• æ™‚é–“ç¯„å›²: h={h}, T_states={T_states}, range=[{h}:{h+T_states}]")

            # DF-B: V_B, u_Bè¨ˆç®— (Ï†_Î¸(xÌ‚_{t|t-1}) â†’ Ïˆ_Ï‰(h_t)ã®å†™åƒå­¦ç¿’)
            if hasattr(self.df_obs, 'cf_config') and self.df_obs.cf_config:
                self.df_obs._fit_with_cross_fitting(Phi_pred, Psi_curr, m_curr, verbose=True)
            else:
                self.df_obs._fit_without_cross_fitting(Phi_pred, Psi_curr, m_curr, verbose=True)

            print(f"  âœ… V_B shape: {self.df_obs.V_B.shape}, u_B shape: {self.df_obs.u_B.shape}")

        print("ğŸ”„ æœ€çµ‚ä½œç”¨ç´ è¨ˆç®—å®Œäº†")

    def _train_df_a_epoch(self, X_states: torch.Tensor, epoch: int) -> Dict[str, float]:
        """
        **ä¿®æ­£2çµ±åˆ**: DF-Aï¼ˆçŠ¶æ…‹å±¤ï¼‰ã®ã‚¨ãƒãƒƒã‚¯å­¦ç¿’ï¼ˆå®Œå…¨ã‚°ãƒ©ãƒ•åˆ†é›¢ç‰ˆï¼‰
        """
        metrics = {}
        opt_phi = self.optimizers['phi']
        
        # **è¿½åŠ **: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’GPUã«ç§»å‹•
        X_states_gpu = X_states.to(self.device)
        
        # **ä¿®æ­£2: å®Œå…¨ã«ãƒ‡ã‚¿ãƒƒãƒã•ã‚ŒãŸå…¥åŠ›ã§ç‹¬ç«‹ã‚°ãƒ©ãƒ•ä½œæˆ**
        X_states_detached = X_states_gpu.detach().requires_grad_(False)
        
        # **ä¿®æ­£2: ç‹¬ç«‹è¨ˆç®—ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§DF-Aå­¦ç¿’**
        with torch.enable_grad():
            stage1_metrics = self.df_state.train_stage1_with_gradients(
                X_states_detached, 
                opt_phi,
                T1_iterations=self.config.T1_iterations
            )
        
        metrics['df_a_stage1_loss'] = stage1_metrics['stage1_loss']
        
        # ãƒ­ã‚°è¨˜éŒ²
        self.logger.log_phase1(
            epoch, TrainingPhase.PHASE1_DF_A, 'stage1', 0,
            stage1_metrics, {'lr_phi': opt_phi.param_groups[0]['lr']}
        )
        
        # Stage-2: U_Aæ¨å®šï¼ˆT2å›å®Ÿè¡Œï¼‰
        stage2_losses = []
        for t in range(self.config.T2_iterations):
            with torch.no_grad():  # **ä¿®æ­£2: Stage-2ã¯å‹¾é…ãªã—**
                stage2_metrics = self.df_state.train_stage2_closed_form()
                stage2_losses.append(stage2_metrics['stage2_loss'])
                
                # ãƒ­ã‚°è¨˜éŒ²
                self.logger.log_phase1(
                    epoch, TrainingPhase.PHASE1_DF_A, 'stage2', t,
                    stage2_metrics, {}
                )
        
        metrics['df_a_stage2_loss'] = sum(stage2_losses) / len(stage2_losses)
        
        # **ä¿®æ­£2: æ˜ç¤ºçš„ã‚°ãƒ©ãƒ•ã‚¯ãƒªã‚¢**
        self._clear_computation_graph()
        
        return metrics
    
    def _train_df_b_epoch(self, X_states: torch.Tensor, m_series: torch.Tensor, 
                        epoch: int) -> Dict[str, float]:
        """
        **ä¿®æ­£ç‰ˆ**: DF-Bï¼ˆè¦³æ¸¬å±¤ï¼‰ã®ã‚¨ãƒãƒƒã‚¯å­¦ç¿’ï¼ˆè¨ˆç®—ã‚°ãƒ©ãƒ•é‡è¤‡ä½¿ç”¨ã‚¨ãƒ©ãƒ¼å¯¾å¿œï¼‰
        """
        metrics = {}
        opt_phi = self.optimizers['phi']
        opt_psi = self.optimizers['psi']

        # **è¿½åŠ **: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’GPUã«ç§»å‹•
        X_states_gpu = X_states.to(self.device)
        m_series_gpu = m_series.to(self.device)

        # **ä¿®æ­£2: å®Œå…¨ã«ãƒ‡ã‚¿ãƒƒãƒã•ã‚ŒãŸå…¥åŠ›ã§ç‹¬ç«‹ã‚°ãƒ©ãƒ•ä½œæˆ**
        X_states_detached = X_states_gpu.detach().requires_grad_(False)
        
        # **ä¿®æ­£2: ç‹¬ç«‹è¨ˆç®—ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§DF-Bå­¦ç¿’**
        with torch.enable_grad():
            # DF-Aã‹ã‚‰ã®çŠ¶æ…‹äºˆæ¸¬ã‚’å–å¾—ï¼ˆæ“ä½œå¤‰æ•°ã¨ã—ã¦æ¨è«–ã®ã¿ï¼‰
            with torch.no_grad():
                X_hat_states = self.df_state.predict_sequence(X_states_detached)
            
            # æ˜ç¤ºçš„ã«å‹¾é…ã‚°ãƒ©ãƒ•ã‹ã‚‰åˆ‡æ–­
            X_hat_states = X_hat_states.detach().requires_grad_(False)
            
            # **ä¿®æ­£4: ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ãŸæ™‚é–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª¿æ•´**
            m_aligned = self._align_time_series(
                X_hat_states, m_series, X_states.size(0), epoch, "DF-B"
            )
            
            # Stage-1å­¦ç¿’
            stage1_metrics = self.df_obs.train_stage1_with_gradients(
                X_hat_states, 
                m_aligned,  # **ä¿®æ­£2+4: æ™‚é–“èª¿æ•´æ¸ˆã¿**
                opt_phi, 
                T1_iterations=self.config.T1_iterations,
                fix_psi_omega=True
            )
        
        metrics['df_b_stage1_loss'] = stage1_metrics['stage1_loss']
        
        # ãƒ­ã‚°è¨˜éŒ²
        self.logger.log_phase1(
            epoch, TrainingPhase.PHASE1_DF_B, 'stage1', 0,
            stage1_metrics, {'lr_phi': opt_phi.param_groups[0]['lr']}
        )
        
        # **ä¿®æ­£2: æ˜ç¤ºçš„ã‚°ãƒ©ãƒ•ã‚¯ãƒªã‚¢**
        self._clear_computation_graph()
        
        # Stage-2: u_Bæ¨å®š + Ïˆ_Ï‰æ›´æ–°ï¼ˆT2å›åå¾©ã€è¨ˆç®—ã‚°ãƒ©ãƒ•åˆ†é›¢ï¼‰
        stage2_losses = []
        for t in range(self.config.T2_iterations):
            with torch.enable_grad():
                # **ä¿®æ­£**: å„åå¾©ã§ç‹¬ç«‹ã—ãŸè¨ˆç®—ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
                m_aligned_independent = m_aligned.detach().requires_grad_(True)
                
                stage2_metrics = self.df_obs.train_stage2_with_gradients(
                    m_aligned_independent,  # â† ä¿®æ­£: ç‹¬ç«‹ã—ãŸãƒ†ãƒ³ã‚½ãƒ«
                    opt_psi, 
                    fix_phi_theta=True
                )
                stage2_losses.append(stage2_metrics['stage2_loss'])
                
                # ãƒ­ã‚°è¨˜éŒ²
                self.logger.log_phase1(
                    epoch, TrainingPhase.PHASE1_DF_B, 'stage2', t,
                    stage2_metrics, {'lr_psi': opt_psi.param_groups[0]['lr']}
                )
        
        metrics['df_b_stage2_loss'] = sum(stage2_losses) / len(stage2_losses)
        
        # **ä¿®æ­£2: æœ€çµ‚ã‚°ãƒ©ãƒ•ã‚¯ãƒªã‚¢**
        self._clear_computation_graph()
        
        return metrics
    
    def _ensure_device(self, tensor: torch.Tensor) -> torch.Tensor:
        # ãƒ†ãƒ³ã‚½ãƒ«ã‚’æŒ‡å®šãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•ï¼ˆå¿…è¦ãªå ´åˆã®ã¿ï¼‰
        return tensor.to(self.device) if tensor.device != self.device else tensor

    def train_phase2(self, Y_train: torch.Tensor, Y_val: Optional[torch.Tensor] = None) -> Dict[str, float]:
        """
        Phase-2: End-to-endå¾®èª¿æ•´
        
        å›ºå®šæ¨è«–ãƒ‘ã‚¹:
        xÌ‚_{t|t-1} = U_A^T V_A Ï†_Î¸(x_{t-1})
        mÌ‚_{t|t-1} = u_B^T V_B Ï†_Î¸(xÌ‚_{t|t-1})
        Å·_{t|t-1} = g_Î±(mÌ‚_{t|t-1})
        
        Args:
            Y_train: è¨“ç·´è¦³æ¸¬ç³»åˆ—
            Y_val: æ¤œè¨¼è¦³æ¸¬ç³»åˆ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        print("\n=== Phase-2: End-to-endå¾®èª¿æ•´é–‹å§‹ ===")
        
        if not self.phase1_complete:
            raise RuntimeError("Phase-1ãŒå®Œäº†ã—ã¦ã„ã¾ã›ã‚“")
        
        opt_e2e = self.optimizers['e2e']
        
        # Phase-2å­¦ç¿’ãƒ«ãƒ¼ãƒ—
        for epoch in range(self.config.phase2_epochs):
            self.current_epoch = self.config.phase1_epochs + epoch
            
            try:
                # å‰å‘ãæ¨è«–ã¨æå¤±è¨ˆç®—
                loss_total, rec_loss, cca_loss = self._forward_and_loss_phase2(Y_train)
                
                # é€†ä¼æ’­
                opt_e2e.zero_grad()
                loss_total.backward()
                opt_e2e.step()
                
            except RealizationError as e:
                print(f"ğŸ”„ Epoch {epoch} ã‚¹ã‚­ãƒƒãƒ— (Phase2æ•°å€¤å®Ÿç¾å¤±æ•—): {e}")
                # ã“ã®ã‚¨ãƒãƒƒã‚¯ã‚’å®Œå…¨ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ¬¡ã®ã‚¨ãƒãƒƒã‚¯ã«é€²ã‚€
                continue
            
            # ãƒ­ã‚°è¨˜éŒ²
            lr_dict = {f'lr_{name}': group['lr'] for name, group in 
                      zip(['encoder', 'decoder', 'phi', 'psi'], opt_e2e.param_groups)}
            self.logger.log_phase2(epoch, loss_total.item(), rec_loss.item(), 
                                  cca_loss.item(), lr_dict)
            
            self.training_history['phase2_losses'].append({
                'epoch': epoch,
                'total_loss': loss_total.item(),
                'rec_loss': rec_loss.item(),
                'cca_loss': cca_loss.item()
            })
            
            # é€²æ—è¡¨ç¤º
            if epoch % self.config.log_interval == 0 and self.config.verbose:
                print(f"Phase-2 Epoch {epoch}: Total={loss_total.item():.6f}, "
                      f"Rec={rec_loss.item():.6f}, CCA={cca_loss.item():.6f}")
            
            # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
            if epoch % self.config.save_interval == 0:
                self._save_checkpoint(epoch, TrainingPhase.PHASE2_E2E)
        
        print("Phase-2 å­¦ç¿’å®Œäº†")
        return self.training_history['phase2_losses']
    
    def _forward_and_loss_phase2(self, Y_train: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        **ä¿®æ­£4çµ±åˆ**: Phase-2ã®å‰å‘ãæ¨è«–ã¨æå¤±è¨ˆç®—ï¼ˆæ™‚é–“èª¿æ•´ãƒ˜ãƒ«ãƒ‘ãƒ¼ä½¿ç”¨ï¼‰
        """
        T, d = Y_train.shape
        h = self.realization.h
        
        if T <= 2 * h:
            # æ™‚ç³»åˆ—ãŒçŸ­ã™ãã‚‹å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return self._handle_short_timeseries_phase2(Y_train)
        
        # Step 1: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ y_t â†’ m_t
        m_series = self.encoder(Y_train.unsqueeze(0)).squeeze()  # (T, 1) -> (T,)
        if m_series.dim() == 2:
            m_series = m_series.squeeze(1)
        
        # Step 2: ç¢ºç‡çš„å®Ÿç¾ m_t â†’ x_t
        try:
            self.realization.fit(m_series.unsqueeze(1))
        except RealizationError as e:
            print(f"âš ï¸ Phase2 RealizationErrorç™ºç”Ÿ: {e}")
            # RealizationErrorã‚’ä¸Šä½ã«å†æŠ•ã’ã—ã¦å®Œå…¨ã‚¨ãƒãƒƒã‚¯ã‚¹ã‚­ãƒƒãƒ—ã‚’å®Ÿè¡Œ
            raise RealizationError(f"Phase2 realization failed: {e}") from e
        X_states = self.realization.filter(m_series.unsqueeze(1))  # (T_eff, r)
        T_eff = X_states.size(0)
        
        # Step 3: DF-Aäºˆæ¸¬ x_{t-1} â†’ xÌ‚_{t|t-1}
        X_hat_states = self.df_state.predict_sequence(X_states)  # (T_pred, r)
        T_pred = X_hat_states.size(0)
        
        # **ä¿®æ­£4: ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ãŸæ™‚é–“èª¿æ•´**
        m_aligned = self._align_time_series(
            X_hat_states, m_series, X_states.size(0), 0, "Phase2"
        )
        
        # Step 4: DF-Bäºˆæ¸¬ xÌ‚_{t|t-1} â†’ mÌ‚_{t|t-1}
        m_hat_series = []
        for t in range(T_pred):
            m_hat_t = self.df_obs.predict_one_step(X_hat_states[t])
            m_hat_series.append(m_hat_t)
        m_hat_tensor = torch.stack(m_hat_series)  # (T_pred,)
        
        # Step 5: ãƒ‡ã‚³ãƒ¼ãƒ‰ mÌ‚_{t|t-1} â†’ Å·_{t|t-1}
        Y_hat = self.decoder(m_hat_tensor.unsqueeze(0).unsqueeze(2)).squeeze(0)  # (T_pred, d)
        
        # Step 6: å¯¾å¿œã™ã‚‹çœŸå€¤å–å¾—
        Y_target = Y_train[h+1:h+1+T_pred]  # å¯¾å¿œã™ã‚‹è¦³æ¸¬
        
        # æå¤±è¨ˆç®—
        loss_rec = torch.norm(Y_hat - Y_target, p='fro') ** 2
        
        # CCAæå¤±ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if self.config.lambda_cca > 0:
            loss_cca = self._compute_cca_loss(m_hat_tensor, m_aligned)
        else:
            loss_cca = torch.tensor(0.0, requires_grad=True)
        
        loss_total = loss_rec + self.config.lambda_cca * loss_cca
        
        return loss_total, loss_rec, loss_cca
    
    def _handle_short_timeseries_phase2(self, Y_train: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """çŸ­ã„æ™‚ç³»åˆ—ç”¨ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†"""
        T, d = Y_train.shape
        h = self.realization.h
        warnings.warn(f"æ™‚ç³»åˆ—é•·({T})ãŒçŸ­ã™ãã¾ã™ã€‚h={h}")
        
        # æœ€å°é™ã®å‡¦ç†
        m_series = self.encoder(Y_train.unsqueeze(0)).squeeze()
        if m_series.dim() == 2:
            m_series = m_series.squeeze(1)
        
        try:
            self.realization.fit(m_series.unsqueeze(1))
        except RealizationError as e:
            print(f"âš ï¸ Evaluation RealizationErrorç™ºç”Ÿ: {e}")
            # è©•ä¾¡æ™‚ã¯ã‚¨ãƒ©ãƒ¼ã‚’ä¸Šä½ã«æŠ•ã’ã¦å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—
            raise RealizationError(f"Evaluation realization failed: {e}") from e
        X_states = self.realization.filter(m_series.unsqueeze(1))
        
        # çŸ­ç¸®å‡¦ç†
        if X_states.size(0) > 1:
            X_hat_states = self.df_state.predict_sequence(X_states)
            # **ä¿®æ­£4: ãƒ˜ãƒ«ãƒ‘ãƒ¼ä½¿ç”¨**
            m_aligned = self._align_time_series(
                X_hat_states, m_series, X_states.size(0), 0, "Phase2-Short"
            )
            
            loss_rec = torch.norm(m_aligned - m_aligned, p=2) ** 2  # ãƒ€ãƒŸãƒ¼æå¤±
            loss_cca = torch.tensor(0.0, requires_grad=True)
            loss_total = loss_rec + self.config.lambda_cca * loss_cca
        else:
            loss_rec = torch.tensor(0.0, requires_grad=True)
            loss_cca = torch.tensor(0.0, requires_grad=True) 
            loss_total = loss_rec
        
        return loss_total, loss_rec, loss_cca
    
    def _compute_cca_loss(self, m_hat: torch.Tensor, m_target: torch.Tensor) -> torch.Tensor:
        """CCAæå¤±è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        # æ­£è¦åŒ–
        m_hat_norm = (m_hat - m_hat.mean()) / (m_hat.std() + 1e-8)
        m_target_norm = (m_target - m_target.mean()) / (m_target.std() + 1e-8)
        
        # ç›¸é–¢ä¿‚æ•°ï¼ˆè² ã®å€¤ãªã®ã§æœ€å°åŒ–ã§ç›¸é–¢æœ€å¤§åŒ–ï¼‰
        correlation = torch.corrcoef(torch.stack([m_hat_norm, m_target_norm]))[0, 1]
        
        return -correlation  # ç›¸é–¢æœ€å¤§åŒ–ã®ãŸã‚è² å·
    
    # ===== ä¿®æ­£4: ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤ =====
    
    def _align_time_series(self, X_hat_states: torch.Tensor, m_series: torch.Tensor, 
                          T_states: int, epoch: int, component: str) -> torch.Tensor:
        """
        **ä¿®æ­£4**: çµ±åˆæ™‚é–“ç³»åˆ—èª¿æ•´ãƒ˜ãƒ«ãƒ‘ãƒ¼
        
        Args:
            X_hat_states: çŠ¶æ…‹äºˆæ¸¬ç³»åˆ—
            m_series: å…ƒã®ã‚¹ã‚«ãƒ©ãƒ¼ç‰¹å¾´ç³»åˆ—
            T_states: çŠ¶æ…‹ç³»åˆ—é•·ï¼ˆX_statesã®é•·ã•ï¼‰
            epoch: ç¾åœ¨ã®ã‚¨ãƒãƒƒã‚¯ï¼ˆãƒ­ã‚°ç”¨ï¼‰
            component: ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåï¼ˆãƒ­ã‚°ç”¨ï¼‰
        
        Returns:
            torch.Tensor: æ™‚é–“èª¿æ•´æ¸ˆã¿ã‚¹ã‚«ãƒ©ãƒ¼ç‰¹å¾´ç³»åˆ—
        """
        T_pred = X_hat_states.size(0)
        T_original = m_series.size(0)
        
        # ã‚ªãƒ•ã‚»ãƒƒãƒˆè¨ˆç®—
        total_offset = self._get_time_alignment_offset(T_original, T_states, T_pred)
        
        # æ™‚é–“èª¿æ•´ã•ã‚ŒãŸm_seriesã‚’æŠ½å‡º
        if total_offset + T_pred <= T_original:
            m_aligned = m_series[total_offset:total_offset + T_pred]
        else:
            # å®‰å…¨æªç½®: æœ«å°¾ã‹ã‚‰å¿…è¦ãªé•·ã•ã‚’å–å¾—
            m_aligned = m_series[-T_pred:]
            if self.config.verbose:
                print(f"è­¦å‘Š: {component} ã§ã‚ªãƒ•ã‚»ãƒƒãƒˆèª¿æ•´å¤±æ•—ã€æœ«å°¾åˆ‡ã‚Šå–ã‚Šä½¿ç”¨")
        
        # æ™‚é–“æ•´åˆæ€§æ¤œè¨¼
        self._validate_time_alignment(X_hat_states, m_aligned, component)
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆverboseæ™‚ã®ã¿ï¼‰ - ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
        # if self.config.verbose and epoch % 10 == 0:
        #     print(f"{component}æ™‚é–“èª¿æ•´ - Epoch {epoch}: "
        #           f"X_hat: {X_hat_states.shape}, m_aligned: {m_aligned.shape}, "
        #           f"offset: {total_offset}")
        
        return m_aligned
    
    def _get_time_alignment_offset(self, T_original: int, T_states: int, T_pred: int) -> int:
        """
        æ™‚é–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª¿æ•´ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆè¨ˆç®—
        ç†è«–: 
        - ç¢ºç‡çš„å®Ÿç¾å‡ºåŠ›: x_h, x_{h+1}, ..., x_{h+T_states-1}
        - DF-Aäºˆæ¸¬: xÌ‚_{h+1|h}, xÌ‚_{h+2|h+1}, ..., xÌ‚_{h+T_pred|h+T_pred-1}
        - æ­£ã—ã„å¯¾å¿œ: xÌ‚_{h+1|h} â†” m_{h+1}
        Args:
            T_original: å…ƒç³»åˆ—é•·
            T_states: çŠ¶æ…‹ç³»åˆ—é•·  
            T_pred: äºˆæ¸¬ç³»åˆ—é•·
            
        Returns:
            int: m_seriesã®ã‚ªãƒ•ã‚»ãƒƒãƒˆ (= h + 1)
        """
        # hå€¤å–å¾—
        h_candidates = [
            'h',                    # Realizationã®æ¨™æº–å±æ€§å
            'past_horizon',         # åˆæœŸåŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å
            'lags',                 # åˆ¥åã®å¯èƒ½æ€§
            'window_size',          # åˆ¥åã®å¯èƒ½æ€§
        ]
        
        h = None
        for attr_name in h_candidates:
            if hasattr(self.realization, attr_name):
                h = getattr(self.realization, attr_name)
                if isinstance(h, (int, float)) and h > 0:
                    h = int(h)
                    break
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: T_original, T_statesã‹ã‚‰é€†ç®—
        if h is None:
            # T_states = T_original - 2*h + 1 ã‹ã‚‰ h ã‚’è¨ˆç®—
            h = (T_original - T_states + 1) // 2
            if self.config.verbose:
                print(f"è­¦å‘Š: hå€¤ã‚’é€†ç®—ã§æ¨å®šã—ã¾ã—ãŸ: h = {h}")
        
        # æ¤œè¨¼
        expected_T_states = T_original - 2 * h + 1
        if abs(T_states - expected_T_states) > 1:  # 1ã®èª¤å·®ã¯è¨±å®¹
            if self.config.verbose:
                print(f"è­¦å‘Š: h={h}ã«ã‚ˆã‚‹æœŸå¾…T_states={expected_T_states}ãŒå®Ÿéš›å€¤{T_states}ã¨ä¸ä¸€è‡´")
        
        return h + 1
    
    def _validate_time_alignment(self, X_hat_states: torch.Tensor, m_aligned: torch.Tensor, 
                               component: str = "unknown") -> None:
        """
        **ä¿®æ­£4**: æ™‚é–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ•´åˆæ€§ã®æ¤œè¨¼
        
        Args:
            X_hat_states: çŠ¶æ…‹äºˆæ¸¬
            m_aligned: èª¿æ•´æ¸ˆã¿ã‚¹ã‚«ãƒ©ãƒ¼ç‰¹å¾´é‡
            component: ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåï¼ˆãƒ­ã‚°ç”¨ï¼‰
        """
        if X_hat_states.size(0) != m_aligned.size(0):
            raise RuntimeError(
                f"{component}ã®æ™‚é–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¸æ•´åˆ: "
                f"X_hat={X_hat_states.shape} vs m_aligned={m_aligned.shape}"
            )
        
        # æ™‚é–“æ•´åˆç¢ºèªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ - ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
        # if self.config.verbose:
        #     print(f"{component} æ™‚é–“æ•´åˆç¢ºèª: {X_hat_states.shape} â†” {m_aligned.shape}")
    
    def _clear_computation_graph(self):
        """
        **ä¿®æ­£2**: è¨ˆç®—ã‚°ãƒ©ãƒ•ã®æ˜ç¤ºçš„ã‚¯ãƒªã‚¢
        """
        # GPU ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        # CPU ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
        gc.collect()
    
    # ===== æ—¢å­˜ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆä¿®æ­£ãªã—ï¼‰ =====
    
    def forecast(self, Y_test: torch.Tensor, forecast_steps: int) -> torch.Tensor:
        """äºˆæ¸¬å®Ÿè¡Œ"""
        self.encoder.eval()
        self.decoder.eval()
        self.df_state.eval()
        self.df_obs.eval()
        
        with torch.no_grad():
            # åˆæœŸçŠ¶æ…‹æ¨å®š
            T_test, d = Y_test.shape
            warmup_len = min(T_test, self.realization.h + 10)
            Y_warmup = Y_test[:warmup_len]
            
            # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            m_warmup = self.encoder(Y_warmup.unsqueeze(0)).squeeze()
            
            # çŠ¶æ…‹æ¨å®š
            try:
                self.realization.fit(m_warmup.unsqueeze(1))
            except RealizationError as e:
                print(f"âš ï¸ Warmup RealizationErrorç™ºç”Ÿ: {e}")
                # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—æ™‚ã¯ã‚¨ãƒ©ãƒ¼ã‚’ä¸Šä½ã«æŠ•ã’ã¦å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—
                raise RealizationError(f"Warmup realization failed: {e}") from e
            X_warmup = self.realization.filter(m_warmup.unsqueeze(1))
            
            # é€æ¬¡äºˆæ¸¬
            predictions = []
            x_current = X_warmup[-1]  # æœ€æ–°çŠ¶æ…‹
            
            for step in range(forecast_steps):
                # DF-A: çŠ¶æ…‹äºˆæ¸¬
                x_pred = self.df_state.predict_one_step(x_current)
                
                # DF-B: ç‰¹å¾´é‡äºˆæ¸¬
                m_pred = self.df_obs.predict_one_step(x_pred)
                
                # ãƒ‡ã‚³ãƒ¼ãƒ‰: è¦³æ¸¬äºˆæ¸¬
                m_input = m_pred.unsqueeze(0).unsqueeze(0).unsqueeze(2)  # (1, 1, 1)
                y_pred = self.decoder(m_input).squeeze()  # (d,)
                
                predictions.append(y_pred)
                x_current = x_pred  # çŠ¶æ…‹æ›´æ–°
            
            return torch.stack(predictions)  # (forecast_steps, d)
    
    def train_full(self, Y_train: torch.Tensor, Y_val: Optional[torch.Tensor] = None) -> Dict[str, Any]:
        """å®Œå…¨å­¦ç¿’å®Ÿè¡Œï¼ˆPhase-1 + Phase-2ï¼‰"""
        try:
            # Phase-1å­¦ç¿’
            phase1_metrics = self.train_phase1(Y_train)
            
            # Phase-2å­¦ç¿’
            phase2_metrics = self.train_phase2(Y_train, Y_val)
            
            # æœ€çµ‚ä¿å­˜
            self._save_final_model()
            self.logger.save_summary()
            
            return {
                'phase1_metrics': phase1_metrics,
                'phase2_losses': phase2_metrics,
                'training_config': self.config.__dict__,
                'model_paths': {
                    'final_model': str(self.output_dir / 'final_model.pth'),
                    'logs': str(self.logger.output_dir)
                }
            }
            
        except Exception as e:
            print(f"å­¦ç¿’ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
            # ç·Šæ€¥ä¿å­˜
            self._save_checkpoint(self.current_epoch, TrainingPhase.PHASE1_DF_A, emergency=True)
            raise
    
    def _print_phase1_progress(self, epoch: int, metrics: Dict[str, float]):
        """Phase-1é€²æ—è¡¨ç¤º"""
        df_a_s1 = metrics.get('df_a_stage1_loss', 0)
        df_a_s2 = metrics.get('df_a_stage2_loss', 0)
        df_b_s1 = metrics.get('df_b_stage1_loss', 0)
        df_b_s2 = metrics.get('df_b_stage2_loss', 0)
        
        print(f"Phase-1 Epoch {epoch:3d}: "
              f"DF-A(S1={df_a_s1:.4f}, S2={df_a_s2:.4f}) "
              f"DF-B(S1={df_b_s1:.4f}, S2={df_b_s2:.4f})")
    
    def _save_checkpoint(self, epoch: int, phase: TrainingPhase, emergency: bool = False):
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜"""
        checkpoint = {
            'epoch': epoch,
            'phase': phase.value,
            'encoder_state': self.encoder.state_dict(),
            'decoder_state': self.decoder.state_dict(),
            'training_config': self.config.__dict__,
            'training_history': self.training_history,
            'phase1_complete': self.phase1_complete
        }
        
        # DF layersçŠ¶æ…‹
        if self.df_state is not None:
            checkpoint['df_state'] = self.df_state.get_state_dict()
        if self.df_obs is not None:
            checkpoint['df_obs'] = self.df_obs.get_state_dict()
        
        # æœ€é©åŒ–å™¨çŠ¶æ…‹
        opt_states = {}
        for name, opt in self.optimizers.items():
            if opt is not None:
                opt_states[name] = opt.state_dict()
        checkpoint['optimizer_states'] = opt_states
        
        # ä¿å­˜ãƒ‘ã‚¹
        if emergency:
            save_path = self.output_dir / f'emergency_checkpoint_epoch_{epoch}.pth'
        else:
            save_path = self.output_dir / f'checkpoint_epoch_{epoch}.pth'
        
        torch.save(checkpoint, save_path)
        
        if self.config.verbose:
            print(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜: {save_path}")
    
    def _save_final_model(self):
        """æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ä¿å­˜"""
        print("DEBUG: _save_final_model called")
        # å­¦ç¿’æ™‚ã®å®Œå…¨ãªè¨­å®šã‚’å¾©å…ƒ
        complete_config = self._build_complete_config()
        
        model_state = {
            'encoder': self.encoder.state_dict(),
            'decoder': self.decoder.state_dict(),
            'df_state': self.df_state.get_inference_state_dict() if self.df_state else None,
            'df_obs': self.df_obs.get_inference_state_dict() if self.df_obs else None,
            'realization_config': self.realization.__dict__,
            'training_config': self.config.__dict__,
            'config': complete_config  # æ¨è«–æ™‚ã«ä½¿ç”¨ã•ã‚Œã‚‹å®Œå…¨ãªè¨­å®š
        }
        
        save_path = self.output_dir / 'final_model.pth'
        torch.save(model_state, save_path)
        
        print(f"æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {save_path}")
    
    def _build_complete_config(self) -> Dict[str, Any]:
        """å­¦ç¿’æ™‚ã®å®Œå…¨ãªè¨­å®šã‚’æ§‹ç¯‰ï¼ˆæ¨è«–æ™‚ã«ä½¿ç”¨ï¼‰"""
        print("DEBUG: _build_complete_config called")
        
        complete_config = {
            'model': {
                'encoder': {
                    'input_dim': getattr(self.encoder, 'input_dim', 6),
                    'channels': getattr(self.encoder, 'channels', 64),
                    'layers': getattr(self.encoder, 'layers', 8),
                    'kernel_size': getattr(self.encoder, 'kernel_size', 3),
                    'activation': getattr(self.encoder, 'activation', 'GELU'),
                    'dropout': getattr(self.encoder, 'dropout', 0.1)
                },
                'decoder': {
                    'output_dim': getattr(self.decoder, 'output_dim', 6),
                    'window': getattr(self.decoder, 'window', 12),
                    'tau': getattr(self.decoder, 'tau', 1),
                    'hidden': getattr(self.decoder, 'hidden', 64),
                    'ma_kernel': getattr(self.decoder, 'ma_kernel', 24),
                    'gru_hidden': getattr(self.decoder, 'gru_hidden', 32),
                    'activation': getattr(self.decoder, 'activation', 'GELU'),
                    'dropout': getattr(self.decoder, 'dropout', 0.1)
                }
            },
            'ssm': {
                'realization': self.realization.__dict__,
                'df_state': self._extract_df_state_config(),
                'df_observation': self._extract_df_obs_config()
            }
        }
        
        print("DEBUG: _build_complete_config completed")
        return complete_config
    
    def _extract_df_state_config(self) -> Dict[str, Any]:
        """å®Ÿéš›ã®DFStateLayerã‹ã‚‰è¨­å®šã‚’æŠ½å‡º"""
        base_config = self.df_state_config.copy()
        
        print(f"DEBUG: df_state exists: {self.df_state is not None}")
        
        # å®Ÿéš›ã®DFStateLayerã‹ã‚‰è©³ç´°è¨­å®šã‚’æŠ½å‡º
        if self.df_state and hasattr(self.df_state, 'phi_theta'):
            print("DEBUG: df_state has phi_theta")
            # StateFeatureNetã®æ§‹é€ ã‚’è§£æ
            phi_theta = self.df_state.phi_theta
            print(f"DEBUG: phi_theta type: {type(phi_theta)}")
            print(f"DEBUG: phi_theta has net: {hasattr(phi_theta, 'net')}")
            
            if hasattr(phi_theta, 'net') and len(phi_theta.net) > 0:
                print(f"DEBUG: phi_theta.net length: {len(phi_theta.net)}")
                print(f"DEBUG: phi_theta.net layers: {[type(layer).__name__ for layer in phi_theta.net]}")
                
                # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ã‹ã‚‰ hidden_sizes ã‚’é€†ç®—
                hidden_sizes = []
                for i, layer in enumerate(phi_theta.net):
                    print(f"DEBUG: Layer {i}: {type(layer).__name__}")
                    if hasattr(layer, 'out_features'):
                        print(f"DEBUG: Layer {i} out_features: {layer.out_features}")
                        hidden_sizes.append(layer.out_features)
                
                print(f"DEBUG: Raw hidden_sizes: {hidden_sizes}")
                
                # æœ€å¾Œã®å±¤ã¯é™¤ãï¼ˆå‡ºåŠ›å±¤ï¼‰
                if len(hidden_sizes) > 1:
                    hidden_sizes = hidden_sizes[:-1]
                    print(f"DEBUG: Final hidden_sizes: {hidden_sizes}")
                
                # feature_net è¨­å®šã‚’æ§‹ç¯‰
                base_config['feature_net'] = {
                    'hidden_sizes': hidden_sizes,
                    'activation': getattr(phi_theta, 'activation', 'ReLU'),
                    'dropout': getattr(phi_theta, 'dropout', 0.1)
                }
                print(f"DEBUG: Created feature_net config: {base_config['feature_net']}")
            else:
                print("DEBUG: phi_theta.net not found or empty")
        else:
            print("DEBUG: df_state doesn't have phi_theta")
        
        print(f"DEBUG: Final base_config keys: {list(base_config.keys())}")
        return base_config
    
    def _extract_df_obs_config(self) -> Dict[str, Any]:
        """å®Ÿéš›ã®DFObservationLayerã‹ã‚‰è¨­å®šã‚’æŠ½å‡º"""
        base_config = self.df_obs_config.copy()
        
        # å®Ÿéš›ã®DFObservationLayerã‹ã‚‰è©³ç´°è¨­å®šã‚’æŠ½å‡º
        if self.df_obs and hasattr(self.df_obs, 'psi_omega'):
            psi_omega = self.df_obs.psi_omega
            if hasattr(psi_omega, 'net') and len(psi_omega.net) > 0:
                # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ã‹ã‚‰ hidden_sizes ã‚’é€†ç®—
                hidden_sizes = []
                for layer in psi_omega.net:
                    if hasattr(layer, 'out_features'):
                        hidden_sizes.append(layer.out_features)
                
                # æœ€å¾Œã®å±¤ã¯é™¤ãï¼ˆå‡ºåŠ›å±¤ï¼‰
                if len(hidden_sizes) > 1:
                    hidden_sizes = hidden_sizes[:-1]
                
                # obs_net è¨­å®šã‚’æ§‹ç¯‰
                base_config['obs_net'] = {
                    'hidden_sizes': hidden_sizes,
                    'activation': getattr(psi_omega, 'activation', 'ReLU'),
                    'dropout': getattr(psi_omega, 'dropout', 0.1)
                }
        
        return base_config
    
    def get_training_summary(self) -> Dict[str, Any]:
        """å­¦ç¿’ã‚µãƒãƒªå–å¾—"""
        summary = {
            'training_complete': self.phase1_complete,
            'total_epochs': {
                'phase1': self.config.phase1_epochs,
                'phase2': self.config.phase2_epochs if self.phase1_complete else 0
            },
            'final_losses': {},
            'model_info': {
                'encoder_params': sum(p.numel() for p in self.encoder.parameters()),
                'decoder_params': sum(p.numel() for p in self.decoder.parameters()),
                'df_state_params': sum(p.numel() for p in self.df_state.phi_theta.parameters()) if self.df_state else 0,
                'df_obs_params': sum(p.numel() for p in self.df_obs.psi_omega.parameters()) if self.df_obs else 0
            }
        }
        
        if self.training_history['phase1_metrics']:
            summary['final_losses']['phase1'] = self.training_history['phase1_metrics'][-1]
        
        if self.training_history['phase2_losses']:
            summary['final_losses']['phase2'] = self.training_history['phase2_losses'][-1]
        
        return summary
    
    """
    å­¦ç¿’å¾Œã®æ¨è«–ç’°å¢ƒè‡ªå‹•ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    """
    def post_training_setup(self, Y_train: torch.Tensor) -> Dict[str, Any]:
        if not self.use_kalman_filtering:
            return {"status": "kalman_disabled"}
        
        if not self.phase1_complete:
            return {"status": "phase1_incomplete"}
        
        print("Setting up post-training inference environment...")
        
        try:
            # æ¨è«–è¨­å®šèª­ã¿è¾¼ã¿ï¼ˆå¾Œè¿°ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹æ‰‹æ³•ä½¿ç”¨ï¼‰
            inference_config = self._load_inference_config()
            
            # ä¸€æ™‚çš„ãªãƒ¢ãƒ‡ãƒ«ä¿å­˜
            temp_model_path = self.output_dir / "temp_inference_model.pth"
            self._save_inference_ready_model(temp_model_path)
            
            # InferenceModelåˆæœŸåŒ–
            from ..models.inference_model import InferenceModel
            
            self.inference_model = InferenceModel(
                trained_model_path=temp_model_path,
                inference_config=inference_config
            )
            
            # æ¨è«–ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
            self.inference_model.setup_inference(calibration_data=self.calibration_data)
            
            # æœ€çµ‚ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
            self.inference_model.export_for_deployment(
                export_path=self.output_dir / "inference_deployment"
            )
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            if temp_model_path.exists():
                temp_model_path.unlink()
            
            return {"status": "success", "inference_model": self.inference_model}
            
        except Exception as e:
            return {"status": "failed", "error": str(e)}

    def _save_inference_ready_model(self, save_path):
        """æ¨è«–ç”¨ãƒ¢ãƒ‡ãƒ«ä¿å­˜"""
        print("DEBUG: _save_inference_ready_model called")
        
        model_state = {
            'config': {
                'ssm': {
                    'realization': {
                        'past_horizon': self.realization.h,
                        'rank': self.realization.rank,
                        'jitter': getattr(self.realization, 'jitter', 1e-3)
                    },
                    'df_state': self._extract_df_state_config(),
                    'df_observation': self._extract_df_obs_config()
                },
                'model': {
                    'encoder': {
                        'input_dim': getattr(self.encoder, 'input_dim', 7)
                    }
                }
            },
            'model_state_dict': {
                'encoder': self.encoder.state_dict(),
                'decoder': self.decoder.state_dict(),
                'df_state': self.df_state.get_inference_state_dict(),
                'df_obs': self.df_obs.get_inference_state_dict()
            }
        }
        torch.save(model_state, save_path)

    def _load_inference_config(self) -> Dict[str, Any]:
        """æ¨è«–è¨­å®šã®èª­ã¿è¾¼ã¿ï¼ˆè­¦å‘Šã®ã¿ç‰ˆï¼‰"""
        try:
            from configs.inference_config_loader import load_inference_config
            
            environment = "production" if not self.config.verbose else "development"
            inference_config = load_inference_config(environment=environment)
            inference_config["device"] = str(self.device)
            
            if self.config.verbose:
                print(f"æ¨è«–è¨­å®šèª­ã¿è¾¼ã¿å®Œäº†ï¼ˆç’°å¢ƒ: {environment}ï¼‰")
            
            return inference_config
            
        except ImportError as e:
            warnings.warn(f"InferenceConfigLoaderãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}. å†…è”µãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            return self._use_builtin_defaults()
            
        except FileNotFoundError as e:
            warnings.warn(f"æ¨è«–è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}. å†…è”µãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            return self._use_builtin_defaults()
            
        except Exception as e:
            warnings.warn(f"æ¨è«–è¨­å®šèª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}. å†…è”µãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            return self._use_builtin_defaults()

    def _use_builtin_defaults(self) -> Dict[str, Any]:
        """å†…è”µãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ç›´æ¥ä½¿ç”¨"""
        try:
            from configs.inference_config_loader import InferenceConfigLoader
            
            # ã‚¯ãƒ©ã‚¹ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç›´æ¥ä½¿ç”¨
            loader = InferenceConfigLoader.__new__(InferenceConfigLoader)  # __init__å›é¿
            
            config = {
                'device': str(self.device),
                'noise_estimation': loader._get_default_section('noise_estimation'),
                'initialization': loader._get_default_section('initialization'),
                'numerical': loader._get_default_section('numerical'),
                # streamingã¨outputã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å›ºæœ‰ãªã®ã§ç›´æ¥å®šç¾©
                'streaming': {
                    'buffer_size': 100,
                    'batch_processing': False,
                    'anomaly_detection': True,
                    'anomaly_threshold': 3.0
                },
                'output': {
                    'save_states': True,
                    'save_covariances': False,
                    'save_likelihoods': True
                }
            }
            
            if self.config.verbose:
                print("å†…è”µãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ã—ã¦æ¨è«–è¨­å®šã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
            
            return config
            
        except Exception as nested_e:
            # ã“ã®å ´åˆã¯ã‚¯ãƒ©ã‚¹è‡ªä½“ã«å•é¡ŒãŒã‚ã‚‹ã®ã§ã€ã‚¨ãƒ©ãƒ¼ã‚’ç™ºç”Ÿã•ã›ã‚‹
            raise RuntimeError(
                f"å†…è”µãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®å–å¾—ã«ã‚‚å¤±æ•—ã—ã¾ã—ãŸ: {nested_e}. "
                f"InferenceConfigLoaderã‚¯ãƒ©ã‚¹ã®å®Ÿè£…ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            ) from nested_e



# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
def create_trainer_from_config(config_path: str, device: torch.device, output_dir: str) -> TwoStageTrainer:
    """
    è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’ä½œæˆ
    
    Args:
        config_path: YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        device: è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        
    Returns:
        TwoStageTrainer: åˆæœŸåŒ–æ¸ˆã¿ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼
    """
    import yaml
    
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    encoder = tcnEncoder(**config['model']['encoder'])
    decoder = tcnDecoder(**config['model']['decoder'])
    realization = Realization(**config['ssm']['realization'])
    
    # è¨­å®šå¤‰æ›
    training_config = TrainingConfig.from_nested_dict(config['training'])
    
    # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ä½œæˆ
    trainer = TwoStageTrainer(
        encoder=encoder,
        decoder=decoder,
        realization=realization,
        df_state_config=config['ssm']['df_state'],
        df_obs_config=config['ssm']['df_observation'],
        training_config=training_config,
        device=device,
        output_dir=output_dir
    )
    
    return trainer


def run_training_experiment(
    config_path: str,
    data_path: str,
    output_dir: str,
    device: Optional[torch.device] = None
) -> Dict[str, Any]:
    """
    **å…ƒé–¢æ•°ã®ä¿®æ­£ç‰ˆ**: å­¦ç¿’å®Ÿé¨“ã®å®Ÿè¡Œ
    
    Args:
        config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        data_path: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (.npz)
        output_dir: çµæœå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        device: è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹ï¼ˆNoneãªã‚‰è‡ªå‹•é¸æŠï¼‰
        
    Returns:
        å®Ÿé¨“çµæœè¾æ›¸
    """
    import yaml
    import numpy as np
    from ..utils.gpu_utils import select_device

    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
    if device is None:
        device = select_device()
    
    print(f"å®Ÿé¨“é–‹å§‹: device={device}")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    try:
        from ..utils.data_loader import load_experimental_data
        
        # dataè¨­å®šãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if 'data' in config:
            print(f"ğŸ“‚ çµ±ä¸€ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã§ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {data_path}")
            data_dict = load_experimental_data(data_path, config['data'])
            Y_train = data_dict['train'].to(device)
            print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {Y_train.shape} (æ­£è¦åŒ–: {data_dict['metadata'].normalization_method})")
        else:
            raise ImportError("dataè¨­å®šãŒãªã„ãŸã‚å¾“æ¥æ–¹å¼ã‚’ä½¿ç”¨")
            
    except (ImportError, ModuleNotFoundError, Exception) as e:
        print(f"âš ï¸  çµ±ä¸€ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½¿ç”¨ä¸å¯ã€å¾“æ¥æ–¹å¼: {e}")
        
        data = np.load(data_path)
        if 'Y' in data:
            Y_train = torch.tensor(data['Y'], dtype=torch.float32, device=device)
        elif 'arr_0' in data:
            Y_train = torch.tensor(data['arr_0'], dtype=torch.float32, device=device)
        else:
            available_keys = list(data.keys())
            raise ValueError(
                f"ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã« 'Y' ã¾ãŸã¯ 'arr_0' ã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
                f"åˆ©ç”¨å¯èƒ½ãªã‚­ãƒ¼: {available_keys}"
                )
    
    print(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {Y_train.shape}")
    
    # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
    if Y_train.dim() != 2:
        raise ValueError(f"ãƒ‡ãƒ¼ã‚¿ã¯2æ¬¡å…ƒ (T, d) ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: got {Y_train.shape}")
    
    T, d = Y_train.shape
    if T < 50:
        warnings.warn(f"æ™‚ç³»åˆ—é•·ãŒçŸ­ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™: T={T}")
    
    # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ä½œæˆ
    try:
        trainer = create_trainer_from_config(config_path, device, output_dir)
    except Exception as e:
        raise RuntimeError(f"ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ä½œæˆå¤±æ•—: {config_path}. ã‚¨ãƒ©ãƒ¼: {e}")
    
    # **ä¿®æ­£**: train_full ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ï¼ˆå…ƒã®fitâ†’train_fullã«å¤‰æ›´ï¼‰
    try:
        results = trainer.train_full(Y_train)
    except Exception as e:
        print(f"å­¦ç¿’ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        # ç·Šæ€¥ä¿å­˜è©¦è¡Œ
        try:
            trainer._save_checkpoint(
                trainer.current_epoch, 
                TrainingPhase.PHASE1_DF_A, 
                emergency=True
            )
            print(f"ç·Šæ€¥ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜: {trainer.output_dir}")
        except:
            print("ç·Šæ€¥ä¿å­˜ã‚‚å¤±æ•—ã—ã¾ã—ãŸ")
        raise
    
    # **ä¿®æ­£**: ã‚µãƒãƒªè¿½åŠ ï¼ˆä¿®æ­£ç‰ˆãƒ¡ã‚½ãƒƒãƒ‰åã«å¯¾å¿œï¼‰
    try:
        experiment_summary = trainer.get_training_summary()
        results['experiment_summary'] = experiment_summary
        results['data_info'] = {
            'data_path': data_path,
            'data_shape': tuple(Y_train.shape),
            'device': str(device),
            'total_parameters': experiment_summary.get('model_info', {}).get('total_params', 0)
        }
        
        # **è¿½åŠ **: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        config_backup_path = Path(output_dir) / 'config_used.yaml'
        if not config_backup_path.exists():
            import shutil
            shutil.copy2(config_path, config_backup_path)
            print(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {config_backup_path}")
            
    except Exception as e:
        warnings.warn(f"ã‚µãƒãƒªä½œæˆã§ã‚¨ãƒ©ãƒ¼: {e}")
        results['experiment_summary'] = {'error': str(e)}
        results['data_info'] = {
            'data_path': data_path,
            'data_shape': tuple(Y_train.shape),
            'device': str(device)
        }
    
    print(f"å®Ÿé¨“å®Œäº†: çµæœã¯ {output_dir} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
    
    return results


def run_validation(
    trainer: TwoStageTrainer, 
    Y_test: torch.Tensor, 
    output_dir: str,
    forecast_steps: int = 96
) -> Dict[str, Any]:
    """
    **æ–°æ©Ÿèƒ½**: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®æ¤œè¨¼å®Ÿè¡Œ
    
    Args:
        trainer: å­¦ç¿’æ¸ˆã¿ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼
        Y_test: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        output_dir: çµæœå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        forecast_steps: äºˆæ¸¬ã‚¹ãƒ†ãƒƒãƒ—æ•°
        
    Returns:
        æ¤œè¨¼çµæœè¾æ›¸
    """
    print("æ¤œè¨¼é–‹å§‹...")
    
    try:
        # äºˆæ¸¬å®Ÿè¡Œ
        predictions = trainer.forecast(Y_test, forecast_steps)
        
        # äºˆæ¸¬ç²¾åº¦è¨ˆç®—
        if Y_test.size(0) > forecast_steps:
            Y_true = Y_test[-forecast_steps:]
            mse = torch.mean((predictions - Y_true) ** 2).item()
            mae = torch.mean(torch.abs(predictions - Y_true)).item()
            
            # ç›¸å¯¾èª¤å·®
            relative_error = (torch.norm(predictions - Y_true) / torch.norm(Y_true)).item()
            
            metrics = {
                'mse': mse,
                'mae': mae,
                'rmse': mse ** 0.5,
                'relative_error': relative_error,
                'forecast_steps': forecast_steps
            }
        else:
            warnings.warn("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒäºˆæ¸¬ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚ˆã‚ŠçŸ­ã„ãŸã‚ã€ç²¾åº¦è¨ˆç®—ã‚’ã‚¹ã‚­ãƒƒãƒ—")
            metrics = {
                'forecast_steps': forecast_steps,
                'note': 'ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚ç²¾åº¦è¨ˆç®—ä¸å¯'
            }
        
        # çµæœä¿å­˜
        validation_results = {
            'metrics': metrics,
            'predictions_shape': tuple(predictions.shape),
            'test_data_shape': tuple(Y_test.shape),
            'model_summary': trainer.get_training_summary()
        }
        
        # äºˆæ¸¬çµæœã‚’numpyé…åˆ—ã¨ã—ã¦ä¿å­˜
        output_path = Path(output_dir)
        predictions_path = output_path / 'predictions.npz'
        np.savez(
            predictions_path,
            predictions=predictions.cpu().numpy(),
            Y_test=Y_test.cpu().numpy()
        )
        
        print(f"æ¤œè¨¼å®Œäº†: ç²¾åº¦æŒ‡æ¨™ MSE={metrics.get('mse', 'N/A'):.6f}")
        
        return validation_results
        
    except Exception as e:
        error_result = {
            'error': str(e),
            'test_data_shape': tuple(Y_test.shape),
            'forecast_steps': forecast_steps
        }
        print(f"æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return error_result


def plot_training_results(output_dir: str) -> None:
    """
    **æ–°æ©Ÿèƒ½**: å­¦ç¿’çµæœã®å¯è¦–åŒ–
    
    Args:
        output_dir: çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    """
    try:
        import matplotlib.pyplot as plt
        import pandas as pd
        
        output_path = Path(output_dir)
        
        # Phase-1 æå¤±ãƒ—ãƒ­ãƒƒãƒˆ
        phase1_csv = output_path / 'phase1_training.csv'
        if phase1_csv.exists():
            df_phase1 = pd.read_csv(phase1_csv)
            
            fig, axes = plt.subplots(2, 2, figsize=(12, 10))
            fig.suptitle('Phase-1 Training Progress')
            
            # DF-A Stage-1
            df_a_s1 = df_phase1[(df_phase1['phase'] == 'phase1_df_a') & (df_phase1['stage'] == 'stage1')]
            if not df_a_s1.empty:
                axes[0, 0].plot(df_a_s1['epoch'], df_a_s1['loss'])
                axes[0, 0].set_title('DF-A Stage-1 Loss')
                axes[0, 0].set_xlabel('Epoch')
                axes[0, 0].set_ylabel('Loss')
            
            # DF-A Stage-2
            df_a_s2 = df_phase1[(df_phase1['phase'] == 'phase1_df_a') & (df_phase1['stage'] == 'stage2')]
            if not df_a_s2.empty:
                axes[0, 1].plot(df_a_s2['epoch'], df_a_s2['loss'])
                axes[0, 1].set_title('DF-A Stage-2 Loss')
                axes[0, 1].set_xlabel('Epoch')
                axes[0, 1].set_ylabel('Loss')
            
            # DF-B Stage-1
            df_b_s1 = df_phase1[(df_phase1['phase'] == 'phase1_df_b') & (df_phase1['stage'] == 'stage1')]
            if not df_b_s1.empty:
                axes[1, 0].plot(df_b_s1['epoch'], df_b_s1['loss'])
                axes[1, 0].set_title('DF-B Stage-1 Loss')
                axes[1, 0].set_xlabel('Epoch')
                axes[1, 0].set_ylabel('Loss')
            
            # DF-B Stage-2
            df_b_s2 = df_phase1[(df_phase1['phase'] == 'phase1_df_b') & (df_phase1['stage'] == 'stage2')]
            if not df_b_s2.empty:
                axes[1, 1].plot(df_b_s2['epoch'], df_b_s2['loss'])
                axes[1, 1].set_title('DF-B Stage-2 Loss')
                axes[1, 1].set_xlabel('Epoch')
                axes[1, 1].set_ylabel('Loss')
            
            plt.tight_layout()
            plt.savefig(output_path / 'phase1_losses.png', dpi=150)
            plt.close()
        
        # Phase-2 æå¤±ãƒ—ãƒ­ãƒƒãƒˆ
        phase2_csv = output_path / 'phase2_training.csv'
        if phase2_csv.exists():
            df_phase2 = pd.read_csv(phase2_csv)
            
            fig, axes = plt.subplots(1, 3, figsize=(15, 5))
            fig.suptitle('Phase-2 Training Progress')
            
            axes[0].plot(df_phase2['epoch'], df_phase2['total_loss'])
            axes[0].set_title('Total Loss')
            axes[0].set_xlabel('Epoch')
            axes[0].set_ylabel('Loss')
            
            axes[1].plot(df_phase2['epoch'], df_phase2['rec_loss'])
            axes[1].set_title('Reconstruction Loss')
            axes[1].set_xlabel('Epoch')
            axes[1].set_ylabel('Loss')
            
            axes[2].plot(df_phase2['epoch'], df_phase2['cca_loss'])
            axes[2].set_title('CCA Loss')
            axes[2].set_xlabel('Epoch')
            axes[2].set_ylabel('Loss')
            
            plt.tight_layout()
            plt.savefig(output_path / 'phase2_losses.png', dpi=150)
            plt.close()
        
        print(f"å¯è¦–åŒ–å®Œäº†: {output_path}")
        
    except ImportError:
        warnings.warn("matplotlib/pandasãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€å¯è¦–åŒ–ã‚’ã‚¹ã‚­ãƒƒãƒ—")
    except Exception as e:
        warnings.warn(f"å¯è¦–åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")


if __name__ == "__main__":
    # ç°¡å˜ãªãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ‰
    print("TwoStageTrainerä¿®æ­£ç‰ˆèª­ã¿è¾¼ã¿å®Œäº†")