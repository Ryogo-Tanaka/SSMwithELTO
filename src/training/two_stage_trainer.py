# ===== src/training/two_stage_trainer.py å®Œå…¨ä¿®æ­£ç‰ˆ =====
# ä¿®æ­£1-4çµ±åˆ: æ™‚é–“èª¿æ•´ + è¨ˆç®—ã‚°ãƒ©ãƒ•åˆ†é›¢ + ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°

"""
TwoStageTrainer: ææ¡ˆæ‰‹æ³•ã®2æ®µéšå­¦ç¿’æˆ¦ç•¥å®Ÿè£…

Phase-1: DF-A/DF-B ã® Stage-1/Stage-2 äº¤äº’å­¦ç¿’
Phase-2: End-to-end å¾®èª¿æ•´

å­¦ç¿’æˆ¦ç•¥:
**DF-A (State Layer)**:
for epoch in Phase1:
  for t = 1 to T1:  # Stage-1
    V_A^{(-k)} = é–‰å½¢å¼è§£(Î¦_minus, Î¦_plus, Ï•_Î¸å›ºå®š)
    Ï•_Î¸ â† Ï•_Î¸ - Î±âˆ‡L1(V_A^{(-k)}, Ï•_Î¸)  # Ï•_Î¸æ›´æ–°
 
  for t = 1 to T2:  # Stage-2
    U_A = é–‰å½¢å¼è§£(H^{(cf)}_A, X_+)        # U_Aæ›´æ–°ï¼ˆé–‰å½¢å¼è§£ã®ã¿ï¼‰

**DF-B (Observation Layer)**:
for epoch in Phase1:
  for t = 1 to T1:  # Stage-1
    V_B = é–‰å½¢å¼è§£(Î¦_prev, Î¨_curr)       # V_Bè¨ˆç®—ï¼ˆÏˆ_Ï‰å›ºå®šï¼‰
    Ï•_Î¸ â† Ï•_Î¸ - Î±âˆ‡L1(V_B, Ï•_Î¸)         # Ï•_Î¸æ›´æ–°ï¼ˆÏˆ_Ï‰å›ºå®šï¼‰
 
  for t = 1 to T2:  # Stage-2 
    U_B = é–‰å½¢å¼è§£(H^{(cf)}_B, M)        # U_Bè¨ˆç®—ï¼ˆÏ•_Î¸å›ºå®šï¼‰
    Ïˆ_Ï‰ â† Ïˆ_Ï‰ - Î±âˆ‡L2(u_B, Ïˆ_Ï‰)         # Ïˆ_Ï‰æ›´æ–°ï¼ˆÏ•_Î¸å›ºå®šï¼‰

Phase-2: End-to-endå¾®èª¿æ•´
for epoch in Phase2:
  # æ¨è«–ãƒ‘ã‚¹å›ºå®š
  xÌ‚_{t|t-1} = U_A^T V_A Ï•_Î¸(x_{t-1})
  mÌ‚_{t|t-1} = u_B^T V_B Ï•_Î¸(xÌ‚_{t|t-1})
  Å·_{t|t-1} = g_Î±(mÌ‚_{t|t-1})
 
  # æå¤±
  L_total = L_rec + Î»_c L_cca
 
  # é¸æŠçš„æ›´æ–°
  (u_Î·, g_Î±, Ï•_Î¸, Ïˆ_Ï‰).backward()
"""

import numpy as np
import torch
import torch.nn as nn
from typing import Dict, Any, Optional, List, Tuple
import warnings
from pathlib import Path
import json
import csv
from dataclasses import dataclass
from enum import Enum
import gc

# ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from ..ssm.df_state_layer import DFStateLayer
from ..ssm.df_observation_layer import DFObservationLayer
from ..ssm.realization import Realization, StochasticRealizationWithEncoder, RealizationError
from ..models.architectures.time_invariant import time_invariantEncoder, time_invariantDecoder


class TrainingPhase(Enum):
    """å­¦ç¿’ãƒ•ã‚§ãƒ¼ã‚ºã®å®šç¾©"""
    PHASE1_DF_A = "phase1_df_a"
    PHASE1_DF_B = "phase1_df_b"
    PHASE2_E2E = "phase2_e2e"


@dataclass
class TrainingConfig:
    """å­¦ç¿’è¨­å®šã®æ§‹é€ åŒ–"""
    # Phase-1è¨­å®š
    phase1_epochs: int = 50
    T1_iterations: int = 10  # Stage-1åå¾©æ•°
    T2_iterations: int = 5   # Stage-2åå¾©æ•°
    df_a_warmup_epochs: int = 5  # DF-Bã‚’é–‹å§‹ã™ã‚‹å‰ã®DF-Aã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
    
    # Phase-2è¨­å®š
    phase2_epochs: int = 100
    lambda_cca: float = 0.1
    update_strategy: str = "all"  # "all" or "encoder_decoder_only"
    
    # å­¦ç¿’ç‡
    lr_phi: float = 1e-3     # Ï†_Î¸ (çŠ¶æ…‹ç‰¹å¾´) å­¦ç¿’ç‡
    lr_psi: float = 1e-3     # Ïˆ_Ï‰ (è¦³æ¸¬ç‰¹å¾´) å­¦ç¿’ç‡
    lr_encoder: float = 1e-4 # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å­¦ç¿’ç‡
    lr_decoder: float = 1e-4 # ãƒ‡ã‚³ãƒ¼ãƒ€å­¦ç¿’ç‡
    
    # ãƒ­ã‚°ãƒ»ä¿å­˜è¨­å®š
    log_interval: int = 5    # ãƒ­ã‚°å‡ºåŠ›é–“éš”ï¼ˆã‚¨ãƒãƒƒã‚¯ï¼‰
    save_interval: int = 10  # ãƒ¢ãƒ‡ãƒ«ä¿å­˜é–“éš”ï¼ˆã‚¨ãƒãƒƒã‚¯ï¼‰
    verbose: bool = True     # è©³ç´°ãƒ­ã‚°
    
    def __post_init__(self):
        """åˆæœŸåŒ–å¾Œã®å‹å¤‰æ›ã¨æ¤œè¨¼"""
        # æ•°å€¤å‹ã®ç¢ºå®Ÿãªå¤‰æ›ï¼ˆYAMLèª­ã¿è¾¼ã¿å¯¾ç­–ï¼‰
        self.phase1_epochs = int(self.phase1_epochs)
        self.T1_iterations = int(self.T1_iterations)
        self.T2_iterations = int(self.T2_iterations)
        self.df_a_warmup_epochs = int(self.df_a_warmup_epochs)
        self.phase2_epochs = int(self.phase2_epochs)
        self.log_interval = int(self.log_interval)
        self.save_interval = int(self.save_interval)
        
        # å­¦ç¿’ç‡ã®å‹å¤‰æ›
        self.lr_phi = float(self.lr_phi)
        self.lr_psi = float(self.lr_psi)
        self.lr_encoder = float(self.lr_encoder)
        self.lr_decoder = float(self.lr_decoder)
        self.lambda_cca = float(self.lambda_cca)
        
        # æ–‡å­—åˆ—å‹ã®æ­£è¦åŒ–
        self.update_strategy = str(self.update_strategy)
        
        # çœŸå½å€¤ã®å¤‰æ›ï¼ˆ"true"/"false"æ–‡å­—åˆ—å¯¾ç­–ï¼‰
        if isinstance(self.verbose, str):
            self.verbose = self.verbose.lower() in ('true', '1', 'yes', 'on')
        else:
            self.verbose = bool(self.verbose)

    @classmethod
    def from_nested_dict(cls, config_dict: Dict[str, Any]) -> 'TrainingConfig':
        """å…¥ã‚Œå­è¨­å®šè¾æ›¸ã‹ã‚‰å¹³å¦ãªTrainingConfigã‚’ä½œæˆ"""
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
        phase1_config = config_dict.get('phase1', {})
        phase2_config = config_dict.get('phase2', {})
        
        return cls(
            # Phase-1è¨­å®š
            phase1_epochs=phase1_config.get('epochs', 50),
            T1_iterations=phase1_config.get('T1_iterations', 10),
            T2_iterations=phase1_config.get('T2_iterations', 5),
            df_a_warmup_epochs=phase1_config.get('df_a', {}).get('warmup_epochs', 5),
            
            # Phase-2è¨­å®š
            phase2_epochs=phase2_config.get('epochs', 100),
            lambda_cca=phase2_config.get('lambda_cca', 0.1),
            update_strategy=phase2_config.get('update_strategy', "all"),
            
            # å­¦ç¿’ç‡ï¼ˆPhase-2å†…ã¾ãŸã¯ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã‹ã‚‰å–å¾—ï¼‰
            lr_phi=phase2_config.get('lr_phi', phase1_config.get('df_a', {}).get('lr', 1e-3)),
            lr_psi=phase2_config.get('lr_psi', phase1_config.get('df_b', {}).get('lr', 1e-3)),
            lr_encoder=phase2_config.get('lr_encoder', 1e-4),
            lr_decoder=phase2_config.get('lr_decoder', 1e-4),
            
            # ãƒ­ã‚°ãƒ»ä¿å­˜è¨­å®šï¼ˆãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã‹ã‚‰ï¼‰
            log_interval=config_dict.get('log_interval', 5),
            save_interval=config_dict.get('checkpoint', {}).get('save_every', 10),
            verbose=config_dict.get('verbose', True)
        )


class TrainingLogger:
    """å­¦ç¿’ãƒ­ã‚°ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    def __init__(self, output_dir: Path):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        self.phase1_csv_path = self.output_dir / 'phase1_training.csv'
        self.phase2_csv_path = self.output_dir / 'phase2_training.csv'
        
        # ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿
        self.phase1_logs = []
        self.phase2_logs = []
        
        # CSVåˆæœŸåŒ–
        self._initialize_csv_files()
    
    def _initialize_csv_files(self):
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ˜ãƒƒãƒ€ãƒ¼åˆæœŸåŒ–"""
        # Phase-1 CSV
        with open(self.phase1_csv_path, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([
                'epoch', 'phase', 'stage', 'iteration', 'loss', 
                'lr_phi', 'lr_psi'
            ])
        
        # Phase-2 CSV
        with open(self.phase2_csv_path, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([
                'epoch', 'total_loss', 'rec_loss', 'cca_loss',
                'lr_encoder', 'lr_decoder', 'lr_phi', 'lr_psi'
            ])
    
    def log_phase1(self, epoch: int, phase: TrainingPhase, stage: str, 
                   iteration: int, metrics: Dict[str, float], 
                   learning_rates: Dict[str, float]):
        """Phase-1ãƒ­ã‚°è¨˜éŒ²"""
        log_entry = {
            'epoch': epoch,
            'phase': phase.value,
            'stage': stage,
            'iteration': iteration,
            'metrics': metrics,
            'learning_rates': learning_rates
        }
        
        self.phase1_logs.append(log_entry)
        
        # CSVæ›¸ãè¾¼ã¿
        with open(self.phase1_csv_path, 'a', newline='') as f:
            writer = csv.writer(f)
            loss_value = metrics.get('stage1_loss') or metrics.get('stage2_loss', '')
            writer.writerow([
                epoch, phase.value, stage, iteration, loss_value,
                learning_rates.get('lr_phi', ''),
                learning_rates.get('lr_psi', '')
            ])
    
    def log_phase2(self, epoch: int, total_loss: float, rec_loss: float, 
                   cca_loss: float, learning_rates: Dict[str, float]):
        """Phase-2ãƒ­ã‚°è¨˜éŒ²"""
        log_entry = {
            'epoch': epoch,
            'total_loss': total_loss,
            'rec_loss': rec_loss,
            'cca_loss': cca_loss,
            'learning_rates': learning_rates
        }
        
        self.phase2_logs.append(log_entry)
        
        # CSVæ›¸ãè¾¼ã¿
        with open(self.phase2_csv_path, 'a', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([
                epoch, total_loss, rec_loss, cca_loss,
                learning_rates.get('lr_encoder', ''),
                learning_rates.get('lr_decoder', ''),
                learning_rates.get('lr_phi', ''),
                learning_rates.get('lr_psi', '')
            ])
    
    def save_summary(self):
        """å­¦ç¿’ã‚µãƒãƒªã‚’JSONã§ä¿å­˜"""
        summary = {
            'phase1_summary': {
                'total_epochs': len(set(log['epoch'] for log in self.phase1_logs)),
                'total_iterations': len(self.phase1_logs),
                'final_metrics': self.phase1_logs[-1]['metrics'] if self.phase1_logs else {}
            },
            'phase2_summary': {
                'total_epochs': len(self.phase2_logs),
                'final_loss': self.phase2_logs[-1]['total_loss'] if self.phase2_logs else None
            }
        }
        
        with open(self.output_dir / 'training_summary.json', 'w') as f:
            json.dump(summary, f, indent=2)


class TwoStageTrainer:
    """
    ææ¡ˆæ‰‹æ³•ã®2æ®µéšå­¦ç¿’æˆ¦ç•¥ã‚’å®Ÿè¡Œã™ã‚‹ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹
    
    çµ±åˆçš„ãªå­¦ç¿’ç®¡ç†:
    1. Phase-1: DF-A/DF-B ã®å”èª¿å­¦ç¿’
    2. Phase-2: End-to-endå¾®èª¿æ•´
    3. å­¦ç¿’éç¨‹ã®è©³ç´°ãƒ­ã‚°ãƒ»å¯è¦–åŒ–
    4. æ™‚é–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª¿æ•´ã¨ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
    """
    
    def __init__(self, encoder: nn.Module = None, decoder: nn.Module = None, realization: Realization = None,
                 df_state_config: Dict[str, Any] = None, df_obs_config: Dict[str, Any] = None,
                 training_config: TrainingConfig = None, device: torch.device = None, output_dir: str = None,
                 use_kalman_filtering: bool = True,
                calibration_ratio: float = 0.1,
                auto_inference_setup: bool = True,
                config: Dict[str, Any] = None):
        
        # configå¼•æ•°ãŒæ¸¡ã•ã‚ŒãŸå ´åˆã¯è¨­å®šã‹ã‚‰åˆæœŸåŒ–
        if config is not None:
            self._init_from_config(config, device, output_dir, use_kalman_filtering)
        else:
            # å¾“æ¥ã®å€‹åˆ¥å¼•æ•°ã‹ã‚‰ã®åˆæœŸåŒ–
            self._init_from_args(encoder, decoder, realization, df_state_config, df_obs_config,
                               training_config, device, output_dir, use_kalman_filtering,
                               calibration_ratio, auto_inference_setup)
    
    def _init_from_config(self, config: Dict[str, Any], device: torch.device, output_dir: str,
                         use_kalman_filtering: bool):
        """è¨­å®šè¾æ›¸ã‹ã‚‰ã®åˆæœŸåŒ–"""
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ï¼ˆæ–°ã—ã„time_invariantã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä½¿ç”¨ï¼‰
        encoder_config = config['model']['encoder'].copy()
        decoder_config = config['model']['decoder'].copy()

        # time_invariantç”¨ã®è¨­å®šèª¿æ•´
        if 'type' not in encoder_config:
            encoder_config['type'] = 'time_invariant'
        if 'output_dim' not in encoder_config:
            encoder_config['output_dim'] = encoder_config.get('channels', 32)

        encoder = time_invariantEncoder(**encoder_config)
        decoder = time_invariantDecoder(**decoder_config)

        # ç¢ºç‡å®Ÿç¾ï¼ˆæ–°ã—ã„ã‚¯ãƒ©ã‚¹å„ªå…ˆï¼‰
        realization_config = config['ssm']['realization']
        if config.get('evaluation', {}).get('use_new_realization', True):
            # StochasticRealizationWithEncoderã¯encoderå¼•æ•°ãŒå¿…è¦
            realization_config_copy = realization_config.copy()
            realization = StochasticRealizationWithEncoder(
                encoder=encoder,
                **realization_config_copy
            )
        else:
            realization = Realization(**realization_config)
        
        # è¨­å®šå¤‰æ›
        training_config = TrainingConfig.from_nested_dict(config['training'])
        
        # å€‹åˆ¥å¼•æ•°ã§ã®åˆæœŸåŒ–ã«å§”è­²
        calibration_ratio = config['training'].get('calibration_ratio', 0.25)
        auto_inference_setup = config['training'].get('auto_inference_setup', True)

        self._init_from_args(encoder, decoder, realization,
                           config['ssm']['df_state'], config['ssm']['df_observation'],
                           training_config, device, output_dir, use_kalman_filtering,
                           calibration_ratio, auto_inference_setup)

    @classmethod
    def from_trained_model(cls, model_path: str, device: torch.device = None,
                          output_dir: str = None) -> 'TwoStageTrainer':
        """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰æ¨è«–å°‚ç”¨ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¸è¦ï¼‰"""
        if device is None:
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        if output_dir is None:
            output_dir = 'temp_inference'

        # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        checkpoint = torch.load(model_path, map_location=device)
        if 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
        else:
            state_dict = checkpoint

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰æ§‹é€ æ¤œå‡º
        encoder_config = cls._detect_encoder_structure(state_dict.get('encoder', {}))
        decoder_config = cls._detect_decoder_structure(state_dict.get('decoder', {}))

        # æ¤œå‡ºã•ã‚ŒãŸæ§‹é€ ã§ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ï¼ˆæ–°ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä½¿ç”¨ï¼‰
        encoder = time_invariantEncoder(**encoder_config)
        decoder = time_invariantDecoder(**decoder_config)

        # æœ€å°é™ã®è¨­å®šã§åˆæœŸåŒ–
        realization = Realization(past_horizon=10, rank=3)
        df_state_config = {'feature_dim': 16}
        df_obs_config = {'obs_feature_dim': 8}
        training_config = TrainingConfig()

        # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        instance = cls._init_from_args_direct(
            encoder, decoder, realization, df_state_config, df_obs_config,
            training_config, device, output_dir, use_kalman_filtering=False
        )

        # é‡ã¿ã‚’èª­ã¿è¾¼ã¿
        instance.encoder.load_state_dict(state_dict.get('encoder', {}))
        instance.decoder.load_state_dict(state_dict.get('decoder', {}))

        return instance

    @classmethod
    def _detect_encoder_structure(cls, encoder_dict: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰æ§‹é€ æ¤œå‡ºï¼ˆtime_invariantå¯¾å¿œã€æ±ç”¨çš„ï¼‰"""
        input_dim = 6  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        output_dim = 32  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        architecture = 'mlp'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        hidden_dims = [64, 32]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

        # æ§‹é€ ã®è‡ªå‹•æ¤œå‡º
        if not encoder_dict:
            # ç©ºã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
            pass
        elif 'core_net.0.weight' in encoder_dict:
            # time_invariantã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ¤œå‡º
            architecture = 'mlp'

            # å…¥åŠ›æ¬¡å…ƒï¼ˆcore_netã®æœ€åˆã®å±¤ï¼‰
            input_dim = encoder_dict['core_net.0.weight'].shape[1]

            # output_dimï¼ˆoutput_meanã‹ã‚‰æ¤œå‡ºï¼‰
            if 'output_mean' in encoder_dict:
                output_dim = encoder_dict['output_mean'].shape[0]
            else:
                # core_netã®æœ€çµ‚å±¤ã‹ã‚‰æ¨å®š
                for key in encoder_dict.keys():
                    if key.startswith('core_net.') and key.endswith('.weight'):
                        output_dim = encoder_dict[key].shape[0]

            # éš ã‚Œå±¤æ¬¡å…ƒã®æ¤œå‡º
            hidden_dims = []
            layer_keys = [k for k in encoder_dict.keys() if k.startswith('core_net.') and k.endswith('.weight')]
            layer_keys.sort(key=lambda x: int(x.split('.')[1]))

            for i, key in enumerate(layer_keys[:-1]):  # æœ€çµ‚å±¤ä»¥å¤–
                hidden_dims.append(encoder_dict[key].shape[0])

        elif 'layers.0.weight' in encoder_dict:
            # MLPæ§‹é€ ã®æ¤œå‡º
            architecture = 'mlp'

            # å…¥åŠ›æ¬¡å…ƒï¼ˆæœ€åˆã®ç·šå½¢å±¤ï¼‰
            input_dim = encoder_dict['layers.0.weight'].shape[1]

            # éš ã‚Œå±¤æ¬¡å…ƒã¨output_dimã®æ¤œå‡º
            hidden_dims = []
            max_layer_idx = -1

            for key in encoder_dict.keys():
                if key.startswith('layers.') and key.endswith('.weight'):
                    try:
                        layer_idx = int(key.split('.')[1])
                        max_layer_idx = max(max_layer_idx, layer_idx)

                        # éš ã‚Œå±¤ã®å‡ºåŠ›æ¬¡å…ƒã‚’åé›†
                        if layer_idx > 0:  # æœ€åˆã®å±¤ä»¥å¤–
                            layer_output_dim = encoder_dict[key].shape[0]
                            if layer_idx == max_layer_idx:
                                output_dim = layer_output_dim  # æœ€çµ‚å±¤ãŒå‡ºåŠ›æ¬¡å…ƒ
                            else:
                                hidden_dims.append(layer_output_dim)
                    except (ValueError, IndexError):
                        continue

            if not hidden_dims:
                hidden_dims = [64, 32]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

        elif any(key.startswith('tcn.') for key in encoder_dict.keys()):
            # æ—§TCNæ§‹é€ ï¼ˆå¾Œæ–¹äº’æ›ï¼‰- time_invariantã«ãƒãƒƒãƒ”ãƒ³ã‚°
            architecture = 'mlp'  # time_invariantã®mlpã«ãƒãƒƒãƒ”ãƒ³ã‚°

            if 'in_proj.weight' in encoder_dict:
                input_dim = encoder_dict['in_proj.weight'].shape[1]
                output_dim = encoder_dict['in_proj.weight'].shape[0]

        elif any(key.startswith('conv') for key in encoder_dict.keys()):
            # CNNç³»æ§‹é€ 
            architecture = 'resnet'  # time_invariantã®resnetã«ãƒãƒƒãƒ”ãƒ³ã‚°

            # æœ€åˆã®convå±¤ã‹ã‚‰å…¥åŠ›æ¬¡å…ƒæ¨å®š
            first_conv_keys = [k for k in encoder_dict.keys() if 'conv' in k and 'weight' in k]
            if first_conv_keys:
                first_key = sorted(first_conv_keys)[0]
                # convå±¤ã®å ´åˆã€å…¥åŠ›ãƒãƒ£ãƒ³ãƒãƒ«æ•°ã‚’å–å¾—
                conv_shape = encoder_dict[first_key].shape
                if len(conv_shape) >= 2:
                    input_dim = conv_shape[1] if len(conv_shape) == 4 else conv_shape[1]
        else:
            # ãã®ä»–ã®æ§‹é€  - æœ€å°é™ã®æ¨å®š
            weight_keys = [k for k in encoder_dict.keys() if 'weight' in k]
            if weight_keys:
                # æœ€åˆã®weightå±¤ã‹ã‚‰æ¨å®š
                first_weight = encoder_dict[weight_keys[0]]
                if len(first_weight.shape) >= 2:
                    input_dim = first_weight.shape[1]
                    output_dim = first_weight.shape[0]

        return {
            'type': 'time_invariant',
            'input_dim': input_dim,
            'output_dim': output_dim,
            'architecture': architecture,
            'hidden_dims': hidden_dims,
            'activation': 'GELU',
            'dropout': 0.1,
            'normalize_input': True,
            'normalize_output': True
        }

    @classmethod
    def _detect_decoder_structure(cls, decoder_dict: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰æ§‹é€ æ¤œå‡ºï¼ˆtime_invariantå¯¾å¿œã€æ±ç”¨çš„ï¼‰"""
        input_dim = 32  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼å‡ºåŠ›ã¨ä¸€è‡´æƒ³å®šï¼‰
        output_dim = 6  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        architecture = 'mlp'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        hidden_dims = [64, 32]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

        # æ§‹é€ ã®è‡ªå‹•æ¤œå‡º
        if not decoder_dict:
            # ç©ºã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
            pass
        elif 'net.0.weight' in decoder_dict:
            # time_invariantDecoderã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ¤œå‡º
            architecture = 'mlp'

            # å…¥åŠ›æ¬¡å…ƒï¼ˆnetã®æœ€åˆã®å±¤ï¼‰
            input_dim = decoder_dict['net.0.weight'].shape[1]

            # å‡ºåŠ›æ¬¡å…ƒï¼ˆnetã®æœ€çµ‚å±¤ï¼‰
            output_dim = 6  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            for key in decoder_dict.keys():
                if key.startswith('net.') and key.endswith('.weight'):
                    output_dim = decoder_dict[key].shape[0]

            # éš ã‚Œå±¤æ¬¡å…ƒã®æ¤œå‡º
            hidden_dims = []
            layer_keys = [k for k in decoder_dict.keys() if k.startswith('net.') and k.endswith('.weight')]
            layer_keys.sort(key=lambda x: int(x.split('.')[1]))

            for key in layer_keys[:-1]:  # æœ€çµ‚å±¤ä»¥å¤–
                hidden_dims.append(decoder_dict[key].shape[0])

        elif 'layers.0.weight' in decoder_dict:
            # MLPæ§‹é€ ã®æ¤œå‡º
            architecture = 'mlp'

            # å…¥åŠ›æ¬¡å…ƒï¼ˆæœ€åˆã®ç·šå½¢å±¤ï¼‰
            input_dim = decoder_dict['layers.0.weight'].shape[1]

            # éš ã‚Œå±¤æ¬¡å…ƒã¨output_dimã®æ¤œå‡º
            hidden_dims = []
            max_layer_idx = -1

            for key in decoder_dict.keys():
                if key.startswith('layers.') and key.endswith('.weight'):
                    try:
                        layer_idx = int(key.split('.')[1])
                        max_layer_idx = max(max_layer_idx, layer_idx)

                        # éš ã‚Œå±¤ã®å‡ºåŠ›æ¬¡å…ƒã‚’åé›†
                        if layer_idx > 0:  # æœ€åˆã®å±¤ä»¥å¤–
                            layer_output_dim = decoder_dict[key].shape[0]
                            if layer_idx == max_layer_idx:
                                output_dim = layer_output_dim  # æœ€çµ‚å±¤ãŒå‡ºåŠ›æ¬¡å…ƒ
                            else:
                                hidden_dims.append(layer_output_dim)
                    except (ValueError, IndexError):
                        continue

            if not hidden_dims:
                hidden_dims = [64, 32]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

        elif 'out_proj.weight' in decoder_dict:
            # æ—§TCNç³»æ§‹é€ ï¼ˆå¾Œæ–¹äº’æ›ï¼‰- time_invariantã«ãƒãƒƒãƒ”ãƒ³ã‚°
            architecture = 'mlp'
            output_dim = decoder_dict['out_proj.weight'].shape[0]

            if 'takens_proj.weight' in decoder_dict:
                input_dim = decoder_dict['takens_proj.weight'].shape[1]

        elif any(key.startswith('conv') for key in decoder_dict.keys()):
            # CNNç³»æ§‹é€ 
            architecture = 'resnet'

            # convå±¤ã‹ã‚‰æ¬¡å…ƒæ¨å®š
            conv_keys = [k for k in decoder_dict.keys() if 'conv' in k and 'weight' in k]
            if conv_keys:
                # æœ€å¾Œã®convå±¤ã‹ã‚‰å‡ºåŠ›æ¬¡å…ƒæ¨å®š
                last_key = sorted(conv_keys)[-1]
                conv_shape = decoder_dict[last_key].shape
                if len(conv_shape) >= 2:
                    output_dim = conv_shape[0] if len(conv_shape) == 4 else conv_shape[0]
        else:
            # ãã®ä»–ã®æ§‹é€  - æœ€å°é™ã®æ¨å®š
            weight_keys = [k for k in decoder_dict.keys() if 'weight' in k]
            if weight_keys:
                # æœ€å¾Œã®weightå±¤ã‹ã‚‰å‡ºåŠ›æ¬¡å…ƒæ¨å®š
                last_weight = decoder_dict[weight_keys[-1]]
                if len(last_weight.shape) >= 2:
                    output_dim = last_weight.shape[0]
                    input_dim = last_weight.shape[1]

        return {
            'type': 'time_invariant',
            'input_dim': input_dim,
            'output_dim': output_dim,
            'architecture': architecture,
            'hidden_dims': hidden_dims,
            'activation': 'GELU',
            'dropout': 0.1,
            'normalize_input': True,
            'normalize_output': True
        }

    @classmethod
    def _init_from_args_direct(cls, encoder, decoder, realization, df_state_config,
                              df_obs_config, training_config, device, output_dir,
                              use_kalman_filtering):
        """ç›´æ¥åˆæœŸåŒ–ï¼ˆã‚¯ãƒ©ã‚¹ãƒ¡ã‚½ãƒƒãƒ‰ç”¨ï¼‰"""
        instance = cls.__new__(cls)
        instance._init_from_args(encoder, decoder, realization, df_state_config,
                               df_obs_config, training_config, device, output_dir,
                               use_kalman_filtering, calibration_ratio=0.1,
                               auto_inference_setup=False)
        return instance
    
    def _init_from_args(self, encoder: nn.Module, decoder: nn.Module, realization: Realization,
                       df_state_config: Dict[str, Any], df_obs_config: Dict[str, Any],
                       training_config: TrainingConfig, device: torch.device, output_dir: str,
                       use_kalman_filtering: bool, calibration_ratio: float = 0.1,
                       auto_inference_setup: bool = True):
        """å€‹åˆ¥å¼•æ•°ã‹ã‚‰ã®åˆæœŸåŒ–"""
        # åŸºæœ¬è¨­å®š
        self.encoder = encoder.to(device)
        self.decoder = decoder.to(device)
        self.realization = realization
        self.config = training_config
        self.device = device
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # **ä¿®æ­£4: æ™‚é–“èª¿æ•´ç”¨ã®çŠ¶æ…‹ç®¡ç†**
        self._last_X_states_length = None  # çŠ¶æ…‹ç³»åˆ—é•·ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        
        # ===== è¿½åŠ ï¼šKalmané–¢é€£è¨­å®š =====
        self.use_kalman_filtering = use_kalman_filtering
        self.calibration_ratio = calibration_ratio
        self.auto_inference_setup = auto_inference_setup
        
        # ===== è¿½åŠ ï¼šKalmanç”¨ãƒ‡ãƒ¼ã‚¿ =====
        self.calibration_data: Optional[torch.Tensor] = None
        self.inference_model: Optional[Any] = None

        # DF layersè¨­å®šä¿å­˜
        self.df_state_config = df_state_config
        self.df_obs_config = df_obs_config
        
        # å­¦ç¿’çŠ¶æ…‹
        self.df_state = None
        self.df_obs = None
        self.optimizers = {}
        self.current_epoch = 0
        self.phase1_complete = False
        
        # å­¦ç¿’å±¥æ­´
        self.training_history = {
            'phase1_metrics': [],
            'phase2_losses': []
        }
        
        # ä¸€æ™‚ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        self._temp_data = {}
        
        # ãƒ­ã‚°ç®¡ç†
        self.logger = TrainingLogger(self.output_dir)
        
        print(f"TwoStageTraineråˆæœŸåŒ–å®Œäº†: {device}")
    
    def _initialize_df_layers(self, X_states: torch.Tensor):
        """DF layersåˆæœŸåŒ–ï¼ˆGPUçµ±ä¸€ç‰ˆï¼‰"""
        # DF-AåˆæœŸåŒ–
        _, r = X_states.shape
        self.df_state = DFStateLayer(
            state_dim=r,
            feature_dim=self.df_state_config['feature_dim'],
            lambda_A=self.df_state_config['lambda_A'],
            lambda_B=self.df_state_config['lambda_B'],
            feature_net_config=self.df_state_config.get('feature_net'),
            cross_fitting_config=self.df_state_config.get('cross_fitting')
        )
        
        # DF-Aã®å†…éƒ¨ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’GPUã«ç§»å‹•
        self.df_state.phi_theta = self.df_state.phi_theta.to(self.device)
        
        # DF-BåˆæœŸåŒ–
        self.df_obs = DFObservationLayer(
            df_state_layer=self.df_state,
            obs_feature_dim=self.df_obs_config['obs_feature_dim'],
            lambda_B=self.df_obs_config['lambda_B'],
            lambda_dB=self.df_obs_config['lambda_dB'],
            obs_net_config=self.df_obs_config.get('obs_net'),
            cross_fitting_config=self.df_obs_config.get('cross_fitting')
        )
        # DF-Bã®å†…éƒ¨ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’GPUã«ç§»å‹•
        self.df_obs.psi_omega = self.df_obs.psi_omega.to(self.device)
        
        print(f"DF layersåˆæœŸåŒ–å®Œäº†: state_dim={r}")
    
    def _initialize_optimizers(self):
        """æœ€é©åŒ–å™¨åˆæœŸåŒ–"""
        # Phase-1ç”¨ã®å€‹åˆ¥æœ€é©åŒ–å™¨
        self.optimizers['phi'] = torch.optim.Adam(
            self.df_state.phi_theta.parameters(), 
            lr=self.config.lr_phi
        )
        
        self.optimizers['psi'] = torch.optim.Adam(
            self.df_obs.psi_omega.parameters(), 
            lr=self.config.lr_psi
        )
        
        # Phase-2ç”¨ã®çµ±åˆæœ€é©åŒ–å™¨
        if self.config.update_strategy == "all":
            # å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°
            phase2_params = list(self.encoder.parameters()) + \
                           list(self.decoder.parameters()) + \
                           list(self.df_state.phi_theta.parameters()) + \
                           list(self.df_obs.psi_omega.parameters())
        else:
            # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ»ãƒ‡ã‚³ãƒ¼ãƒ€ã®ã¿æ›´æ–°
            phase2_params = list(self.encoder.parameters()) + \
                           list(self.decoder.parameters())
        
        self.optimizers['e2e'] = torch.optim.Adam([
            {'params': self.encoder.parameters(), 'lr': self.config.lr_encoder},
            {'params': self.decoder.parameters(), 'lr': self.config.lr_decoder},
            {'params': self.df_state.phi_theta.parameters(), 'lr': self.config.lr_phi},
            {'params': self.df_obs.psi_omega.parameters(), 'lr': self.config.lr_psi}
        ])
        
        print("æœ€é©åŒ–å™¨åˆæœŸåŒ–å®Œäº†")
    
    def _prepare_data(self, Y_train: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        **å¤šå¤‰é‡å¯¾å¿œç‰ˆ**: ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆStochasticRealizationWithEncoderä½¿ç”¨ï¼‰

        Returns:
            M_features: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å‡ºåŠ›ç³»åˆ— (T, m) - å¤šå¤‰é‡ç‰¹å¾´é‡
            X_states: çŠ¶æ…‹æ¨å®šç³»åˆ— (T_eff, r)
        """
        print(f"ğŸ“Š å…¥åŠ›ãƒ‡ãƒ¼ã‚¿: Y_train.shape = {Y_train.shape}")

        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’GPUã«ç§»å‹•
        Y_train = self._ensure_device(Y_train)

        # 1. ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰: y_t â†’ m_t âˆˆ R^mï¼ˆå¤šå¤‰é‡ç‰¹å¾´é‡ï¼‰
        with torch.no_grad():
            self.encoder.eval()  # BatchNormç­‰ã®æ­£ç¢ºãªæ¨è«–

            if Y_train.dim() == 2:
                # (T, d) â†’ (1, T, d) for TCN
                Y_batch = Y_train.unsqueeze(0)
                M_batch = self.encoder(Y_batch).squeeze(0)  # (T, m)
            else:
                M_batch = self.encoder(Y_train)

            # å¤šå¤‰é‡ç‰¹å¾´é‡ã®å½¢çŠ¶ç¢ºèª
            if M_batch.dim() == 1:
                # ã‚¹ã‚«ãƒ©ãƒ¼å‡ºåŠ› â†’ (T, 1)ã«å¤‰æ›
                M_features = M_batch.unsqueeze(1)
            elif M_batch.dim() == 2:
                # æ­£å¸¸ãªå¤šå¤‰é‡ç‰¹å¾´é‡ (T, m)
                M_features = M_batch
            else:
                raise ValueError(f"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å‡ºåŠ›ã®å½¢çŠ¶ãŒä¸æ­£: {M_batch.shape}. æœŸå¾…: (T, m)")

        print(f"ğŸ“Š ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å‡ºåŠ›: M_features.shape = {M_features.shape} (å¤šå¤‰é‡ç‰¹å¾´é‡)")

        # 2. StochasticRealizationWithEncoderã‚’ä½¿ç”¨ã—ã¦å¤šå¤‰é‡ç‰¹å¾´é‡ã‚’ç›´æ¥å‡¦ç†
        
        # ===== è¿½åŠ ï¼šã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿åˆ†å‰² =====
        if hasattr(self, 'use_kalman_filtering') and self.use_kalman_filtering:
            n_calib = int(Y_train.size(0) * getattr(self, 'calibration_ratio', 0.1))
            self.calibration_data = Y_train[:n_calib].clone()
            if self.config.verbose:
                print(f"Calibration data prepared: {self.calibration_data.shape}")

        # 2. StochasticRealizationWithEncoderã‚’ä½¿ç”¨ã—ãŸç¢ºç‡çš„å®Ÿç¾
        try:
            if isinstance(self.realization, StochasticRealizationWithEncoder):
                # å¤šå¤‰é‡ç‰¹å¾´é‡ã‚’ç›´æ¥å‡¦ç†: Y_train + encoder â†’ x_t
                self.realization.fit(Y_train, self.encoder)
                X_states = self.realization.estimate_states(Y_train)
                print(f"ğŸ“Š StochasticRealizationä½¿ç”¨: {Y_train.shape} â†’ M_features={M_features.shape} â†’ X_states={X_states.shape}")
            else:
                # å¾“æ¥ã®Realizationã®å ´åˆï¼šå¤šå¤‰é‡ç‰¹å¾´é‡ã‚’ã‚¹ã‚«ãƒ©ãƒ¼åŒ–
                m_scalar = M_features.mean(dim=1)  # (T, m) â†’ (T,) ã‚¹ã‚«ãƒ©ãƒ¼ç‰¹å¾´é‡
                self.realization.fit(m_scalar.unsqueeze(1))  # (T,) â†’ (T, 1)
                X_states = self.realization.filter(m_scalar.unsqueeze(1))
                print(f"ğŸ“Š å¾“æ¥Realizationä½¿ç”¨: M_features={M_features.shape} â†’ m_scalar={m_scalar.shape} â†’ X_states={X_states.shape}")
        except RealizationError as e:
            print(f"âš ï¸ RealizationErrorç™ºç”Ÿ: {e}")
            # RealizationErrorã‚’ä¸Šä½ã«å†æŠ•ã’ã—ã¦å®Œå…¨ã‚¨ãƒãƒƒã‚¯ã‚¹ã‚­ãƒƒãƒ—ã‚’å®Ÿè¡Œ
            raise RealizationError(f"Phase1 realization failed: {e}") from e

        # ===== è¿½åŠ ï¼šKalmanä½¿ç”¨æ™‚ã®åˆ†å²å‡¦ç†ï¼ˆStochasticRealizationWithEncoderå¯¾å¿œï¼‰=====
        if (hasattr(self, 'use_kalman_filtering') and self.use_kalman_filtering and
            hasattr(self, 'phase1_complete') and self.phase1_complete and
            hasattr(self, 'df_state') and self.df_state is not None and
            hasattr(self, 'df_obs') and self.df_obs is not None):

            try:
                if isinstance(self.realization, StochasticRealizationWithEncoder):
                    # StochasticRealizationWithEncoderã®å ´åˆï¼šå¤šå¤‰é‡ç‰¹å¾´é‡ã§Kalman
                    X_means, X_covariances = self.realization.filter_with_kalman(
                        M_features, self.df_state, self.df_obs
                    )
                else:
                    # å¾“æ¥Realizationã®å ´åˆï¼šã‚¹ã‚«ãƒ©ãƒ¼ç‰¹å¾´é‡ã§Kalman
                    m_scalar = M_features.mean(dim=1)
                    X_means, X_covariances = self.realization.filter_with_kalman(
                        m_scalar, self.df_state, self.df_obs
                    )

                if self.config.verbose:
                    print(f"Kalman filtering applied: {X_means.shape}")

                # ===== é‡è¦ï¼šå…±åˆ†æ•£ã¯å†…éƒ¨ä¿å­˜ã€æˆ»ã‚Šå€¤ã¯æ—¢å­˜å½¢å¼ =====
                self._last_covariances = X_covariances  # æ–°ã—ã„å†…éƒ¨å±æ€§
                X_states = X_means  # æ—¢å­˜å¤‰æ•°åã§è¿”ã™

            except Exception as e:
                warnings.warn(f"Kalman filtering failed, using deterministic: {e}")
                # Kalmanå¤±æ•—æ™‚ã¯ä¸Šè¨˜ã§è¨ˆç®—æ¸ˆã¿ã®X_statesã‚’ä½¿ç”¨
                self._last_covariances = None
        
        # **ä¿®æ­£4: çŠ¶æ…‹ç³»åˆ—é•·ã‚’è¨˜éŒ²ï¼ˆæ™‚é–“èª¿æ•´ç”¨ï¼‰**
        self._last_X_states_length = X_states.size(0)

        if self.config.verbose:
            print(f"çŠ¶æ…‹æ¨å®šå®Œäº†: M_features={M_features.shape} -> X_states={X_states.shape}")

        # ä¸€æ™‚ä¿å­˜ï¼ˆå¤šå¤‰é‡ç‰¹å¾´é‡å¯¾å¿œï¼‰
        self._temp_data = {
            'Y_train': Y_train,
            'M_features': M_features,  # å¤šå¤‰é‡ç‰¹å¾´é‡
            'X_states': X_states
        }

        return M_features, X_states  # å¤šå¤‰é‡ç‰¹å¾´é‡ã‚’è¿”ã™
    
    def train_phase1(self, Y_train: torch.Tensor) -> Dict[str, Any]:
        """
        Phase-1: DF-A/DF-B ã®å”èª¿å­¦ç¿’
        
        Args:
            Y_train: è¨“ç·´è¦³æ¸¬ç³»åˆ— (T, d)
            
        Returns:
            Phase-1ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        """
        print("\n=== Phase-1: DFå­¦ç¿’é–‹å§‹ ===")

        # ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆå¤šå¤‰é‡ç‰¹å¾´é‡å¯¾å¿œï¼‰
        M_features, X_states = self._prepare_data(Y_train)
        
        # DF layersåˆæœŸåŒ–
        self._initialize_df_layers(X_states)
        self._initialize_optimizers()
        
        # Phase-1å­¦ç¿’ãƒ«ãƒ¼ãƒ—
        for epoch in range(self.config.phase1_epochs):
            self.current_epoch = epoch
            epoch_metrics = {}
            
            # DF-Aå­¦ç¿’
            df_a_metrics = self._train_df_a_epoch(X_states, epoch)
            epoch_metrics.update(df_a_metrics)
            
            # DF-Bå­¦ç¿’ï¼ˆã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å¾Œï¼‰
            if epoch >= self.config.df_a_warmup_epochs:
                df_b_metrics = self._train_df_b_epoch(X_states, M_features, epoch)
                epoch_metrics.update(df_b_metrics)
            
            # ãƒ­ã‚°è¨˜éŒ²
            self.training_history['phase1_metrics'].append(epoch_metrics)
            
            # ãƒ­ã‚°å‡ºåŠ›
            if epoch % self.config.log_interval == 0 and self.config.verbose:
                self._print_phase1_progress(epoch, epoch_metrics)
                # å¤šå¤‰é‡å¯¾å¿œã®è¿½åŠ ãƒ­ã‚°
                self.log_multivariate_training_progress(epoch, "phase1")
            
            # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
            if epoch % self.config.save_interval == 0:
                self._save_checkpoint(epoch, TrainingPhase.PHASE1_DF_A)
        
        # Phase-1å®Œäº†å¾Œ: DFLayerã®fit()ã§V_A/V_B/U_A/u_Bã‚’è¨ˆç®—
        print("ğŸ”„ æœ€çµ‚ä½œç”¨ç´ ï¼ˆV_A/V_B/U_A/u_Bï¼‰è¨ˆç®—ä¸­...")
        self._compute_final_operators(Y_train)

        self.phase1_complete = True
        print("Phase-1 å­¦ç¿’å®Œäº†")

        return self.training_history['phase1_metrics']

    def _compute_final_operators(self, Y_train: torch.Tensor):
        """Phase-1å®Œäº†å¾Œã«æœ€çµ‚ä½œç”¨ç´ V_A/V_B/U_A/U_Bã‚’è¨ˆç®—ï¼ˆå¤šå¤‰é‡ç‰¹å¾´é‡å¯¾å¿œï¼‰"""
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆå¤šå¤‰é‡ç‰¹å¾´é‡å¯¾å¿œï¼‰
        M_features, X_states = self._prepare_data(Y_train)

        # DFStateLayerç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™
        with torch.no_grad():
            # çŠ¶æ…‹ç‰¹å¾´é‡è¨ˆç®—: Ï†_Î¸(x_t)
            Phi_full = self.df_state.phi_theta(X_states)  # (T, d_A)

            # æ™‚é–“ã‚·ãƒ•ãƒˆã—ãŸãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆå…ƒã®å­¦ç¿’ã¨åŒã˜æ™‚é–“å¯¾å¿œï¼‰
            Phi_minus = Phi_full[:-1]  # Ï†(x_{t-1}): t=0,...,T-2
            Phi_plus = Phi_full[1:]    # Ï†(x_t): t=1,...,T-1
            X_plus = X_states[1:]      # x_{t}: t=1,...,T-1 (å…ƒã®å­¦ç¿’ã¨åŒã˜)

        # DF-A: V_A, U_Aè¨ˆç®—
        print("  ğŸ”„ DF-Aä½œç”¨ç´ ï¼ˆV_A/U_Aï¼‰è¨ˆç®—ä¸­...")
        if hasattr(self.df_state, 'cf_config') and self.df_state.cf_config:
            self.df_state._fit_with_cross_fitting(Phi_minus, Phi_plus, X_plus, verbose=True)
        else:
            self.df_state._fit_without_cross_fitting(Phi_minus, Phi_plus, X_plus, verbose=True)

        print(f"  âœ… V_A shape: {self.df_state.V_A.shape}, U_A shape: {self.df_state.U_A.shape}")

        # DFObservationLayerç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆDF-Aã®çµæœã‚’ä½¿ç”¨ï¼‰
        if hasattr(self, 'df_obs') and self.df_obs is not None:
            print("  ğŸ”„ DF-Bä½œç”¨ç´ ï¼ˆV_B/u_Bï¼‰è¨ˆç®—ä¸­...")

            # DF-Aã«ã‚ˆã‚‹1ã‚¹ãƒ†ãƒƒãƒ—äºˆæ¸¬ã¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å‡ºåŠ›ã®æ­£ã—ã„ä½¿ç”¨
            with torch.no_grad():
                # 1ã‚¹ãƒ†ãƒƒãƒ—äºˆæ¸¬: xÌ‚_{t|t-1} = U_A^T V_A Ï†(x_{t-1})
                X_pred = (self.df_state.U_A.T @ (self.df_state.V_A @ Phi_minus.T)).T  # (T-1, d_x)
                # äºˆæ¸¬ã‚’ç‰¹å¾´é‡åŒ–: Ï†_Î¸(xÌ‚_{t|t-1})
                Phi_pred = self.df_state.phi_theta(X_pred)  # (T-1, d_A)

                # realizationã®æ™‚é–“çŸ­ç¸®ã‚’è€ƒæ…®ã—ãŸå¤šå¤‰é‡ç‰¹å¾´é‡ã®å–å¾—
                # realization: T -> T_eff = T - 2*h + 1ã®çŸ­ç¸®
                if isinstance(self.realization, StochasticRealizationWithEncoder):
                    # StochasticRealizationWithEncoderã®å ´åˆ
                    h = getattr(self.realization, 'window_length', 5)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                else:
                    # å¾“æ¥Realizationã®å ´åˆ
                    h = self.realization.h
                T_states = X_states.shape[0]  # realizationå¾Œã®çŠ¶æ…‹ç³»åˆ—é•·

                # å¤šå¤‰é‡ç‰¹å¾´é‡ã®æ­£ã—ã„ç¯„å›²ï¼ˆrealizationã¨åŒã˜æ™‚é–“ç¯„å›²ï¼‰
                M_curr = M_features[h:h+T_states]  # M_t: realizationç¯„å›²ã¨ä¸€è‡´ (T_states, m)

                # è¦³æ¸¬ç‰¹å¾´é‡: Ïˆ_Ï‰(M_t) - å¤šå¤‰é‡å¯¾å¿œ
                Psi_curr = self.df_obs.psi_omega(M_curr)  # (T_states, d_B)

                # åŒæ™‚åˆ»ã®å¤šå¤‰é‡ç‰¹å¾´é‡
                m_curr = M_curr  # M_t (T_states, m)

                # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºèª¿æ•´ï¼ˆæœ€å°ã‚µã‚¤ã‚ºã«åˆã‚ã›ã‚‹ï¼‰
                min_size = min(Phi_pred.shape[0], Psi_curr.shape[0], m_curr.shape[0])
                Phi_pred = Phi_pred[:min_size]  # Ï†_Î¸(xÌ‚_{t|t-1})
                Psi_curr = Psi_curr[:min_size]  # Ïˆ_Ï‰(h_t)
                m_curr = m_curr[:min_size]     # m_t

            print(f"    ğŸ“Š DF-Bå­¦ç¿’ãƒ‡ãƒ¼ã‚¿: Phi_pred={Phi_pred.shape}, Psi_curr={Psi_curr.shape}, m_curr={m_curr.shape}")
            print(f"    ğŸ• æ™‚é–“ç¯„å›²: h={h}, T_states={T_states}, range=[{h}:{h+T_states}]")

            # DF-B: V_B, u_Bè¨ˆç®— (Ï†_Î¸(xÌ‚_{t|t-1}) â†’ Ïˆ_Ï‰(h_t)ã®å†™åƒå­¦ç¿’)
            if hasattr(self.df_obs, 'cf_config') and self.df_obs.cf_config:
                self.df_obs._fit_with_cross_fitting(Phi_pred, Psi_curr, m_curr, verbose=True)
            else:
                self.df_obs._fit_without_cross_fitting(Phi_pred, Psi_curr, m_curr, verbose=True)

            print(f"  âœ… V_B shape: {self.df_obs.V_B.shape}, U_B shape: {self.df_obs.U_B.shape}")

        print("ğŸ”„ æœ€çµ‚ä½œç”¨ç´ è¨ˆç®—å®Œäº†")

    def _train_df_a_epoch(self, X_states: torch.Tensor, epoch: int) -> Dict[str, float]:
        """
        **ä¿®æ­£2çµ±åˆ**: DF-Aï¼ˆçŠ¶æ…‹å±¤ï¼‰ã®ã‚¨ãƒãƒƒã‚¯å­¦ç¿’ï¼ˆå®Œå…¨ã‚°ãƒ©ãƒ•åˆ†é›¢ç‰ˆï¼‰
        """
        metrics = {}
        opt_phi = self.optimizers['phi']
        
        # **è¿½åŠ **: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’GPUã«ç§»å‹•
        X_states_gpu = X_states.to(self.device)
        
        # **ä¿®æ­£2: å®Œå…¨ã«ãƒ‡ã‚¿ãƒƒãƒã•ã‚ŒãŸå…¥åŠ›ã§ç‹¬ç«‹ã‚°ãƒ©ãƒ•ä½œæˆ**
        X_states_detached = X_states_gpu.detach().requires_grad_(False)
        
        # **ä¿®æ­£2: ç‹¬ç«‹è¨ˆç®—ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§DF-Aå­¦ç¿’**
        with torch.enable_grad():
            stage1_metrics = self.df_state.train_stage1_with_gradients(
                X_states_detached, 
                opt_phi,
                T1_iterations=self.config.T1_iterations
            )
        
        metrics['df_a_stage1_loss'] = stage1_metrics['stage1_loss']
        
        # ãƒ­ã‚°è¨˜éŒ²
        self.logger.log_phase1(
            epoch, TrainingPhase.PHASE1_DF_A, 'stage1', 0,
            stage1_metrics, {'lr_phi': opt_phi.param_groups[0]['lr']}
        )
        
        # Stage-2: U_Aæ¨å®šï¼ˆä¸€åº¦ã ã‘å®Ÿè¡Œï¼‰
        with torch.no_grad():  # **ä¿®æ­£2: Stage-2ã¯å‹¾é…ãªã—**
            stage2_metrics = self.df_state.train_stage2_closed_form()

            # ãƒ­ã‚°è¨˜éŒ²
            self.logger.log_phase1(
                epoch, TrainingPhase.PHASE1_DF_A, 'stage2', 0,
                stage2_metrics, {}
            )

        metrics['df_a_stage2_loss'] = stage2_metrics['stage2_loss']
        
        # **ä¿®æ­£2: æ˜ç¤ºçš„ã‚°ãƒ©ãƒ•ã‚¯ãƒªã‚¢**
        self._clear_computation_graph()
        
        return metrics
    
    def _train_df_b_epoch(self, X_states: torch.Tensor, M_features: torch.Tensor,
                        epoch: int) -> Dict[str, float]:
        """
        **å¤šå¤‰é‡å¯¾å¿œç‰ˆ**: DF-Bï¼ˆè¦³æ¸¬å±¤ï¼‰ã®ã‚¨ãƒãƒƒã‚¯å­¦ç¿’ï¼ˆè¨ˆç®—ã‚°ãƒ©ãƒ•é‡è¤‡ä½¿ç”¨ã‚¨ãƒ©ãƒ¼å¯¾å¿œï¼‰
        """
        metrics = {}
        opt_phi = self.optimizers['phi']
        opt_psi = self.optimizers['psi']

        # **è¿½åŠ **: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’GPUã«ç§»å‹•
        X_states_gpu = X_states.to(self.device)
        M_features_gpu = M_features.to(self.device)

        # **ä¿®æ­£2: å®Œå…¨ã«ãƒ‡ã‚¿ãƒƒãƒã•ã‚ŒãŸå…¥åŠ›ã§ç‹¬ç«‹ã‚°ãƒ©ãƒ•ä½œæˆ**
        X_states_detached = X_states_gpu.detach().requires_grad_(False)
        
        # **ä¿®æ­£2: ç‹¬ç«‹è¨ˆç®—ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§DF-Bå­¦ç¿’**
        with torch.enable_grad():
            # DF-Aã‹ã‚‰ã®çŠ¶æ…‹äºˆæ¸¬ã‚’å–å¾—ï¼ˆæ“ä½œå¤‰æ•°ã¨ã—ã¦æ¨è«–ã®ã¿ï¼‰
            with torch.no_grad():
                X_hat_states = self.df_state.predict_sequence(X_states_detached)
            
            # æ˜ç¤ºçš„ã«å‹¾é…ã‚°ãƒ©ãƒ•ã‹ã‚‰åˆ‡æ–­
            X_hat_states = X_hat_states.detach().requires_grad_(False)
            
            # **ä¿®æ­£4: ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ãŸæ™‚é–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª¿æ•´ï¼ˆå¤šå¤‰é‡å¯¾å¿œï¼‰**
            M_aligned = self._align_time_series_multivariate(
                X_hat_states, M_features_gpu, X_states.size(0), epoch, "DF-B"
            )
            
            # Stage-1å­¦ç¿’ï¼ˆå¤šå¤‰é‡ç‰¹å¾´é‡å¯¾å¿œï¼‰
            stage1_metrics = self.df_obs.train_stage1_with_gradients(
                X_hat_states,
                M_aligned,  # **ä¿®æ­£2+4: æ™‚é–“èª¿æ•´æ¸ˆã¿å¤šå¤‰é‡ç‰¹å¾´é‡**
                opt_phi,
                T1_iterations=self.config.T1_iterations,
                fix_psi_omega=True
            )
        
        metrics['df_b_stage1_loss'] = stage1_metrics['stage1_loss']
        
        # ãƒ­ã‚°è¨˜éŒ²
        self.logger.log_phase1(
            epoch, TrainingPhase.PHASE1_DF_B, 'stage1', 0,
            stage1_metrics, {'lr_phi': opt_phi.param_groups[0]['lr']}
        )
        
        # **ä¿®æ­£2: æ˜ç¤ºçš„ã‚°ãƒ©ãƒ•ã‚¯ãƒªã‚¢**
        self._clear_computation_graph()
        
        # Stage-2: u_Bæ¨å®š + Ïˆ_Ï‰æ›´æ–°ï¼ˆT2å›åå¾©ã€è¨ˆç®—ã‚°ãƒ©ãƒ•åˆ†é›¢ï¼‰
        stage2_losses = []
        for t in range(self.config.T2_iterations):
            with torch.enable_grad():
                # **ä¿®æ­£**: å„åå¾©ã§ç‹¬ç«‹ã—ãŸè¨ˆç®—ã‚°ãƒ©ãƒ•ã‚’ä½œæˆï¼ˆå¤šå¤‰é‡å¯¾å¿œï¼‰
                M_aligned_independent = M_aligned.detach().requires_grad_(True)

                stage2_metrics = self.df_obs.train_stage2_with_gradients(
                    M_aligned_independent,  # â† ä¿®æ­£: ç‹¬ç«‹ã—ãŸå¤šå¤‰é‡ãƒ†ãƒ³ã‚½ãƒ«
                    opt_psi,
                    fix_phi_theta=True
                )
                stage2_losses.append(stage2_metrics['stage2_loss'])
                
                # ãƒ­ã‚°è¨˜éŒ²
                self.logger.log_phase1(
                    epoch, TrainingPhase.PHASE1_DF_B, 'stage2', t,
                    stage2_metrics, {'lr_psi': opt_psi.param_groups[0]['lr']}
                )
        
        metrics['df_b_stage2_loss'] = sum(stage2_losses) / len(stage2_losses)
        
        # **ä¿®æ­£2: æœ€çµ‚ã‚°ãƒ©ãƒ•ã‚¯ãƒªã‚¢**
        self._clear_computation_graph()
        
        return metrics
    
    def _ensure_device(self, tensor: torch.Tensor) -> torch.Tensor:
        # ãƒ†ãƒ³ã‚½ãƒ«ã‚’æŒ‡å®šãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•ï¼ˆå¿…è¦ãªå ´åˆã®ã¿ï¼‰
        return tensor.to(self.device) if tensor.device != self.device else tensor

    def train_phase2(self, Y_train: torch.Tensor, Y_val: Optional[torch.Tensor] = None) -> Dict[str, float]:
        """
        Phase-2: End-to-endå¾®èª¿æ•´
        
        å›ºå®šæ¨è«–ãƒ‘ã‚¹:
        xÌ‚_{t|t-1} = U_A^T V_A Ï†_Î¸(x_{t-1})
        mÌ‚_{t|t-1} = u_B^T V_B Ï†_Î¸(xÌ‚_{t|t-1})
        Å·_{t|t-1} = g_Î±(mÌ‚_{t|t-1})
        
        Args:
            Y_train: è¨“ç·´è¦³æ¸¬ç³»åˆ—
            Y_val: æ¤œè¨¼è¦³æ¸¬ç³»åˆ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        print("\n=== Phase-2: End-to-endå¾®èª¿æ•´é–‹å§‹ ===")

        # GPUãƒ‡ãƒã‚¤ã‚¹æ•´åˆæ€§ã‚’ç¢ºä¿
        Y_train = self._ensure_device(Y_train)
        if Y_val is not None:
            Y_val = self._ensure_device(Y_val)
        
        if not self.phase1_complete:
            raise RuntimeError("Phase-1ãŒå®Œäº†ã—ã¦ã„ã¾ã›ã‚“")
        
        opt_e2e = self.optimizers['e2e']
        
        # Phase-2å­¦ç¿’ãƒ«ãƒ¼ãƒ—
        for epoch in range(self.config.phase2_epochs):
            self.current_epoch = self.config.phase1_epochs + epoch
            
            try:
                # å‰å‘ãæ¨è«–ã¨æå¤±è¨ˆç®—
                loss_total, rec_loss, cca_loss = self._forward_and_loss_phase2(Y_train)
                
                # é€†ä¼æ’­
                opt_e2e.zero_grad()
                loss_total.backward()
                opt_e2e.step()
                
            except RealizationError as e:
                print(f"ğŸ”„ Epoch {epoch} ã‚¹ã‚­ãƒƒãƒ— (Phase2æ•°å€¤å®Ÿç¾å¤±æ•—): {e}")
                # ã“ã®ã‚¨ãƒãƒƒã‚¯ã‚’å®Œå…¨ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ¬¡ã®ã‚¨ãƒãƒƒã‚¯ã«é€²ã‚€
                continue
            
            # ãƒ­ã‚°è¨˜éŒ²
            lr_dict = {f'lr_{name}': group['lr'] for name, group in 
                      zip(['encoder', 'decoder', 'phi', 'psi'], opt_e2e.param_groups)}
            self.logger.log_phase2(epoch, loss_total.item(), rec_loss.item(), 
                                  cca_loss.item(), lr_dict)
            
            self.training_history['phase2_losses'].append({
                'epoch': epoch,
                'total_loss': loss_total.item(),
                'rec_loss': rec_loss.item(),
                'cca_loss': cca_loss.item()
            })
            
            # é€²æ—è¡¨ç¤º
            if epoch % self.config.log_interval == 0 and self.config.verbose:
                print(f"Phase-2 Epoch {epoch}: Total={loss_total.item():.6f}, "
                      f"Rec={rec_loss.item():.6f}, CCA={cca_loss.item():.6f}")
                # å¤šå¤‰é‡å¯¾å¿œã®è¿½åŠ ãƒ­ã‚°
                self.log_multivariate_training_progress(epoch, "phase2")
            
            # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
            if epoch % self.config.save_interval == 0:
                self._save_checkpoint(epoch, TrainingPhase.PHASE2_E2E)
        
        print("Phase-2 å­¦ç¿’å®Œäº†")
        return self.training_history['phase2_losses']
    
    def _forward_and_loss_phase2(self, Y_train: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        **ä¿®æ­£4çµ±åˆ**: Phase-2ã®å‰å‘ãæ¨è«–ã¨æå¤±è¨ˆç®—ï¼ˆæ™‚é–“èª¿æ•´ãƒ˜ãƒ«ãƒ‘ãƒ¼ä½¿ç”¨ï¼‰
        """
        T, d = Y_train.shape
        h = self.realization.h
        
        if T <= 2 * h:
            # æ™‚ç³»åˆ—ãŒçŸ­ã™ãã‚‹å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return self._handle_short_timeseries_phase2(Y_train)
        
        # Step 1: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ y_t â†’ m_tï¼ˆå¤šå¤‰é‡ç‰¹å¾´é‡å¯¾å¿œï¼‰
        M_features = self.encoder(Y_train.unsqueeze(0)).squeeze(0)  # (T, m)
        if M_features.dim() == 1:
            M_features = M_features.unsqueeze(1)  # (T,) â†’ (T, 1)
        
        # Step 2: ç¢ºç‡çš„å®Ÿç¾ M_t â†’ x_tï¼ˆå¤šå¤‰é‡å¯¾å¿œï¼‰
        try:
            if isinstance(self.realization, StochasticRealizationWithEncoder):
                # StochasticRealizationWithEncoderã®å ´åˆï¼šå¤šå¤‰é‡ç‰¹å¾´é‡ã‚’ç›´æ¥å‡¦ç†
                self.realization.fit(Y_train, self.encoder)
                X_states = self.realization.estimate_states(Y_train)
            else:
                # å¾“æ¥Realizationã®å ´åˆï¼šã‚¹ã‚«ãƒ©ãƒ¼åŒ–
                m_scalar = M_features.mean(dim=1)  # (T, m) â†’ (T,)
                self.realization.fit(m_scalar.unsqueeze(1))
                X_states = self.realization.filter(m_scalar.unsqueeze(1))
        except RealizationError as e:
            print(f"âš ï¸ Phase2 RealizationErrorç™ºç”Ÿ: {e}")
            # RealizationErrorã‚’ä¸Šä½ã«å†æŠ•ã’ã—ã¦å®Œå…¨ã‚¨ãƒãƒƒã‚¯ã‚¹ã‚­ãƒƒãƒ—ã‚’å®Ÿè¡Œ
            raise RealizationError(f"Phase2 realization failed: {e}") from e
        T_eff = X_states.size(0)
        
        # Step 3: DF-Aäºˆæ¸¬ x_{t-1} â†’ xÌ‚_{t|t-1}
        X_hat_states = self.df_state.predict_sequence(X_states)  # (T_pred, r)
        T_pred = X_hat_states.size(0)
        
        # **ä¿®æ­£4: ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ãŸæ™‚é–“èª¿æ•´ï¼ˆå¤šå¤‰é‡å¯¾å¿œï¼‰**
        M_aligned = self._align_time_series_multivariate(
            X_hat_states, M_features, X_states.size(0), 0, "Phase2"
        )
        
        # Step 4: DF-Bäºˆæ¸¬ xÌ‚_{t|t-1} â†’ mÌ‚_{t|t-1}ï¼ˆå¤šå¤‰é‡å¯¾å¿œï¼‰
        M_hat_series = []
        for t in range(T_pred):
            m_hat_t = self.df_obs.predict_one_step(X_hat_states[t])  # m âˆˆ R^mï¼ˆæ—¢ã«å¤šå¤‰é‡å¯¾å¿œï¼‰
            M_hat_series.append(m_hat_t)
        M_hat_tensor = torch.stack(M_hat_series)  # (T_pred, m)
        M_hat_tensor = self._ensure_device(M_hat_tensor)  # GPUãƒ‡ãƒã‚¤ã‚¹æ•´åˆæ€§ã‚’ç¢ºä¿

        # Step 5: ãƒ‡ã‚³ãƒ¼ãƒ‰ mÌ‚_{t|t-1} â†’ Å·_{t|t-1}ï¼ˆå¤šå¤‰é‡å¯¾å¿œï¼‰
        # time_invariantDecoderã¯ (T, m) â†’ (T, n) å¤‰æ›
        Y_hat = self.decoder(M_hat_tensor)  # (T_pred, n)
        
        # Step 6: å¯¾å¿œã™ã‚‹çœŸå€¤å–å¾—
        Y_target = Y_train[h+1:h+1+T_pred]  # å¯¾å¿œã™ã‚‹è¦³æ¸¬
        Y_target = self._ensure_device(Y_target)  # GPUãƒ‡ãƒã‚¤ã‚¹æ•´åˆæ€§ã‚’ç¢ºä¿

        # æå¤±è¨ˆç®—ï¼ˆæ­£è¦åŒ–æ¸ˆã¿ï¼‰
        loss_rec = torch.norm(Y_hat - Y_target, p='fro') ** 2 / Y_target.numel()
        
        # CCAæå¤±ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ï¼ˆå¤šå¤‰é‡å¯¾å¿œï¼‰
        if self.config.lambda_cca > 0:
            loss_cca = self._compute_cca_loss(M_hat_tensor, M_aligned)
        else:
            loss_cca = torch.tensor(0.0, requires_grad=True)
        
        loss_total = loss_rec + self.config.lambda_cca * loss_cca
        
        return loss_total, loss_rec, loss_cca
    
    def _handle_short_timeseries_phase2(self, Y_train: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """çŸ­ã„æ™‚ç³»åˆ—ç”¨ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†"""
        T, d = Y_train.shape
        h = self.realization.h
        warnings.warn(f"æ™‚ç³»åˆ—é•·({T})ãŒçŸ­ã™ãã¾ã™ã€‚h={h}")
        
        # æœ€å°é™ã®å‡¦ç†
        m_series = self.encoder(Y_train.unsqueeze(0)).squeeze()
        if m_series.dim() == 2:
            m_series = m_series.squeeze(1)
        
        try:
            self.realization.fit(m_series.unsqueeze(1))
        except RealizationError as e:
            print(f"âš ï¸ Evaluation RealizationErrorç™ºç”Ÿ: {e}")
            # è©•ä¾¡æ™‚ã¯ã‚¨ãƒ©ãƒ¼ã‚’ä¸Šä½ã«æŠ•ã’ã¦å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—
            raise RealizationError(f"Evaluation realization failed: {e}") from e
        X_states = self.realization.filter(m_series.unsqueeze(1))
        
        # çŸ­ç¸®å‡¦ç†
        if X_states.size(0) > 1:
            X_hat_states = self.df_state.predict_sequence(X_states)
            # **ä¿®æ­£4: ãƒ˜ãƒ«ãƒ‘ãƒ¼ä½¿ç”¨**
            m_aligned = self._align_time_series(
                X_hat_states, m_series, X_states.size(0), 0, "Phase2-Short"
            )
            
            loss_rec = torch.norm(m_aligned - m_aligned, p=2) ** 2  # ãƒ€ãƒŸãƒ¼æå¤±
            loss_cca = torch.tensor(0.0, requires_grad=True)
            loss_total = loss_rec + self.config.lambda_cca * loss_cca
        else:
            loss_rec = torch.tensor(0.0, requires_grad=True)
            loss_cca = torch.tensor(0.0, requires_grad=True) 
            loss_total = loss_rec
        
        return loss_total, loss_rec, loss_cca
    
    def _compute_cca_loss(self, M_hat: torch.Tensor, M_target: torch.Tensor) -> torch.Tensor:
        """
        **ä¿®æ­£ç‰ˆ**: ç¢ºç‡çš„å®Ÿç¾ã®æ­£æº–ç›¸é–¢ä¿‚æ•°ã«åŸºã¥ãCCAæå¤±

        å®šå¼åŒ–ã«åŸºã¥ãæ­£ã—ã„å®Ÿè£…ï¼š
        L_cca = -Î£_i Ï_i ï¼ˆæ­£æº–ç›¸é–¢ä¿‚æ•°ã®å’Œã®æœ€å¤§åŒ–ï¼‰

        Args:
            M_hat: äºˆæ¸¬å¤šå¤‰é‡ç‰¹å¾´é‡ (T, m) - ãƒ­ã‚°ãƒ»ç›£è¦–ç”¨ï¼ˆå°†æ¥ã®å‹•çš„æ›´æ–°ã«å‚™ãˆã¦ä¿æŒï¼‰
            M_target: çœŸã®å¤šå¤‰é‡ç‰¹å¾´é‡ (T, m) - ãƒ­ã‚°ãƒ»ç›£è¦–ç”¨ï¼ˆå°†æ¥ã®å‹•çš„æ›´æ–°ã«å‚™ãˆã¦ä¿æŒï¼‰

        Returns:
            torch.Tensor: CCAæå¤±ï¼ˆè² ã®æ­£æº–ç›¸é–¢ä¿‚æ•°å’Œï¼‰
        """
        try:
            # ç¢ºç‡çš„å®Ÿç¾ã‹ã‚‰æ­£æº–ç›¸é–¢ä¿‚æ•°ã‚’å–å¾—
            canonical_correlations = self._get_canonical_correlations_from_realization()

            if canonical_correlations is None:
                # æ­£æº–ç›¸é–¢ä¿‚æ•°ãŒåˆ©ç”¨ã§ããªã„å ´åˆã®è­¦å‘Šã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                if self.config.verbose:
                    print("âš ï¸ æ­£æº–ç›¸é–¢ä¿‚æ•°ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚CCAæå¤±ã‚’0ã¨ã—ã¾ã™ã€‚")
                return torch.tensor(0.0, requires_grad=True, device=self.device)

            # æ­£æº–ç›¸é–¢ä¿‚æ•°ã®å’Œã®æœ€å¤§åŒ– â†’ è² å·ã§æœ€å°åŒ–å•é¡Œã«å¤‰æ›
            cca_loss = -canonical_correlations.sum()

            # ãƒ‡ãƒãƒƒã‚°ãƒ»ç›£è¦–æƒ…å ±ï¼ˆverboseæ™‚ã®ã¿ï¼‰
            if self.config.verbose and hasattr(self, 'current_epoch'):
                if getattr(self, 'current_epoch', 0) % self.config.log_interval == 0:
                    print(f"  ğŸ“Š CCAæå¤±: Ï_sum={canonical_correlations.sum().item():.4f}, "
                          f"loss={cca_loss.item():.4f}")

            return cca_loss

        except Exception as e:
            warnings.warn(f"CCAæå¤±è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}. æå¤±ã‚’0ã¨ã—ã¾ã™ã€‚")
            return torch.tensor(0.0, requires_grad=True, device=self.device)

    def _get_canonical_correlations_from_realization(self) -> Optional[torch.Tensor]:
        """
        ç¢ºç‡çš„å®Ÿç¾ã‚¯ãƒ©ã‚¹ã‹ã‚‰æ­£æº–ç›¸é–¢ä¿‚æ•°ã‚’å–å¾—

        Returns:
            torch.Tensor: æ­£æº–ç›¸é–¢ä¿‚æ•° Ï_i âˆˆ R^r, ã¾ãŸã¯ None
        """
        try:
            if isinstance(self.realization, StochasticRealizationWithEncoder):
                # StochasticRealizationWithEncoderã®å ´åˆ
                if hasattr(self.realization, 'canonical_correlations') and \
                   self.realization.canonical_correlations is not None:
                    correlations = self.realization.canonical_correlations.clone()
                    # ãƒ‡ãƒã‚¤ã‚¹çµ±ä¸€
                    return correlations.to(self.device)

            elif hasattr(self.realization, '_L_vals') and self.realization._L_vals is not None:
                # å¾“æ¥Realizationã®å ´åˆï¼šç‰¹ç•°å€¤ã‚’æ­£æº–ç›¸é–¢ä¿‚æ•°ã¨ã—ã¦ä½¿ç”¨
                # ç‰¹ç•°å€¤ã¯ [0, 1] ã«æ­£è¦åŒ–ã•ã‚Œã¦ã„ã‚‹å‰æ
                l_vals = self.realization._L_vals.clone()
                # ãƒ‡ãƒã‚¤ã‚¹çµ±ä¸€
                return l_vals.to(self.device)

            return None

        except Exception as e:
            warnings.warn(f"æ­£æº–ç›¸é–¢ä¿‚æ•°å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    # ===== ä¿®æ­£4: ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤ =====
    
    def _align_time_series(self, X_hat_states: torch.Tensor, m_series: torch.Tensor, 
                          T_states: int, epoch: int, component: str) -> torch.Tensor:
        """
        **ä¿®æ­£4**: çµ±åˆæ™‚é–“ç³»åˆ—èª¿æ•´ãƒ˜ãƒ«ãƒ‘ãƒ¼
        
        Args:
            X_hat_states: çŠ¶æ…‹äºˆæ¸¬ç³»åˆ—
            m_series: å…ƒã®ã‚¹ã‚«ãƒ©ãƒ¼ç‰¹å¾´ç³»åˆ—
            T_states: çŠ¶æ…‹ç³»åˆ—é•·ï¼ˆX_statesã®é•·ã•ï¼‰
            epoch: ç¾åœ¨ã®ã‚¨ãƒãƒƒã‚¯ï¼ˆãƒ­ã‚°ç”¨ï¼‰
            component: ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåï¼ˆãƒ­ã‚°ç”¨ï¼‰
        
        Returns:
            torch.Tensor: æ™‚é–“èª¿æ•´æ¸ˆã¿ã‚¹ã‚«ãƒ©ãƒ¼ç‰¹å¾´ç³»åˆ—
        """
        T_pred = X_hat_states.size(0)
        T_original = m_series.size(0)
        
        # ã‚ªãƒ•ã‚»ãƒƒãƒˆè¨ˆç®—
        total_offset = self._get_time_alignment_offset(T_original, T_states, T_pred)
        
        # æ™‚é–“èª¿æ•´ã•ã‚ŒãŸm_seriesã‚’æŠ½å‡º
        if total_offset + T_pred <= T_original:
            m_aligned = m_series[total_offset:total_offset + T_pred]
        else:
            # å®‰å…¨æªç½®: æœ«å°¾ã‹ã‚‰å¿…è¦ãªé•·ã•ã‚’å–å¾—
            m_aligned = m_series[-T_pred:]
            if self.config.verbose:
                print(f"è­¦å‘Š: {component} ã§ã‚ªãƒ•ã‚»ãƒƒãƒˆèª¿æ•´å¤±æ•—ã€æœ«å°¾åˆ‡ã‚Šå–ã‚Šä½¿ç”¨")
        
        # æ™‚é–“æ•´åˆæ€§æ¤œè¨¼
        self._validate_time_alignment(X_hat_states, m_aligned, component)
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆverboseæ™‚ã®ã¿ï¼‰ - ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
        # if self.config.verbose and epoch % 10 == 0:
        #     print(f"{component}æ™‚é–“èª¿æ•´ - Epoch {epoch}: "
        #           f"X_hat: {X_hat_states.shape}, m_aligned: {m_aligned.shape}, "
        #           f"offset: {total_offset}")
        
        return m_aligned

    def _align_time_series_multivariate(
        self,
        X_hat_states: torch.Tensor,
        M_features: torch.Tensor,
        T_states: int,
        epoch: int,
        component: str = "unknown"
    ) -> torch.Tensor:
        """
        **å¤šå¤‰é‡å¯¾å¿œç‰ˆ**: æ™‚é–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª¿æ•´ï¼ˆM_features âˆˆ R^(TÃ—m)ï¼‰

        Args:
            X_hat_states: çŠ¶æ…‹äºˆæ¸¬ (T_pred, r)
            M_features: å¤šå¤‰é‡ç‰¹å¾´é‡ (T, m)
            T_states: çŠ¶æ…‹ç³»åˆ—é•·
            epoch: ã‚¨ãƒãƒƒã‚¯ç•ªå·
            component: ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå

        Returns:
            torch.Tensor: æ™‚é–“èª¿æ•´æ¸ˆã¿å¤šå¤‰é‡ç‰¹å¾´ç³»åˆ— (T_pred, m)
        """
        T_pred = X_hat_states.size(0)
        T_original = M_features.size(0)

        # ã‚ªãƒ•ã‚»ãƒƒãƒˆè¨ˆç®—ï¼ˆæ—¢å­˜ãƒ¡ã‚½ãƒƒãƒ‰ä½¿ç”¨ï¼‰
        total_offset = self._get_time_alignment_offset(T_original, T_states, T_pred)

        # æ™‚é–“èª¿æ•´ã•ã‚ŒãŸå¤šå¤‰é‡ç‰¹å¾´é‡ã‚’æŠ½å‡º
        if total_offset + T_pred <= T_original:
            M_aligned = M_features[total_offset:total_offset + T_pred]  # (T_pred, m)
        else:
            # å®‰å…¨æªç½®: æœ«å°¾ã‹ã‚‰å¿…è¦ãªé•·ã•ã‚’å–å¾—
            M_aligned = M_features[-T_pred:]  # (T_pred, m)
            if self.config.verbose:
                print(f"è­¦å‘Š: {component} ã§ã‚ªãƒ•ã‚»ãƒƒãƒˆèª¿æ•´å¤±æ•—ã€æœ«å°¾åˆ‡ã‚Šå–ã‚Šä½¿ç”¨")

        # æ™‚é–“æ•´åˆæ€§æ¤œè¨¼ï¼ˆå¤šå¤‰é‡å¯¾å¿œï¼‰
        self._validate_time_alignment_multivariate(X_hat_states, M_aligned, component)

        return M_aligned

    def _get_time_alignment_offset(self, T_original: int, T_states: int, T_pred: int) -> int:
        """
        æ™‚é–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª¿æ•´ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆè¨ˆç®—
        ç†è«–: 
        - ç¢ºç‡çš„å®Ÿç¾å‡ºåŠ›: x_h, x_{h+1}, ..., x_{h+T_states-1}
        - DF-Aäºˆæ¸¬: xÌ‚_{h+1|h}, xÌ‚_{h+2|h+1}, ..., xÌ‚_{h+T_pred|h+T_pred-1}
        - æ­£ã—ã„å¯¾å¿œ: xÌ‚_{h+1|h} â†” m_{h+1}
        Args:
            T_original: å…ƒç³»åˆ—é•·
            T_states: çŠ¶æ…‹ç³»åˆ—é•·  
            T_pred: äºˆæ¸¬ç³»åˆ—é•·
            
        Returns:
            int: m_seriesã®ã‚ªãƒ•ã‚»ãƒƒãƒˆ (= h + 1)
        """
        # hå€¤å–å¾—
        h_candidates = [
            'h',                    # Realizationã®æ¨™æº–å±æ€§å
            'past_horizon',         # åˆæœŸåŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å
            'lags',                 # åˆ¥åã®å¯èƒ½æ€§
            'window_size',          # åˆ¥åã®å¯èƒ½æ€§
        ]
        
        h = None
        for attr_name in h_candidates:
            if hasattr(self.realization, attr_name):
                h = getattr(self.realization, attr_name)
                if isinstance(h, (int, float)) and h > 0:
                    h = int(h)
                    break
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: T_original, T_statesã‹ã‚‰é€†ç®—
        if h is None:
            # T_states = T_original - 2*h + 1 ã‹ã‚‰ h ã‚’è¨ˆç®—
            h = (T_original - T_states + 1) // 2
            if self.config.verbose:
                print(f"è­¦å‘Š: hå€¤ã‚’é€†ç®—ã§æ¨å®šã—ã¾ã—ãŸ: h = {h}")
        
        # æ¤œè¨¼
        expected_T_states = T_original - 2 * h + 1
        if abs(T_states - expected_T_states) > 1:  # 1ã®èª¤å·®ã¯è¨±å®¹
            if self.config.verbose:
                print(f"è­¦å‘Š: h={h}ã«ã‚ˆã‚‹æœŸå¾…T_states={expected_T_states}ãŒå®Ÿéš›å€¤{T_states}ã¨ä¸ä¸€è‡´")
        
        return h + 1
    
    def _validate_time_alignment(self, X_hat_states: torch.Tensor, m_aligned: torch.Tensor, 
                               component: str = "unknown") -> None:
        """
        **ä¿®æ­£4**: æ™‚é–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ•´åˆæ€§ã®æ¤œè¨¼
        
        Args:
            X_hat_states: çŠ¶æ…‹äºˆæ¸¬
            m_aligned: èª¿æ•´æ¸ˆã¿ã‚¹ã‚«ãƒ©ãƒ¼ç‰¹å¾´é‡
            component: ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåï¼ˆãƒ­ã‚°ç”¨ï¼‰
        """
        if X_hat_states.size(0) != m_aligned.size(0):
            raise RuntimeError(
                f"{component}ã®æ™‚é–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¸æ•´åˆ: "
                f"X_hat={X_hat_states.shape} vs m_aligned={m_aligned.shape}"
            )
        
        # æ™‚é–“æ•´åˆç¢ºèªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ - ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
        # if self.config.verbose:
        #     print(f"{component} æ™‚é–“æ•´åˆç¢ºèª: {X_hat_states.shape} â†” {m_aligned.shape}")

    def _validate_time_alignment_multivariate(
        self,
        X_hat_states: torch.Tensor,
        M_aligned: torch.Tensor,
        component: str = "unknown"
    ) -> None:
        """
        **å¤šå¤‰é‡å¯¾å¿œç‰ˆ**: æ™‚é–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ•´åˆæ€§ã®æ¤œè¨¼

        Args:
            X_hat_states: çŠ¶æ…‹äºˆæ¸¬ (T_pred, r)
            M_aligned: èª¿æ•´æ¸ˆã¿å¤šå¤‰é‡ç‰¹å¾´é‡ (T_pred, m)
            component: ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåï¼ˆãƒ­ã‚°ç”¨ï¼‰
        """
        if X_hat_states.size(0) != M_aligned.size(0):
            raise RuntimeError(
                f"{component}ã®æ™‚é–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¸æ•´åˆ: "
                f"X_hat={X_hat_states.shape} vs M_aligned={M_aligned.shape}"
            )

        # å¤šå¤‰é‡ç‰¹å¾´é‡ã®æ¬¡å…ƒç¢ºèª
        if M_aligned.dim() != 2:
            raise RuntimeError(
                f"{component}ã®å¤šå¤‰é‡ç‰¹å¾´é‡å½¢çŠ¶ã‚¨ãƒ©ãƒ¼: "
                f"æœŸå¾…=(T_pred, m), å®Ÿéš›={M_aligned.shape}"
            )

    def _ensure_device(self, tensor: torch.Tensor) -> torch.Tensor:
        """ãƒ†ãƒ³ã‚½ãƒ«ã‚’é©åˆ‡ãªãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•"""
        if tensor.device != self.device:
            return tensor.to(self.device)
        return tensor

    def _clear_computation_graph(self):
        """
        **ä¿®æ­£2**: è¨ˆç®—ã‚°ãƒ©ãƒ•ã®æ˜ç¤ºçš„ã‚¯ãƒªã‚¢
        """
        # GPU ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

        # CPU ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
        gc.collect()

    def verify_multivariate_dimensions(self, M_features: torch.Tensor, X_states: torch.Tensor) -> Dict[str, Any]:
        """
        å¤šå¤‰é‡å¯¾å¿œã®æ¬¡å…ƒæ•´åˆæ€§æ¤œè¨¼

        Args:
            M_features: å¤šå¤‰é‡ç‰¹å¾´é‡ (T, m)
            X_states: çŠ¶æ…‹æ¨å®š (T_eff, r)

        Returns:
            Dict: æ¤œè¨¼çµæœ
        """
        result = {
            "status": "ok",
            "dimensions": {},
            "warnings": [],
            "errors": []
        }

        try:
            # åŸºæœ¬æ¬¡å…ƒç¢ºèª
            result["dimensions"] = {
                "M_features_shape": tuple(M_features.shape),
                "X_states_shape": tuple(X_states.shape),
                "encoder_output_dim": getattr(self.encoder, 'output_dim', 'unknown'),
                "expected_feature_dim": getattr(self.df_obs, 'multivariate_feature_dim', 'unknown'),
                "df_state_feature_dim": getattr(self.df_state, 'feature_dim', 'unknown'),
                "df_obs_feature_dim": getattr(self.df_obs, 'obs_feature_dim', 'unknown')
            }

            # å¤šå¤‰é‡ç‰¹å¾´é‡å½¢çŠ¶ãƒã‚§ãƒƒã‚¯
            if M_features.dim() != 2:
                result["errors"].append(f"M_featureså½¢çŠ¶ã‚¨ãƒ©ãƒ¼: æœŸå¾…=(T, m), å®Ÿéš›={M_features.shape}")

            # DF-Bå¤šå¤‰é‡ç‰¹å¾´é‡æ¬¡å…ƒãƒã‚§ãƒƒã‚¯
            if hasattr(self.df_obs, 'multivariate_feature_dim'):
                expected_m = self.df_obs.multivariate_feature_dim
                if M_features.size(1) != expected_m:
                    result["errors"].append(
                        f"ç‰¹å¾´é‡æ¬¡å…ƒä¸ä¸€è‡´: M_features.size(1)={M_features.size(1)} vs "
                        f"expected={expected_m}"
                    )

            # U_Bè¡Œåˆ—æ¬¡å…ƒãƒã‚§ãƒƒã‚¯
            if hasattr(self.df_obs, 'U_B') and self.df_obs.U_B is not None:
                U_B_shape = self.df_obs.U_B.shape
                expected_U_B_shape = (self.df_obs.obs_feature_dim, M_features.size(1))
                if tuple(U_B_shape) != expected_U_B_shape:
                    result["errors"].append(
                        f"U_Bè¡Œåˆ—æ¬¡å…ƒã‚¨ãƒ©ãƒ¼: å®Ÿéš›={U_B_shape} vs æœŸå¾…={expected_U_B_shape}"
                    )

            # æ•°å€¤å®‰å®šæ€§ãƒã‚§ãƒƒã‚¯
            if hasattr(self.df_obs, 'V_B') and self.df_obs.V_B is not None:
                cond_V_B = torch.linalg.cond(self.df_obs.V_B).item()
                if cond_V_B > 1e12:
                    result["warnings"].append(f"V_Bæ¡ä»¶æ•°ãŒå¤§ãã„: {cond_V_B:.2e}")

            if hasattr(self.df_obs, 'U_B') and self.df_obs.U_B is not None:
                # U_B @ U_B.T ã®æ¡ä»¶æ•°ï¼ˆè¡Œåˆ—åŒ–ã«ã‚ˆã‚‹æ•°å€¤å®‰å®šæ€§ï¼‰
                U_B_gram = self.df_obs.U_B @ self.df_obs.U_B.T
                cond_U_B_gram = torch.linalg.cond(U_B_gram).item()
                if cond_U_B_gram > 1e12:
                    result["warnings"].append(f"U_B @ U_B.Tæ¡ä»¶æ•°ãŒå¤§ãã„: {cond_U_B_gram:.2e}")

            if result["errors"]:
                result["status"] = "error"
            elif result["warnings"]:
                result["status"] = "warning"

        except Exception as e:
            result["status"] = "error"
            result["errors"].append(f"æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")

        return result

    def log_multivariate_training_progress(self, epoch: int, phase: str):
        """
        å¤šå¤‰é‡å¯¾å¿œã®å­¦ç¿’é€²æ—ãƒ­ã‚°

        Args:
            epoch: ã‚¨ãƒãƒƒã‚¯ç•ªå·
            phase: å­¦ç¿’ãƒ•ã‚§ãƒ¼ã‚º ("phase1_df_a", "phase1_df_b", "phase2")
        """
        if not self.config.verbose or epoch % self.config.log_interval != 0:
            return

        try:
            print(f"\nğŸ“Š å¤šå¤‰é‡å­¦ç¿’é€²æ—ç¢ºèª - Epoch {epoch}, Phase: {phase}")

            # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼çµ±è¨ˆ
            if hasattr(self, '_temp_data') and 'M_features' in self._temp_data:
                M_features = self._temp_data['M_features']
                print(f"  ğŸ“ˆ å¤šå¤‰é‡ç‰¹å¾´é‡: shape={M_features.shape}, "
                      f"mean={M_features.mean().item():.4f}, "
                      f"std={M_features.std().item():.4f}")

            # DF-Bçµ±è¨ˆ
            if hasattr(self, 'df_obs') and self.df_obs is not None:
                if hasattr(self.df_obs, 'V_B') and self.df_obs.V_B is not None:
                    V_B_norm = torch.norm(self.df_obs.V_B, p='fro').item()
                    print(f"  ğŸ”— V_B: shape={self.df_obs.V_B.shape}, norm={V_B_norm:.4f}")

                if hasattr(self.df_obs, 'U_B') and self.df_obs.U_B is not None:
                    U_B_norm = torch.norm(self.df_obs.U_B, p='fro').item()
                    print(f"  ğŸ“ U_B: shape={self.df_obs.U_B.shape}, norm={U_B_norm:.4f}")

            # æ•°å€¤å®‰å®šæ€§ç¢ºèª
            if hasattr(self, '_temp_data') and 'M_features' in self._temp_data:
                M_features = self._temp_data['M_features']
                X_states = self._temp_data['X_states']
                verification = self.verify_multivariate_dimensions(M_features, X_states)

                if verification["status"] == "error":
                    print(f"  âŒ æ¬¡å…ƒã‚¨ãƒ©ãƒ¼: {verification['errors']}")
                elif verification["status"] == "warning":
                    print(f"  âš ï¸  æ•°å€¤è­¦å‘Š: {verification['warnings']}")
                else:
                    print(f"  âœ… æ¬¡å…ƒæ•´åˆæ€§: OK")

        except Exception as e:
            print(f"  âŒ ãƒ­ã‚°å‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ===== æ—¢å­˜ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆä¿®æ­£ãªã—ï¼‰ =====
    
    def forecast(self, Y_test: torch.Tensor, forecast_steps: int) -> torch.Tensor:
        """äºˆæ¸¬å®Ÿè¡Œ"""
        self.encoder.eval()
        self.decoder.eval()
        self.df_state.eval()
        self.df_obs.eval()
        
        with torch.no_grad():
            # åˆæœŸçŠ¶æ…‹æ¨å®š
            T_test, d = Y_test.shape
            warmup_len = min(T_test, self.realization.h + 10)
            Y_warmup = Y_test[:warmup_len]
            
            # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            m_warmup = self.encoder(Y_warmup.unsqueeze(0)).squeeze()
            
            # çŠ¶æ…‹æ¨å®š
            try:
                self.realization.fit(m_warmup.unsqueeze(1))
            except RealizationError as e:
                print(f"âš ï¸ Warmup RealizationErrorç™ºç”Ÿ: {e}")
                # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—æ™‚ã¯ã‚¨ãƒ©ãƒ¼ã‚’ä¸Šä½ã«æŠ•ã’ã¦å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—
                raise RealizationError(f"Warmup realization failed: {e}") from e
            X_warmup = self.realization.filter(m_warmup.unsqueeze(1))
            
            # é€æ¬¡äºˆæ¸¬
            predictions = []
            x_current = X_warmup[-1]  # æœ€æ–°çŠ¶æ…‹
            
            for step in range(forecast_steps):
                # DF-A: çŠ¶æ…‹äºˆæ¸¬
                x_pred = self.df_state.predict_one_step(x_current)
                
                # DF-B: ç‰¹å¾´é‡äºˆæ¸¬
                m_pred = self.df_obs.predict_one_step(x_pred)
                
                # ãƒ‡ã‚³ãƒ¼ãƒ‰: è¦³æ¸¬äºˆæ¸¬
                m_input = m_pred.unsqueeze(0).unsqueeze(0).unsqueeze(2)  # (1, 1, 1)
                y_pred = self.decoder(m_input).squeeze()  # (d,)
                
                predictions.append(y_pred)
                x_current = x_pred  # çŠ¶æ…‹æ›´æ–°
            
            return torch.stack(predictions)  # (forecast_steps, d)
    
    def train_full(self, Y_train: torch.Tensor, Y_val: Optional[torch.Tensor] = None) -> Dict[str, Any]:
        """å®Œå…¨å­¦ç¿’å®Ÿè¡Œï¼ˆPhase-1 + Phase-2ï¼‰"""
        try:
            # Phase-1å­¦ç¿’
            phase1_metrics = self.train_phase1(Y_train)
            
            # Phase-2å­¦ç¿’
            phase2_metrics = self.train_phase2(Y_train, Y_val)
            
            # æœ€çµ‚ä¿å­˜
            self._save_final_model()
            self.logger.save_summary()
            
            return {
                'phase1_metrics': phase1_metrics,
                'phase2_losses': phase2_metrics,
                'training_config': self.config.__dict__,
                'model_paths': {
                    'final_model': str(self.output_dir / 'final_model.pth'),
                    'logs': str(self.logger.output_dir)
                }
            }
            
        except Exception as e:
            print(f"å­¦ç¿’ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
            # ç·Šæ€¥ä¿å­˜
            self._save_checkpoint(self.current_epoch, TrainingPhase.PHASE1_DF_A, emergency=True)
            raise
    
    def _print_phase1_progress(self, epoch: int, metrics: Dict[str, float]):
        """Phase-1é€²æ—è¡¨ç¤º"""
        df_a_s1 = metrics.get('df_a_stage1_loss', 0)
        df_a_s2 = metrics.get('df_a_stage2_loss', 0)
        df_b_s1 = metrics.get('df_b_stage1_loss', 0)
        df_b_s2 = metrics.get('df_b_stage2_loss', 0)
        
        print(f"Phase-1 Epoch {epoch:3d}: "
              f"DF-A(S1={df_a_s1:.4f}, S2={df_a_s2:.4f}) "
              f"DF-B(S1={df_b_s1:.4f}, S2={df_b_s2:.4f})")
    
    def _save_checkpoint(self, epoch: int, phase: TrainingPhase, emergency: bool = False):
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜"""
        checkpoint = {
            'epoch': epoch,
            'phase': phase.value,
            'encoder_state': self.encoder.state_dict(),
            'decoder_state': self.decoder.state_dict(),
            'training_config': self.config.__dict__,
            'training_history': self.training_history,
            'phase1_complete': self.phase1_complete
        }
        
        # DF layersçŠ¶æ…‹
        if self.df_state is not None:
            checkpoint['df_state'] = self.df_state.get_state_dict()
        if self.df_obs is not None:
            checkpoint['df_obs'] = self.df_obs.get_state_dict()
        
        # æœ€é©åŒ–å™¨çŠ¶æ…‹
        opt_states = {}
        for name, opt in self.optimizers.items():
            if opt is not None:
                opt_states[name] = opt.state_dict()
        checkpoint['optimizer_states'] = opt_states
        
        # ä¿å­˜ãƒ‘ã‚¹
        if emergency:
            save_path = self.output_dir / f'emergency_checkpoint_epoch_{epoch}.pth'
        else:
            save_path = self.output_dir / f'checkpoint_epoch_{epoch}.pth'
        
        torch.save(checkpoint, save_path)
        
        if self.config.verbose:
            print(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜: {save_path}")
    
    def _save_final_model(self):
        """æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ä¿å­˜"""
        print("DEBUG: _save_final_model called")
        # å­¦ç¿’æ™‚ã®å®Œå…¨ãªè¨­å®šã‚’å¾©å…ƒ
        complete_config = self._build_complete_config()
        
        model_state = {
            'encoder': self.encoder.state_dict(),
            'decoder': self.decoder.state_dict(),
            'df_state': self.df_state.get_inference_state_dict() if self.df_state else None,
            'df_obs': self.df_obs.get_inference_state_dict() if self.df_obs else None,
            'realization_config': self.realization.__dict__,
            'training_config': self.config.__dict__,
            'config': complete_config  # æ¨è«–æ™‚ã«ä½¿ç”¨ã•ã‚Œã‚‹å®Œå…¨ãªè¨­å®š
        }
        
        save_path = self.output_dir / 'final_model.pth'
        torch.save(model_state, save_path)
        
        print(f"æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {save_path}")
    
    def _build_complete_config(self) -> Dict[str, Any]:
        """å­¦ç¿’æ™‚ã®å®Œå…¨ãªè¨­å®šã‚’æ§‹ç¯‰ï¼ˆæ¨è«–æ™‚ã«ä½¿ç”¨ï¼‰"""
        print("DEBUG: _build_complete_config called")
        
        complete_config = {
            'model': {
                'encoder': {
                    'input_dim': getattr(self.encoder, 'input_dim', 6),
                    'channels': getattr(self.encoder, 'channels', 64),
                    'layers': getattr(self.encoder, 'layers', 8),
                    'kernel_size': getattr(self.encoder, 'kernel_size', 3),
                    'activation': getattr(self.encoder, 'activation', 'GELU'),
                    'dropout': getattr(self.encoder, 'dropout', 0.1)
                },
                'decoder': {
                    'output_dim': getattr(self.decoder, 'output_dim', 6),
                    'window': getattr(self.decoder, 'window', 12),
                    'tau': getattr(self.decoder, 'tau', 1),
                    'hidden': getattr(self.decoder, 'hidden', 64),
                    'ma_kernel': getattr(self.decoder, 'ma_kernel', 24),
                    'gru_hidden': getattr(self.decoder, 'gru_hidden', 32),
                    'activation': getattr(self.decoder, 'activation', 'GELU'),
                    'dropout': getattr(self.decoder, 'dropout', 0.1)
                }
            },
            'ssm': {
                'realization': self.realization.__dict__,
                'df_state': self._extract_df_state_config(),
                'df_observation': self._extract_df_obs_config()
            }
        }
        
        print("DEBUG: _build_complete_config completed")
        return complete_config
    
    def _extract_df_state_config(self) -> Dict[str, Any]:
        """å®Ÿéš›ã®DFStateLayerã‹ã‚‰è¨­å®šã‚’æŠ½å‡º"""
        base_config = self.df_state_config.copy()
        
        print(f"DEBUG: df_state exists: {self.df_state is not None}")
        
        # å®Ÿéš›ã®DFStateLayerã‹ã‚‰è©³ç´°è¨­å®šã‚’æŠ½å‡º
        if self.df_state and hasattr(self.df_state, 'phi_theta'):
            print("DEBUG: df_state has phi_theta")
            # StateFeatureNetã®æ§‹é€ ã‚’è§£æ
            phi_theta = self.df_state.phi_theta
            print(f"DEBUG: phi_theta type: {type(phi_theta)}")
            print(f"DEBUG: phi_theta has net: {hasattr(phi_theta, 'net')}")
            
            if hasattr(phi_theta, 'net') and len(phi_theta.net) > 0:
                print(f"DEBUG: phi_theta.net length: {len(phi_theta.net)}")
                print(f"DEBUG: phi_theta.net layers: {[type(layer).__name__ for layer in phi_theta.net]}")
                
                # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ã‹ã‚‰ hidden_sizes ã‚’é€†ç®—
                hidden_sizes = []
                for i, layer in enumerate(phi_theta.net):
                    print(f"DEBUG: Layer {i}: {type(layer).__name__}")
                    if hasattr(layer, 'out_features'):
                        print(f"DEBUG: Layer {i} out_features: {layer.out_features}")
                        hidden_sizes.append(layer.out_features)
                
                print(f"DEBUG: Raw hidden_sizes: {hidden_sizes}")
                
                # æœ€å¾Œã®å±¤ã¯é™¤ãï¼ˆå‡ºåŠ›å±¤ï¼‰
                if len(hidden_sizes) > 1:
                    hidden_sizes = hidden_sizes[:-1]
                    print(f"DEBUG: Final hidden_sizes: {hidden_sizes}")
                
                # feature_net è¨­å®šã‚’æ§‹ç¯‰
                base_config['feature_net'] = {
                    'hidden_sizes': hidden_sizes,
                    'activation': getattr(phi_theta, 'activation', 'ReLU'),
                    'dropout': getattr(phi_theta, 'dropout', 0.1)
                }
                print(f"DEBUG: Created feature_net config: {base_config['feature_net']}")
            else:
                print("DEBUG: phi_theta.net not found or empty")
        else:
            print("DEBUG: df_state doesn't have phi_theta")
        
        print(f"DEBUG: Final base_config keys: {list(base_config.keys())}")
        return base_config
    
    def _extract_df_obs_config(self) -> Dict[str, Any]:
        """å®Ÿéš›ã®DFObservationLayerã‹ã‚‰è¨­å®šã‚’æŠ½å‡º"""
        base_config = self.df_obs_config.copy()
        
        # å®Ÿéš›ã®DFObservationLayerã‹ã‚‰è©³ç´°è¨­å®šã‚’æŠ½å‡º
        if self.df_obs and hasattr(self.df_obs, 'psi_omega'):
            psi_omega = self.df_obs.psi_omega
            if hasattr(psi_omega, 'net') and len(psi_omega.net) > 0:
                # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ã‹ã‚‰ hidden_sizes ã‚’é€†ç®—
                hidden_sizes = []
                for layer in psi_omega.net:
                    if hasattr(layer, 'out_features'):
                        hidden_sizes.append(layer.out_features)
                
                # æœ€å¾Œã®å±¤ã¯é™¤ãï¼ˆå‡ºåŠ›å±¤ï¼‰
                if len(hidden_sizes) > 1:
                    hidden_sizes = hidden_sizes[:-1]
                
                # obs_net è¨­å®šã‚’æ§‹ç¯‰
                base_config['obs_net'] = {
                    'hidden_sizes': hidden_sizes,
                    'activation': getattr(psi_omega, 'activation', 'ReLU'),
                    'dropout': getattr(psi_omega, 'dropout', 0.1)
                }
        
        return base_config
    
    def get_training_summary(self) -> Dict[str, Any]:
        """å­¦ç¿’ã‚µãƒãƒªå–å¾—"""
        summary = {
            'training_complete': self.phase1_complete,
            'total_epochs': {
                'phase1': self.config.phase1_epochs,
                'phase2': self.config.phase2_epochs if self.phase1_complete else 0
            },
            'final_losses': {},
            'model_info': {
                'encoder_params': sum(p.numel() for p in self.encoder.parameters()),
                'decoder_params': sum(p.numel() for p in self.decoder.parameters()),
                'df_state_params': sum(p.numel() for p in self.df_state.phi_theta.parameters()) if self.df_state else 0,
                'df_obs_params': sum(p.numel() for p in self.df_obs.psi_omega.parameters()) if self.df_obs else 0
            }
        }
        
        if self.training_history['phase1_metrics']:
            summary['final_losses']['phase1'] = self.training_history['phase1_metrics'][-1]
        
        if self.training_history['phase2_losses']:
            summary['final_losses']['phase2'] = self.training_history['phase2_losses'][-1]
        
        return summary
    
    """
    å­¦ç¿’å¾Œã®æ¨è«–ç’°å¢ƒè‡ªå‹•ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    """
    def post_training_setup(self, Y_train: torch.Tensor) -> Dict[str, Any]:
        if not self.use_kalman_filtering:
            return {"status": "kalman_disabled"}
        
        if not self.phase1_complete:
            return {"status": "phase1_incomplete"}
        
        print("Setting up post-training inference environment...")
        
        try:
            # æ¨è«–è¨­å®šèª­ã¿è¾¼ã¿ï¼ˆå¾Œè¿°ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹æ‰‹æ³•ä½¿ç”¨ï¼‰
            inference_config = self._load_inference_config()
            
            # ä¸€æ™‚çš„ãªãƒ¢ãƒ‡ãƒ«ä¿å­˜
            temp_model_path = self.output_dir / "temp_inference_model.pth"
            self._save_inference_ready_model(temp_model_path)
            
            # InferenceModelåˆæœŸåŒ–
            from ..models.inference_model import InferenceModel
            
            self.inference_model = InferenceModel(
                trained_model_path=temp_model_path,
                inference_config=inference_config
            )
            
            # æ¨è«–ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
            self.inference_model.setup_inference(calibration_data=self.calibration_data)
            
            # æœ€çµ‚ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
            self.inference_model.export_for_deployment(
                export_path=self.output_dir / "inference_deployment"
            )
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            if temp_model_path.exists():
                temp_model_path.unlink()
            
            return {"status": "success", "inference_model": self.inference_model}
            
        except Exception as e:
            return {"status": "failed", "error": str(e)}

    def _save_inference_ready_model(self, save_path):
        """æ¨è«–ç”¨ãƒ¢ãƒ‡ãƒ«ä¿å­˜"""
        print("DEBUG: _save_inference_ready_model called")
        
        model_state = {
            'config': {
                'ssm': {
                    'realization': {
                        'past_horizon': self.realization.h,
                        'rank': self.realization.rank,
                        'jitter': getattr(self.realization, 'jitter', 1e-3)
                    },
                    'df_state': self._extract_df_state_config(),
                    'df_observation': self._extract_df_obs_config()
                },
                'model': {
                    'encoder': {
                        'input_dim': getattr(self.encoder, 'input_dim', 7)
                    }
                }
            },
            'model_state_dict': {
                'encoder': self.encoder.state_dict(),
                'decoder': self.decoder.state_dict(),
                'df_state': self.df_state.get_inference_state_dict(),
                'df_obs': self.df_obs.get_inference_state_dict()
            }
        }
        torch.save(model_state, save_path)

    def _load_inference_config(self) -> Dict[str, Any]:
        """æ¨è«–è¨­å®šã®èª­ã¿è¾¼ã¿ï¼ˆè­¦å‘Šã®ã¿ç‰ˆï¼‰"""
        try:
            from configs.inference_config_loader import load_inference_config
            
            environment = "production" if not self.config.verbose else "development"
            inference_config = load_inference_config(environment=environment)
            inference_config["device"] = str(self.device)
            
            if self.config.verbose:
                print(f"æ¨è«–è¨­å®šèª­ã¿è¾¼ã¿å®Œäº†ï¼ˆç’°å¢ƒ: {environment}ï¼‰")
            
            return inference_config
            
        except ImportError as e:
            warnings.warn(f"InferenceConfigLoaderãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}. å†…è”µãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            return self._use_builtin_defaults()
            
        except FileNotFoundError as e:
            warnings.warn(f"æ¨è«–è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}. å†…è”µãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            return self._use_builtin_defaults()
            
        except Exception as e:
            warnings.warn(f"æ¨è«–è¨­å®šèª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}. å†…è”µãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            return self._use_builtin_defaults()

    def _use_builtin_defaults(self) -> Dict[str, Any]:
        """å†…è”µãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ç›´æ¥ä½¿ç”¨"""
        try:
            from configs.inference_config_loader import InferenceConfigLoader
            
            # ã‚¯ãƒ©ã‚¹ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç›´æ¥ä½¿ç”¨
            loader = InferenceConfigLoader.__new__(InferenceConfigLoader)  # __init__å›é¿
            
            config = {
                'device': str(self.device),
                'noise_estimation': loader._get_default_section('noise_estimation'),
                'initialization': loader._get_default_section('initialization'),
                'numerical': loader._get_default_section('numerical'),
                # streamingã¨outputã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å›ºæœ‰ãªã®ã§ç›´æ¥å®šç¾©
                'streaming': {
                    'buffer_size': 100,
                    'batch_processing': False,
                    'anomaly_detection': True,
                    'anomaly_threshold': 3.0
                },
                'output': {
                    'save_states': True,
                    'save_covariances': False,
                    'save_likelihoods': True
                }
            }
            
            if self.config.verbose:
                print("å†…è”µãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ã—ã¦æ¨è«–è¨­å®šã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
            
            return config
            
        except Exception as nested_e:
            # ã“ã®å ´åˆã¯ã‚¯ãƒ©ã‚¹è‡ªä½“ã«å•é¡ŒãŒã‚ã‚‹ã®ã§ã€ã‚¨ãƒ©ãƒ¼ã‚’ç™ºç”Ÿã•ã›ã‚‹
            raise RuntimeError(
                f"å†…è”µãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®å–å¾—ã«ã‚‚å¤±æ•—ã—ã¾ã—ãŸ: {nested_e}. "
                f"InferenceConfigLoaderã‚¯ãƒ©ã‚¹ã®å®Ÿè£…ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            ) from nested_e



# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
def create_trainer_from_config(config_path: str, device: torch.device, output_dir: str) -> TwoStageTrainer:
    """
    è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’ä½œæˆ
    
    Args:
        config_path: YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        device: è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        
    Returns:
        TwoStageTrainer: åˆæœŸåŒ–æ¸ˆã¿ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼
    """
    import yaml
    
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ï¼ˆæ–°ã—ã„time_invariantã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä½¿ç”¨ï¼‰
    encoder_config = config['model']['encoder'].copy()
    decoder_config = config['model']['decoder'].copy()

    # time_invariantç”¨ã®è¨­å®šèª¿æ•´
    if 'output_dim' not in encoder_config:
        encoder_config['output_dim'] = encoder_config.get('channels', 32)

    encoder = time_invariantEncoder(**encoder_config)
    decoder = time_invariantDecoder(**decoder_config)

    # ç¢ºç‡å®Ÿç¾ï¼ˆæ–°ã—ã„ã‚¯ãƒ©ã‚¹å„ªå…ˆï¼‰
    realization_config = config['ssm']['realization']
    if config.get('evaluation', {}).get('use_new_realization', True):
        # StochasticRealizationWithEncoderã¯encoderå¼•æ•°ãŒå¿…è¦
        realization_config_copy = realization_config.copy()
        realization = StochasticRealizationWithEncoder(
            encoder=encoder,
            **realization_config_copy
        )
    else:
        realization = Realization(**realization_config)
    
    # è¨­å®šå¤‰æ›
    training_config = TrainingConfig.from_nested_dict(config['training'])
    
    # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ä½œæˆ
    trainer = TwoStageTrainer(
        encoder=encoder,
        decoder=decoder,
        realization=realization,
        df_state_config=config['ssm']['df_state'],
        df_obs_config=config['ssm']['df_observation'],
        training_config=training_config,
        device=device,
        output_dir=output_dir
    )
    
    return trainer


def run_training_experiment(
    config_path: str,
    data_path: str,
    output_dir: str,
    device: Optional[torch.device] = None
) -> Dict[str, Any]:
    """
    **å…ƒé–¢æ•°ã®ä¿®æ­£ç‰ˆ**: å­¦ç¿’å®Ÿé¨“ã®å®Ÿè¡Œ
    
    Args:
        config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        data_path: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (.npz)
        output_dir: çµæœå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        device: è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹ï¼ˆNoneãªã‚‰è‡ªå‹•é¸æŠï¼‰
        
    Returns:
        å®Ÿé¨“çµæœè¾æ›¸
    """
    import yaml
    import numpy as np
    from ..utils.gpu_utils import select_device

    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
    if device is None:
        device = select_device()
    
    print(f"å®Ÿé¨“é–‹å§‹: device={device}")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    try:
        from ..utils.data_loader import load_experimental_data
        
        # dataè¨­å®šãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if 'data' in config:
            print(f"ğŸ“‚ çµ±ä¸€ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã§ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {data_path}")
            data_dict = load_experimental_data(data_path, config['data'])
            Y_train = data_dict['train'].to(device)
            print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {Y_train.shape} (æ­£è¦åŒ–: {data_dict['metadata'].normalization_method})")
        else:
            raise ImportError("dataè¨­å®šãŒãªã„ãŸã‚å¾“æ¥æ–¹å¼ã‚’ä½¿ç”¨")
            
    except (ImportError, ModuleNotFoundError, Exception) as e:
        print(f"âš ï¸  çµ±ä¸€ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½¿ç”¨ä¸å¯ã€å¾“æ¥æ–¹å¼: {e}")
        
        data = np.load(data_path)
        if 'Y' in data:
            Y_train = torch.tensor(data['Y'], dtype=torch.float32, device=device)
        elif 'arr_0' in data:
            Y_train = torch.tensor(data['arr_0'], dtype=torch.float32, device=device)
        else:
            available_keys = list(data.keys())
            raise ValueError(
                f"ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã« 'Y' ã¾ãŸã¯ 'arr_0' ã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
                f"åˆ©ç”¨å¯èƒ½ãªã‚­ãƒ¼: {available_keys}"
                )
    
    print(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {Y_train.shape}")
    
    # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
    if Y_train.dim() != 2:
        raise ValueError(f"ãƒ‡ãƒ¼ã‚¿ã¯2æ¬¡å…ƒ (T, d) ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: got {Y_train.shape}")
    
    T, d = Y_train.shape
    if T < 50:
        warnings.warn(f"æ™‚ç³»åˆ—é•·ãŒçŸ­ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™: T={T}")
    
    # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ä½œæˆ
    try:
        trainer = create_trainer_from_config(config_path, device, output_dir)
    except Exception as e:
        raise RuntimeError(f"ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ä½œæˆå¤±æ•—: {config_path}. ã‚¨ãƒ©ãƒ¼: {e}")
    
    # **ä¿®æ­£**: train_full ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ï¼ˆå…ƒã®fitâ†’train_fullã«å¤‰æ›´ï¼‰
    try:
        results = trainer.train_full(Y_train)
    except Exception as e:
        print(f"å­¦ç¿’ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        # ç·Šæ€¥ä¿å­˜è©¦è¡Œ
        try:
            trainer._save_checkpoint(
                trainer.current_epoch, 
                TrainingPhase.PHASE1_DF_A, 
                emergency=True
            )
            print(f"ç·Šæ€¥ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜: {trainer.output_dir}")
        except:
            print("ç·Šæ€¥ä¿å­˜ã‚‚å¤±æ•—ã—ã¾ã—ãŸ")
        raise
    
    # **ä¿®æ­£**: ã‚µãƒãƒªè¿½åŠ ï¼ˆä¿®æ­£ç‰ˆãƒ¡ã‚½ãƒƒãƒ‰åã«å¯¾å¿œï¼‰
    try:
        experiment_summary = trainer.get_training_summary()
        results['experiment_summary'] = experiment_summary
        results['data_info'] = {
            'data_path': data_path,
            'data_shape': tuple(Y_train.shape),
            'device': str(device),
            'total_parameters': experiment_summary.get('model_info', {}).get('total_params', 0)
        }
        
        # **è¿½åŠ **: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        config_backup_path = Path(output_dir) / 'config_used.yaml'
        if not config_backup_path.exists():
            import shutil
            shutil.copy2(config_path, config_backup_path)
            print(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {config_backup_path}")
            
    except Exception as e:
        warnings.warn(f"ã‚µãƒãƒªä½œæˆã§ã‚¨ãƒ©ãƒ¼: {e}")
        results['experiment_summary'] = {'error': str(e)}
        results['data_info'] = {
            'data_path': data_path,
            'data_shape': tuple(Y_train.shape),
            'device': str(device)
        }
    
    print(f"å®Ÿé¨“å®Œäº†: çµæœã¯ {output_dir} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
    
    return results


def run_validation(
    trainer: TwoStageTrainer, 
    Y_test: torch.Tensor, 
    output_dir: str,
    forecast_steps: int = 96
) -> Dict[str, Any]:
    """
    **æ–°æ©Ÿèƒ½**: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®æ¤œè¨¼å®Ÿè¡Œ
    
    Args:
        trainer: å­¦ç¿’æ¸ˆã¿ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼
        Y_test: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        output_dir: çµæœå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        forecast_steps: äºˆæ¸¬ã‚¹ãƒ†ãƒƒãƒ—æ•°
        
    Returns:
        æ¤œè¨¼çµæœè¾æ›¸
    """
    print("æ¤œè¨¼é–‹å§‹...")
    
    try:
        # äºˆæ¸¬å®Ÿè¡Œ
        predictions = trainer.forecast(Y_test, forecast_steps)
        
        # äºˆæ¸¬ç²¾åº¦è¨ˆç®—
        if Y_test.size(0) > forecast_steps:
            Y_true = Y_test[-forecast_steps:]
            mse = torch.mean((predictions - Y_true) ** 2).item()
            mae = torch.mean(torch.abs(predictions - Y_true)).item()
            
            # ç›¸å¯¾èª¤å·®
            relative_error = (torch.norm(predictions - Y_true) / torch.norm(Y_true)).item()
            
            metrics = {
                'mse': mse,
                'mae': mae,
                'rmse': mse ** 0.5,
                'relative_error': relative_error,
                'forecast_steps': forecast_steps
            }
        else:
            warnings.warn("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒäºˆæ¸¬ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚ˆã‚ŠçŸ­ã„ãŸã‚ã€ç²¾åº¦è¨ˆç®—ã‚’ã‚¹ã‚­ãƒƒãƒ—")
            metrics = {
                'forecast_steps': forecast_steps,
                'note': 'ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚ç²¾åº¦è¨ˆç®—ä¸å¯'
            }
        
        # çµæœä¿å­˜
        validation_results = {
            'metrics': metrics,
            'predictions_shape': tuple(predictions.shape),
            'test_data_shape': tuple(Y_test.shape),
            'model_summary': trainer.get_training_summary()
        }
        
        # äºˆæ¸¬çµæœã‚’numpyé…åˆ—ã¨ã—ã¦ä¿å­˜
        output_path = Path(output_dir)
        predictions_path = output_path / 'predictions.npz'
        np.savez(
            predictions_path,
            predictions=predictions.cpu().numpy(),
            Y_test=Y_test.cpu().numpy()
        )
        
        print(f"æ¤œè¨¼å®Œäº†: ç²¾åº¦æŒ‡æ¨™ MSE={metrics.get('mse', 'N/A'):.6f}")
        
        return validation_results
        
    except Exception as e:
        error_result = {
            'error': str(e),
            'test_data_shape': tuple(Y_test.shape),
            'forecast_steps': forecast_steps
        }
        print(f"æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return error_result


def plot_training_results(output_dir: str) -> None:
    """
    **æ–°æ©Ÿèƒ½**: å­¦ç¿’çµæœã®å¯è¦–åŒ–
    
    Args:
        output_dir: çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    """
    try:
        import matplotlib.pyplot as plt
        import pandas as pd
        
        output_path = Path(output_dir)
        
        # Phase-1 æå¤±ãƒ—ãƒ­ãƒƒãƒˆ
        phase1_csv = output_path / 'phase1_training.csv'
        if phase1_csv.exists():
            df_phase1 = pd.read_csv(phase1_csv)
            
            fig, axes = plt.subplots(2, 2, figsize=(12, 10))
            fig.suptitle('Phase-1 Training Progress')
            
            # DF-A Stage-1
            df_a_s1 = df_phase1[(df_phase1['phase'] == 'phase1_df_a') & (df_phase1['stage'] == 'stage1')]
            if not df_a_s1.empty:
                axes[0, 0].plot(df_a_s1['epoch'], df_a_s1['loss'])
                axes[0, 0].set_title('DF-A Stage-1 Loss')
                axes[0, 0].set_xlabel('Epoch')
                axes[0, 0].set_ylabel('Loss')
            
            # DF-A Stage-2
            df_a_s2 = df_phase1[(df_phase1['phase'] == 'phase1_df_a') & (df_phase1['stage'] == 'stage2')]
            if not df_a_s2.empty:
                axes[0, 1].plot(df_a_s2['epoch'], df_a_s2['loss'])
                axes[0, 1].set_title('DF-A Stage-2 Loss')
                axes[0, 1].set_xlabel('Epoch')
                axes[0, 1].set_ylabel('Loss')
            
            # DF-B Stage-1
            df_b_s1 = df_phase1[(df_phase1['phase'] == 'phase1_df_b') & (df_phase1['stage'] == 'stage1')]
            if not df_b_s1.empty:
                axes[1, 0].plot(df_b_s1['epoch'], df_b_s1['loss'])
                axes[1, 0].set_title('DF-B Stage-1 Loss')
                axes[1, 0].set_xlabel('Epoch')
                axes[1, 0].set_ylabel('Loss')
            
            # DF-B Stage-2
            df_b_s2 = df_phase1[(df_phase1['phase'] == 'phase1_df_b') & (df_phase1['stage'] == 'stage2')]
            if not df_b_s2.empty:
                axes[1, 1].plot(df_b_s2['epoch'], df_b_s2['loss'])
                axes[1, 1].set_title('DF-B Stage-2 Loss')
                axes[1, 1].set_xlabel('Epoch')
                axes[1, 1].set_ylabel('Loss')
            
            plt.tight_layout()
            plt.savefig(output_path / 'phase1_losses.png', dpi=150)
            plt.close()
        
        # Phase-2 æå¤±ãƒ—ãƒ­ãƒƒãƒˆ
        phase2_csv = output_path / 'phase2_training.csv'
        if phase2_csv.exists():
            df_phase2 = pd.read_csv(phase2_csv)
            
            fig, axes = plt.subplots(1, 3, figsize=(15, 5))
            fig.suptitle('Phase-2 Training Progress')
            
            axes[0].plot(df_phase2['epoch'], df_phase2['total_loss'])
            axes[0].set_title('Total Loss')
            axes[0].set_xlabel('Epoch')
            axes[0].set_ylabel('Loss')
            
            axes[1].plot(df_phase2['epoch'], df_phase2['rec_loss'])
            axes[1].set_title('Reconstruction Loss')
            axes[1].set_xlabel('Epoch')
            axes[1].set_ylabel('Loss')
            
            axes[2].plot(df_phase2['epoch'], df_phase2['cca_loss'])
            axes[2].set_title('CCA Loss')
            axes[2].set_xlabel('Epoch')
            axes[2].set_ylabel('Loss')
            
            plt.tight_layout()
            plt.savefig(output_path / 'phase2_losses.png', dpi=150)
            plt.close()
        
        print(f"å¯è¦–åŒ–å®Œäº†: {output_path}")
        
    except ImportError:
        warnings.warn("matplotlib/pandasãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€å¯è¦–åŒ–ã‚’ã‚¹ã‚­ãƒƒãƒ—")
    except Exception as e:
        warnings.warn(f"å¯è¦–åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")


if __name__ == "__main__":
    # ç°¡å˜ãªãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ‰
    print("TwoStageTrainerä¿®æ­£ç‰ˆèª­ã¿è¾¼ã¿å®Œäº†")