#!/usr/bin/env python3
# scripts/run_full_experiment.py
"""
ã‚¿ã‚¹ã‚¯3: å®Ÿãƒ‡ãƒ¼ã‚¿å­¦ç¿’ãƒ»è©•ä¾¡ç’°å¢ƒæ§‹ç¯‰
å®Œå…¨å®Ÿé¨“ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

æ©Ÿèƒ½:
- çµ±ä¸€ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã«ã‚ˆã‚‹å‰å‡¦ç†
- Phase-1 + Phase-2å­¦ç¿’ï¼ˆKalmanå«ã‚€ï¼‰
- å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ»è»¢é€ä½œç”¨ç´ ã®ä¿å­˜
- å­¦ç¿’éç¨‹ã®å¯è¦–åŒ–ãƒ»ãƒ­ã‚°è¨˜éŒ²
- å®Ÿé¨“å†ç¾æ€§æ‹…ä¿

å®Ÿè¡Œä¾‹:
python scripts/run_full_experiment.py \
    --config configs/full_experiment_config.yaml \
    --data data/sim_complex.npz \
    --output results/full_experiment_001 \
    --use-kalman
"""

import argparse
import sys
import yaml
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional

import numpy as np
import torch
import matplotlib.pyplot as plt

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹è¨­å®š
SCRIPT_DIR = Path(__file__).parent
PROJECT_ROOT = SCRIPT_DIR.parent
sys.path.insert(0, str(PROJECT_ROOT))
sys.path.insert(0, str(PROJECT_ROOT / 'src'))

# çµ±ä¸€ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
from src.utils.data_loader import load_experimental_data_with_architecture, DataMetadata

# æ—¢å­˜ã®å­¦ç¿’ã‚¯ãƒ©ã‚¹
from src.training.two_stage_trainer import TwoStageTrainer
from src.utils.gpu_utils import select_device

# æ–°ã—ã„ç¢ºç‡å®Ÿç¾ã‚¯ãƒ©ã‚¹ã¨ãƒ¢ãƒ¼ãƒ‰åˆ†è§£æ©Ÿèƒ½
from src.ssm.realization import StochasticRealizationWithEncoder
from src.evaluation.mode_decomposition import TrainedModelSpectrumAnalysis, SpectrumResultsSaver


class FullExperimentPipeline:
    """
    å®Œå…¨å®Ÿé¨“ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œã‚¯ãƒ©ã‚¹
    
    ã‚¿ã‚¹ã‚¯3ã®è¦ä»¶ã‚’æº€ãŸã™å®Œå…¨ãªå­¦ç¿’ãƒ»è©•ä¾¡ç’°å¢ƒ
    """
    
    def __init__(self, config: Dict[str, Any], output_dir: Path, device: torch.device):
        self.config = config
        self.output_dir = output_dir
        self.device = device
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™
        self.output_dir.mkdir(parents=True, exist_ok=True)
        (self.output_dir / 'models').mkdir(exist_ok=True)
        (self.output_dir / 'plots').mkdir(exist_ok=True)
        (self.output_dir / 'logs').mkdir(exist_ok=True)
        (self.output_dir / 'artifacts').mkdir(exist_ok=True)
        
        # ãƒ­ã‚°è¨­å®š
        self.experiment_log = []
        self.start_time = datetime.now()
        
        self._log_experiment_start()
    
    def _log_experiment_start(self):
        """å®Ÿé¨“é–‹å§‹ãƒ­ã‚°"""
        log_entry = {
            'timestamp': self.start_time.isoformat(),
            'event': 'experiment_start',
            'config': self.config,
            'device': str(self.device),
            'output_dir': str(self.output_dir)
        }
        self.experiment_log.append(log_entry)
        print(f"ğŸš€ å®Ÿé¨“é–‹å§‹: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.output_dir}")
        print(f"ğŸ–¥ï¸  è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
    
    def step_1_data_loading(self, data_path: str) -> Dict[str, torch.Tensor]:
        """
        Step 3.1: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ»å‰å‡¦ç†

        Args:
            data_path: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Returns:
            å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿è¾æ›¸
        """
        print("\n" + "="*50)
        print("Step 3.1: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ»å‰å‡¦ç†")
        print("="*50)

        start_time = datetime.now()

        # Step 5: experiment_modeè‡ªå‹•åˆ¤å®š
        experiment_mode = self.config.get('experiment', {}).get('mode', 'reconstruction')
        print(f"ğŸ¯ å®Ÿé¨“ãƒ¢ãƒ¼ãƒ‰: {experiment_mode}")

        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿è¨­å®š
        data_config = self.config.get('data', {})

        # çµ±ä¸€ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã«ã‚ˆã‚‹èª­ã¿è¾¼ã¿ï¼ˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å¯¾å¿œï¼‰
        print(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­: {data_path}")
        datasets = load_experimental_data_with_architecture(
            data_path=data_path,
            config=self.config,  # å…¨ä½“è¨­å®šã‚’æ¸¡ã—ã¦ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ¤å®š
            split="all",
            return_dataloaders=False
        )

        # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚Tensorè¾æ›¸å½¢å¼ã«å¤‰æ›
        data_dict = {split: dataset.get_full_data() for split, dataset in datasets.items()}
        data_dict['metadata'] = datasets['train'].metadata

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã‚’data_dictã«è¿½åŠ ï¼ˆåŒ…æ‹¬çš„å¯¾å¿œï¼‰
        for split, dataset in datasets.items():
            if hasattr(dataset, 'target_data') and dataset.target_data is not None:
                # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒæ¤œå‡ºã—ãŸã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
                split_size = data_dict[split].shape[0]
                if split == 'train':
                    target_data = dataset.target_data
                elif split == 'test' and hasattr(dataset, 'target_test_data') and dataset.target_test_data is not None:
                    # target_test_dataã®ã‚µã‚¤ã‚ºç¢ºèªï¼ˆåˆ†å‰²ã‚µã‚¤ã‚ºã¨ä¸€è‡´ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼‰
                    if dataset.target_test_data.shape[0] == split_size:
                        target_data = dataset.target_test_data
                        print(f"ğŸ“‹ {split}åˆ†å‰²: ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®target_test_dataã‚’ä½¿ç”¨ï¼ˆæ­£ã—ã„ã‚µã‚¤ã‚ºï¼‰")
                    else:
                        # print(f"âš ï¸  {split}åˆ†å‰²: target_test_dataã‚µã‚¤ã‚º({dataset.target_test_data.shape[0]}) != æœŸå¾…ã‚µã‚¤ã‚º({split_size}), åˆ†å‰²ãƒ­ã‚¸ãƒƒã‚¯é©ç”¨")
                        # ã‚µã‚¤ã‚ºãŒä¸€è‡´ã—ãªã„å ´åˆã¯åˆ†å‰²ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨
                        if hasattr(dataset, 'target_data') and dataset.target_data is not None:
                            train_size = datasets['train'].data.shape[0]
                            val_size = datasets['val'].data.shape[0] if 'val' in datasets else 0
                            target_data = dataset.target_data[train_size + val_size:train_size + val_size + split_size]
                        else:
                            continue
                else:
                    # åˆ†å‰²ã«å¯¾å¿œã™ã‚‹ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åˆ†å‰²
                    if hasattr(dataset, 'target_data') and dataset.target_data is not None:
                        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆ†å‰²ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«åŸºã¥ã„ã¦ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²
                        train_size = datasets['train'].data.shape[0]
                        val_size = datasets['val'].data.shape[0] if 'val' in datasets else 0

                        if split == 'val':
                            target_data = dataset.target_data[train_size:train_size + val_size]
                        elif split == 'test':
                            # testãƒ‡ãƒ¼ã‚¿ã¯ train_size + val_size ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
                            target_data = dataset.target_data[train_size + val_size:train_size + val_size + split_size]
                        else:
                            target_data = dataset.target_data[:split_size]
                    else:
                        continue

                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã‚’Tensorã«å¤‰æ›ã—ã¦data_dictã«è¿½åŠ 
                if isinstance(target_data, np.ndarray):
                    target_data = torch.from_numpy(target_data).float()
                data_dict[f'{split}_targets'] = target_data
                print(f"âœ… {split}åˆ†å‰²ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿è¿½åŠ : shape={target_data.shape}")
            else:
                print(f"â„¹ï¸  {split}åˆ†å‰²: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ãªã—")

        # Step 5: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
        metadata: DataMetadata = data_dict['metadata']
        if experiment_mode == "target_prediction":
            if not hasattr(metadata, 'has_target_data') or not metadata.has_target_data:
                raise ValueError("Target prediction mode requires target data")
            print(f"âœ… ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿æ¤œå‡º: {getattr(metadata, 'target_shape', 'Unknown shape')}")

        # ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆè¡¨ç¤º
        print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ:")
        print(f"  - å…ƒãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {metadata.original_shape}")
        print(f"  - ç‰¹å¾´é‡æ•°: {len(metadata.feature_names)}")
        print(f"  - æ¬ æå€¤ç‡: {metadata.missing_ratio:.2%}")
        print(f"  - æ­£è¦åŒ–æ–¹æ³•: {metadata.normalization_method}")
        print(f"  - è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {data_dict['train'].shape}")
        print(f"  - æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {data_dict['val'].shape}")
        print(f"  - ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {data_dict['test'].shape}")
        if experiment_mode == "target_prediction" and hasattr(metadata, 'has_target_data') and metadata.has_target_data:
            print(f"  - ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿åˆ©ç”¨å¯èƒ½: {metadata.has_target_data}")
        
        # ãƒ‡ãƒ¼ã‚¿ã®æ¬¡å…ƒæ•°ã‚’å–å¾—ã—ã¦è¨­å®šã‚’å‹•çš„ã«æ›´æ–°
        data_dim = data_dict['train'].shape[1]  # (T, d) ã® d ã‚’å–å¾—
        if 'model' in self.config:
            # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®å…¥åŠ›æ¬¡å…ƒã‚’ãƒ‡ãƒ¼ã‚¿ã«åˆã‚ã›ã¦æ›´æ–°
            if 'encoder' in self.config['model']:
                original_input_dim = self.config['model']['encoder'].get('input_dim', data_dim)
                self.config['model']['encoder']['input_dim'] = data_dim
                if original_input_dim != data_dim:
                    print(f"ğŸ”§ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼å…¥åŠ›æ¬¡å…ƒã‚’è‡ªå‹•èª¿æ•´: {original_input_dim} â†’ {data_dim}")
            
            # ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã®å‡ºåŠ›æ¬¡å…ƒã‚’ãƒ‡ãƒ¼ã‚¿ã«åˆã‚ã›ã¦æ›´æ–°
            if 'decoder' in self.config['model']:
                original_output_dim = self.config['model']['decoder'].get('output_dim', data_dim)
                self.config['model']['decoder']['output_dim'] = data_dim
                if original_output_dim != data_dim:
                    print(f"ğŸ”§ ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼å‡ºåŠ›æ¬¡å…ƒã‚’è‡ªå‹•èª¿æ•´: {original_output_dim} â†’ {data_dim}")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•
        for key in ['train', 'val', 'test']:
            data_dict[key] = data_dict[key].to(self.device)

        # Step 5: experiment_modeã‚’data_dictã«ä¿å­˜
        data_dict['experiment_mode'] = experiment_mode

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        with open(self.output_dir / 'logs' / 'data_metadata.json', 'w') as f:
            # DataMetadataã¯__dict__ãŒãªã„ãŸã‚ã€asdict()ã‚’ä½¿ç”¨
            metadata_dict = {
                'original_shape': metadata.original_shape,
                'feature_names': metadata.feature_names,
                'time_index': metadata.time_index,
                'sampling_rate': metadata.sampling_rate,
                'missing_ratio': metadata.missing_ratio,
                'data_source': metadata.data_source,
                'normalization_method': metadata.normalization_method,
                'train_indices': metadata.train_indices,
                'val_indices': metadata.val_indices,
                'test_indices': metadata.test_indices
            }
            json.dump(metadata_dict, f, indent=2)
        
        # ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ï¼ˆè¡¨ç¤ºå´©ã‚Œã®ãŸã‚ä¸€æ™‚ç„¡åŠ¹åŒ–ï¼‰
        # self._plot_data_overview(data_dict)
        
        elapsed = (datetime.now() - start_time).total_seconds()
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†å®Œäº† ({elapsed:.1f}ç§’)")
        
        # ãƒ­ã‚°è¨˜éŒ²
        self.experiment_log.append({
            'timestamp': datetime.now().isoformat(),
            'event': 'data_loading_complete',
            'elapsed_seconds': elapsed,
            'data_shapes': {k: list(v.shape) for k, v in data_dict.items() if isinstance(v, torch.Tensor)},
            'metadata': metadata_dict
        })
        
        return data_dict
    
    def step_2_training_execution(self, data_dict: Dict[str, torch.Tensor]) -> Dict[str, Any]:
        """
        Step 3.2: å®Œå…¨å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ

        Args:
            data_dict: å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿

        Returns:
            å­¦ç¿’çµæœè¾æ›¸
        """
        print("\n" + "="*50)
        print("Step 3.2: Phase-1 + Phase-2å­¦ç¿’å®Ÿè¡Œ")
        print("="*50)

        start_time = datetime.now()

        # Step 5: experiment_modeå–å¾—
        experiment_mode = data_dict.get('experiment_mode', 'reconstruction')
        print(f"ğŸ¯ å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰: {experiment_mode}")

        # Step 5: ãƒ‡ã‚³ãƒ¼ãƒ€é¸æŠï¼ˆexperiment_modeå¯¾å¿œï¼‰
        if experiment_mode == "target_prediction":
            if 'target_decoder' in self.config.get('model', {}):
                print("ğŸ”§ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆäºˆæ¸¬ãƒ‡ã‚³ãƒ¼ãƒ€ã‚’ä½¿ç”¨")
            else:
                print("âš ï¸  target_decoderãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚é€šå¸¸ã®decoderã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")

        # å­¦ç¿’å™¨åˆæœŸåŒ–
        use_kalman = self.config.get('training', {}).get('use_kalman_filtering', False)
        print(f"ğŸ”§ Kalmanãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°: {'æœ‰åŠ¹' if use_kalman else 'ç„¡åŠ¹'}")

        # Step 5: TrainingConfigã«experiment_modeè¨­å®š
        if 'training' in self.config:
            self.config['training']['experiment_mode'] = experiment_mode

        # è¨­å®šè¾æ›¸ã‚’ä½¿ç”¨ã—ã¦TwoStageTrainerã‚’ç›´æ¥åˆæœŸåŒ–
        trainer = TwoStageTrainer(
            config=self.config,
            device=self.device,
            output_dir=str(self.output_dir),
            use_kalman_filtering=use_kalman
        )

        # çµ±åˆå­¦ç¿’ï¼ˆå„ã‚¨ãƒãƒƒã‚¯ã§Phase-1 + Phase-2ã‚’é€£ç¶šå®Ÿè¡Œï¼‰
        print("ğŸƒâ€â™‚ï¸ çµ±åˆå­¦ç¿’é–‹å§‹...")

        # Step 5: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã¨å­¦ç¿’å®Ÿè¡Œ
        if experiment_mode == "target_prediction":
            target_train = self._extract_targets_from_dict(data_dict, 'train')
            target_val = self._extract_targets_from_dict(data_dict, 'val') if data_dict.get('val') is not None else None

            integrated_results = trainer.train_integrated(
                Y_train=data_dict['train'],
                Y_val=data_dict['val'],
                target_train=target_train,
                target_val=target_val
            )
        else:
            integrated_results = trainer.train_integrated(
                Y_train=data_dict['train'],
                Y_val=data_dict['val']
            )

        total_elapsed = (datetime.now() - start_time).total_seconds()
        print(f"âœ… çµ±åˆå­¦ç¿’å®Œäº† ({total_elapsed:.1f}ç§’)")

        # å­¦ç¿’çµæœçµ±åˆï¼ˆçµ±åˆå­¦ç¿’å½¢å¼ï¼‰
        training_results = {
            'integrated': integrated_results,
            'phase1_metrics': integrated_results['phase1_metrics'],
            'phase2_losses': integrated_results['phase2_losses'],
            'integrated_metrics': integrated_results['integrated_metrics'],
            'total_time': total_elapsed,
            'use_kalman': use_kalman
        }
        
        # å­¦ç¿’éç¨‹å¯è¦–åŒ–
        self._plot_training_progress(training_results)
        
        # å­¦ç¿’çµæœä¿å­˜
        results_path = self.output_dir / 'logs' / 'training_results.json'
        with open(results_path, 'w') as f:
            # Tensorç­‰ã¯JSONéå¯¾å¿œã®ãŸã‚ã€ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¯èƒ½ãªå½¢å¼ã«å¤‰æ›
            serializable_results = self._make_json_serializable(training_results)
            json.dump(serializable_results, f, indent=2)
        
        # ãƒ­ã‚°è¨˜éŒ²
        self.experiment_log.append({
            'timestamp': datetime.now().isoformat(),
            'event': 'integrated_training_complete',
            'total_time': total_elapsed,
            'epochs': len(integrated_results.get('integrated_metrics', [])),
            'use_kalman': use_kalman
        })
        
        return {
            'trainer': trainer,
            'results': training_results
        }
    
    def step_3_model_analysis(self, trainer: TwoStageTrainer, data_dict: Dict[str, torch.Tensor]):
        """
        Step 3.3: å­¦ç¿’æ¸ˆã¿è»¢é€ä½œç”¨ç´ ã®è¡¨ç¾ç¢ºèª

        Args:
            trainer: å­¦ç¿’æ¸ˆã¿å­¦ç¿’å™¨
            data_dict: ãƒ‡ãƒ¼ã‚¿è¾æ›¸
        """
        print("\n" + "="*50)
        print("Step 3.3: è»¢é€ä½œç”¨ç´ ãƒ»è¡¨ç¾åˆ†æãƒ»ãƒ¢ãƒ¼ãƒ‰åˆ†è§£")
        print("="*50)

        start_time = datetime.now()

        # è»¢é€ä½œç”¨ç´ å–å¾—ãƒ»ä¿å­˜
        operators_info = self._analyze_transfer_operators(trainer)

        # å†…éƒ¨è¡¨ç¾åˆ†æ
        representations_info = self._analyze_internal_representations(trainer, data_dict)

        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ç‰¹å¾´ç©ºé–“å¯è¦–åŒ–ï¼ˆè¨­å®šå¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
        # æ—§å: state_space_viz â†’ æ–°å: encoded_feature_space_viz
        viz_config = self.config.get('evaluation', {}).get('encoded_feature_space_viz', {})
        dim_indices = tuple(viz_config.get('dim_indices', [0, 1]))
        max_samples = viz_config.get('max_samples', 100)
        self._visualize_encoded_feature_space(trainer, data_dict['test'], dim_indices, max_samples)

        # ãƒ¢ãƒ¼ãƒ‰åˆ†è§£åˆ†æï¼ˆæ–°æ©Ÿèƒ½ï¼‰
        mode_decomp_info = self._perform_mode_decomposition_analysis(trainer)

        # Step 6-8: å®Ÿé¨“ãƒ¢ãƒ¼ãƒ‰åˆ¥è©•ä¾¡ï¼ˆçµ±åˆï¼‰
        target_evaluation_info = {}
        reconstruction_evaluation_info = {}
        experiment_mode = data_dict.get('experiment_mode', 'reconstruction')

        if experiment_mode == "target_prediction":
            target_evaluation_info = self._perform_target_prediction_evaluation(trainer, data_dict)
        elif experiment_mode == "reconstruction":
            reconstruction_evaluation_info = self._perform_reconstruction_evaluation(trainer, data_dict)

        elapsed = (datetime.now() - start_time).total_seconds()
        print(f"âœ… è¡¨ç¾åˆ†æãƒ»ãƒ¢ãƒ¼ãƒ‰åˆ†è§£ãƒ»è©•ä¾¡å®Œäº† ({elapsed:.1f}ç§’)")

        # åˆ†æçµæœä¿å­˜
        analysis_results = {
            'operators': operators_info,
            'representations': representations_info,
            'mode_decomposition': mode_decomp_info,
            'target_evaluation': target_evaluation_info,  # Step 6
            'reconstruction_evaluation': reconstruction_evaluation_info,  # Step 8è¿½åŠ 
            'analysis_time': elapsed
        }

        with open(self.output_dir / 'logs' / 'model_analysis.json', 'w') as f:
            serializable_analysis = self._make_json_serializable(analysis_results)
            json.dump(serializable_analysis, f, indent=2)

        # ãƒ­ã‚°è¨˜éŒ²
        self.experiment_log.append({
            'timestamp': datetime.now().isoformat(),
            'event': 'model_analysis_complete',
            'elapsed_seconds': elapsed
        })
    
    def finalize_experiment(self, trainer: TwoStageTrainer):
        """å®Ÿé¨“çµ‚äº†å‡¦ç†"""
        print("\n" + "="*50)
        print("å®Ÿé¨“çµ‚äº†å‡¦ç†")
        print("="*50)
        
        # æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        model_path = self.output_dir / 'models' / 'final_model.pth'
        trainer._save_inference_ready_model(str(model_path))
        print(f"ğŸ’¾ æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {model_path}")
        
        # å®Ÿé¨“è¨­å®šä¿å­˜ï¼ˆYAML + TXTå½¢å¼ï¼‰
        config_path = self.output_dir / 'logs' / 'experiment_config.yaml'
        with open(config_path, 'w') as f:
            yaml.dump(self.config, f, default_flow_style=False)

        # TXTå½¢å¼ã§ã‚‚è¨­å®šæƒ…å ±ã‚’ä¿å­˜
        config_txt_path = self.output_dir / 'logs' / 'experiment_config.txt'
        with open(config_txt_path, 'w', encoding='utf-8') as f:
            f.write("=== DFIV Kalman Filterå®Ÿé¨“è¨­å®šæƒ…å ± ===\n")
            f.write(f"å®Ÿé¨“æ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.output_dir}\n\n")

            # è¨­å®šå†…å®¹ã‚’éšå±¤çš„ã«å‡ºåŠ›
            def write_config_section(config_dict, prefix=""):
                for key, value in config_dict.items():
                    if isinstance(value, dict):
                        f.write(f"{prefix}[{key}]\n")
                        write_config_section(value, prefix + "  ")
                    else:
                        f.write(f"{prefix}{key}: {value}\n")

            write_config_section(self.config)
        
        # å®Œå…¨å®Ÿé¨“ãƒ­ã‚°ä¿å­˜
        end_time = datetime.now()
        total_time = (end_time - self.start_time).total_seconds()
        
        self.experiment_log.append({
            'timestamp': end_time.isoformat(),
            'event': 'experiment_complete',
            'total_experiment_time': total_time
        })
        
        with open(self.output_dir / 'logs' / 'full_experiment_log.json', 'w') as f:
            json.dump(self.experiment_log, f, indent=2)
        
        print(f"â±ï¸  ç·å®Ÿé¨“æ™‚é–“: {total_time:.1f}ç§’ ({total_time/60:.1f}åˆ†)")
        print(f"ğŸ“Š å®Ÿé¨“å®Œäº†: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ“ å…¨çµæœä¿å­˜å…ˆ: {self.output_dir}")
    
    def _plot_data_overview(self, data_dict: Dict[str, torch.Tensor]):
        """ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ãƒ—ãƒ­ãƒƒãƒˆï¼ˆç”»åƒãƒ»æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿å¯¾å¿œï¼‰"""
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))
        fig.suptitle('Data Overview', fontsize=14)

        train_data = data_dict['train'].cpu().numpy()

        # ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ã«å¿œã˜ãŸå‡¦ç†
        if len(train_data.shape) == 4:  # ç”»åƒãƒ‡ãƒ¼ã‚¿ (T, H, W, C)
            T, H, W, C = train_data.shape

            # ç”»åƒã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤ºï¼ˆæœ€åˆã®æ•°ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰
            sample_images = train_data[:min(6, T)]  # æœ€åˆã®6ãƒ•ãƒ¬ãƒ¼ãƒ 
            for i, img in enumerate(sample_images):
                if i >= 6:
                    break
                row = i // 3
                col = i % 3
                if row < 2 and col < 2:
                    if C == 1:
                        axes[row, col].imshow(img.squeeze(-1), cmap='gray')
                    else:
                        axes[row, col].imshow(img)
                    axes[row, col].set_title(f'Frame {i}')
                    axes[row, col].axis('off')

            # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²æ¯”ç‡
            sizes = [data_dict['train'].shape[0], data_dict['val'].shape[0], data_dict['test'].shape[0]]
            if len(sizes) >= 3:
                axes[0, 1].pie(sizes, labels=['Train', 'Val', 'Test'], autopct='%1.1f%%')
                axes[0, 1].set_title('Data Split Ratio')

            # ãƒ”ã‚¯ã‚»ãƒ«å€¤åˆ†å¸ƒ
            axes[1, 0].hist(train_data.flatten(), bins=50, alpha=0.7)
            axes[1, 0].set_title('Pixel Value Distribution')
            axes[1, 0].set_xlabel('Pixel Value')
            axes[1, 0].set_ylabel('Frequency')
            axes[1, 0].grid(True)

            # ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ
            stats_text = f"""
            Data Type: Image Sequence
            Shape: {train_data.shape}
            Time steps: {T}
            Image size: {H}Ã—{W}Ã—{C}
            Mean: {train_data.mean():.3f}
            Std: {train_data.std():.3f}
            Min: {train_data.min():.3f}
            Max: {train_data.max():.3f}
            """

        else:  # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ (T, d)
            # æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆï¼ˆæœ€åˆã®3æ¬¡å…ƒï¼‰
            for i in range(min(3, train_data.shape[1])):
                axes[0, 0].plot(train_data[:, i], label=f'Feature {i+1}')
            axes[0, 0].set_title('Training Data Time Series')
            axes[0, 0].legend()
            axes[0, 0].grid(True)

            # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²æ¯”ç‡
            sizes = [data_dict['train'].shape[0], data_dict['val'].shape[0], data_dict['test'].shape[0]]
            axes[0, 1].pie(sizes, labels=['Train', 'Val', 'Test'], autopct='%1.1f%%')
            axes[0, 1].set_title('Data Split Ratio')

            # ç‰¹å¾´é‡åˆ†å¸ƒ
            axes[1, 0].hist(train_data.flatten(), bins=50, alpha=0.7)
            axes[1, 0].set_title('Feature Value Distribution')
            axes[1, 0].set_xlabel('Value')
            axes[1, 0].set_ylabel('Frequency')
            axes[1, 0].grid(True)

            # ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ
            stats_text = f"""
            Data Type: Time Series
            Shape: {train_data.shape}
            Mean: {train_data.mean():.3f}
            Std: {train_data.std():.3f}
            Min: {train_data.min():.3f}
            Max: {train_data.max():.3f}
            """

        axes[1, 1].text(0.1, 0.5, stats_text, transform=axes[1, 1].transAxes,
                        verticalalignment='center', fontsize=10)
        axes[1, 1].set_title('Data Statistics')
        axes[1, 1].axis('off')

        plt.tight_layout()
        plt.savefig(self.output_dir / 'plots' / 'data_overview.png', dpi=300)
        plt.close()
    
    def _plot_training_progress(self, results: Dict[str, Any]):
        """å­¦ç¿’éç¨‹å¯è¦–åŒ–ï¼ˆçµ±åˆå­¦ç¿’å¯¾å¿œã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆäºˆæ¸¬å¯¾å¿œï¼‰"""
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))
        fig.suptitle('Training Progress', fontsize=14)

        # Step 5: experiment_modeåˆ¤å®š
        experiment_mode = self.config.get('experiment', {}).get('mode', 'reconstruction')

        # Phase-2æå¤±æ¨ç§»ï¼ˆçµ±åˆå­¦ç¿’ï¼‰
        if 'phase2_losses' in results and len(results['phase2_losses']) > 0:
            phase2_data = results['phase2_losses']
            epochs = list(range(len(phase2_data)))

            if experiment_mode == "target_prediction":
                # Step 5: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆäºˆæ¸¬ãƒ¢ãƒ¼ãƒ‰ç”¨ã®å¯è¦–åŒ–
                total_losses = [entry.get('total_loss', 0) for entry in phase2_data]
                target_losses = [entry.get('loss_target', entry.get('target_loss', 0)) for entry in phase2_data]
                cca_losses = [entry.get('cca_loss', 0) for entry in phase2_data]

                axes[0, 0].plot(epochs, target_losses, label='Target Loss (MSE)', color='red', linewidth=2)
                axes[0, 0].plot(epochs, total_losses, label='Total Loss', color='blue')
                axes[0, 0].plot(epochs, cca_losses, label='CCA Loss', color='green')
                axes[0, 0].set_title('Target Prediction Loss')
                axes[0, 0].set_ylabel('MSE / Total Loss')
                axes[0, 0].set_xlabel('Epoch')
                axes[0, 0].legend()
                axes[0, 0].grid(True)

                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæå¤±ã®è©³ç´°
                axes[0, 1].plot(epochs, target_losses, 'r-', linewidth=2)
                axes[0, 1].set_title('Target Prediction MSE Loss')
                axes[0, 1].set_xlabel('Epoch')
                axes[0, 1].set_ylabel('MSE')
                axes[0, 1].grid(True)

            else:
                # æ—¢å­˜ã®å†æ§‹æˆãƒ¢ãƒ¼ãƒ‰ç”¨ã®å¯è¦–åŒ–
                total_losses = [entry['total_loss'] for entry in phase2_data]
                rec_losses = [entry.get('rec_loss', entry.get('loss_rec', 0)) for entry in phase2_data]
                cca_losses = [entry['cca_loss'] for entry in phase2_data]

                axes[0, 0].plot(epochs, total_losses, label='Total Loss')
                axes[0, 0].plot(epochs, rec_losses, label='Reconstruction Loss')
                axes[0, 0].plot(epochs, cca_losses, label='CCA Loss')
                axes[0, 0].set_title('Phase-2 Loss Components')
                axes[0, 0].set_xlabel('Epoch')
                axes[0, 0].set_ylabel('Loss')
                axes[0, 0].legend()
                axes[0, 0].grid(True)

                # CCAæå¤±ã®è©³ç´°ï¼ˆå‹•çš„å¤‰åŒ–ç¢ºèªç”¨ï¼‰
                axes[0, 1].plot(epochs, cca_losses, 'r-', linewidth=2)
                axes[0, 1].set_title('CCA Loss (Dynamic Check)')
                axes[0, 1].set_xlabel('Epoch')
                axes[0, 1].set_ylabel('CCA Loss')
                axes[0, 1].grid(True)
        else:
            # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã®è¡¨ç¤º
            loss_type = "Target Loss" if experiment_mode == "target_prediction" else "Phase-2 Loss"
            axes[0, 0].text(0.5, 0.5, f'No {loss_type} training data available',
                           ha='center', va='center', transform=axes[0, 0].transAxes)
            axes[0, 0].set_title(f'{loss_type} Components')

            detail_type = "Target MSE" if experiment_mode == "target_prediction" else "CCA"
            axes[0, 1].text(0.5, 0.5, f'No {detail_type} loss data available',
                           ha='center', va='center', transform=axes[0, 1].transAxes)
            axes[0, 1].set_title(f'{detail_type} Loss')
        
        # çµ±åˆå­¦ç¿’æ™‚é–“è¡¨ç¤º
        total_time = results.get('total_time', 0)
        axes[1, 0].bar(['Integrated Training'], [total_time])
        axes[1, 0].set_title('Training Time')
        axes[1, 0].set_ylabel('Time (seconds)')

        # å­¦ç¿’è¨­å®šæƒ…å ±ï¼ˆçµ±åˆå­¦ç¿’ç‰ˆã€experiment_modeå¯¾å¿œï¼‰
        phase2_count = len(results.get('phase2_losses', []))
        integrated_count = len(results.get('integrated_metrics', []))

        info_text = f"""
        Experiment Mode: {experiment_mode}
        Total Training Time: {total_time:.1f}s
        Kalman Filtering: {results.get('use_kalman', False)}
        Phase-2 Epochs: {phase2_count}
        Integrated Epochs: {integrated_count}
        Status: {'Completed' if phase2_count > 0 else 'Phase-1 Only'}
        """
        axes[1, 1].text(0.1, 0.5, info_text, transform=axes[1, 1].transAxes,
                        verticalalignment='center', fontsize=10)
        axes[1, 1].set_title('Training Info')
        axes[1, 1].axis('off')
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'plots' / 'training_progress.png', dpi=300)
        plt.close()
    
    def _analyze_transfer_operators(self, trainer: TwoStageTrainer) -> Dict[str, Any]:
        """è»¢é€ä½œç”¨ç´ åˆ†æ"""
        operators_info = {}
        
        # DF-Aè»¢é€ä½œç”¨ç´ ï¼ˆV_A, U_Aï¼‰
        if hasattr(trainer, 'df_state') and trainer.df_state is not None:
            try:
                state_dict = trainer.df_state.get_state_dict()
                if 'V_A' in state_dict:
                    V_A = state_dict['V_A']
                    operators_info['V_A_shape'] = list(V_A.shape)
                    operators_info['V_A_norm'] = float(torch.norm(V_A).item())
                if 'U_A' in state_dict:
                    U_A = state_dict['U_A']
                    operators_info['U_A_shape'] = list(U_A.shape)
                    operators_info['U_A_norm'] = float(torch.norm(U_A).item())
            except Exception as e:
                print(f"âš ï¸  DF-Aè»¢é€ä½œç”¨ç´ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        
        # DF-Bè»¢é€ä½œç”¨ç´ ï¼ˆV_B, u_Bï¼‰
        if hasattr(trainer, 'df_obs') and trainer.df_obs is not None:
            try:
                obs_dict = trainer.df_obs.get_state_dict()
                if 'V_B' in obs_dict:
                    V_B = obs_dict['V_B']
                    operators_info['V_B_shape'] = list(V_B.shape)
                    operators_info['V_B_norm'] = float(torch.norm(V_B).item())
                if 'u_B' in obs_dict:
                    u_B = obs_dict['u_B']
                    operators_info['u_B_shape'] = list(u_B.shape)
                    operators_info['u_B_norm'] = float(torch.norm(u_B).item())
            except Exception as e:
                print(f"âš ï¸  DF-Bè»¢é€ä½œç”¨ç´ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        
        # è»¢é€ä½œç”¨ç´ ä¿å­˜
        operators_path = self.output_dir / 'artifacts' / 'transfer_operators.pth'
        try:
            operators_data = {
                'df_state': trainer.df_state.get_state_dict() if hasattr(trainer, 'df_state') and trainer.df_state else None,
                'df_obs': trainer.df_obs.get_state_dict() if hasattr(trainer, 'df_obs') and trainer.df_obs else None
            }
            torch.save(operators_data, operators_path)
            print(f"ğŸ’¾ è»¢é€ä½œç”¨ç´ ä¿å­˜: {operators_path}")
        except Exception as e:
            print(f"âš ï¸  è»¢é€ä½œç”¨ç´ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        
        return operators_info
    
    def _analyze_internal_representations(self, trainer: TwoStageTrainer, data_dict: Dict[str, torch.Tensor]) -> Dict[str, Any]:
        """å†…éƒ¨è¡¨ç¾åˆ†æ"""
        representations_info = {}
        
        try:
            # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€è¡¨ç¾åˆ†æ
            if hasattr(trainer, 'encoder'):
                # ãƒ‡ãƒã‚¤ã‚¹æ•´åˆæ€§ç¢ºä¿
                trainer.encoder = trainer.encoder.to(trainer.device)

                test_sample = data_dict['test'][:100]  # æœ€åˆã®100ã‚µãƒ³ãƒ—ãƒ«
                test_sample = test_sample.to(trainer.device)  # ãƒ‡ãƒã‚¤ã‚¹çµ±ä¸€

                with torch.no_grad():
                    # unsqueeze/squeezeæ“ä½œã‚’å‰Šé™¤ï¼ˆTCNå»ƒæ­¢ã«ä¼´ã†ä¿®æ­£ï¼‰
                    encoded = trainer.encoder(test_sample)
                    representations_info['encoder_output_shape'] = list(encoded.shape)
                    representations_info['encoder_output_mean'] = float(encoded.mean().item())
                    representations_info['encoder_output_std'] = float(encoded.std().item())

        except Exception as e:
            import traceback
            print(f"âš ï¸  å†…éƒ¨è¡¨ç¾åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            print(f"ğŸ“‹ è©³ç´°ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
        
        return representations_info
    
    def _visualize_encoded_feature_space(self, trainer: TwoStageTrainer, test_data: torch.Tensor,
                                        dim_indices: tuple = (0, 1), max_samples: int = 100):
        """ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ç‰¹å¾´ç©ºé–“å¯è¦–åŒ–ï¼ˆæ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆã®ã¿ï¼‰

        Args:
            trainer: å­¦ç¿’æ¸ˆã¿ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼
            test_data: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
            dim_indices: è¡¨ç¤ºã™ã‚‹æ¬¡å…ƒã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: æœ€åˆã®2æ¬¡å…ƒ)
            max_samples: æœ€å¤§è¡¨ç¤ºã‚µãƒ³ãƒ—ãƒ«æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 100)

        è¨­å®šä¾‹:
            evaluation:
              encoded_feature_space_viz:
                dim_indices: [2, 5]  # 3ç•ªç›®ã¨6ç•ªç›®ã®æ¬¡å…ƒã‚’è¡¨ç¤º
                max_samples: 150     # æœ€å¤§150ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
        """
        try:
            # ãƒ‡ãƒã‚¤ã‚¹æ•´åˆæ€§ç¢ºä¿
            trainer.encoder = trainer.encoder.to(trainer.device)
            test_data = test_data.to(trainer.device)

            # ãƒ‡ãƒ¼ã‚¿æ•°èª¿æ•´: å…¥åŠ›ãŒæŒ‡å®šæ•°ä»¥ä¸‹ãªã‚‰å…¥åŠ›é•·ã€ãã†ã§ãªã‘ã‚Œã°æŒ‡å®šæ•°
            n_samples = min(len(test_data), max_samples)
            print(f"ğŸ“‹ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ç‰¹å¾´ç©ºé–“å¯è¦–åŒ–: {n_samples}ã‚µãƒ³ãƒ—ãƒ«ã€æ¬¡å…ƒ{dim_indices}")

            with torch.no_grad():
                if hasattr(trainer, 'encoder'):
                    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ
                    encoded = trainer.encoder(test_data[:n_samples])

                    # æŒ‡å®šæ¬¡å…ƒã®ç¢ºèª
                    if encoded.shape[1] <= max(dim_indices):
                        print(f"âš ï¸  è­¦å‘Š: æŒ‡å®šæ¬¡å…ƒ{dim_indices}ãŒç‰¹å¾´é‡æ¬¡å…ƒ{encoded.shape[1]}ã‚’è¶…ãˆã¦ã„ã¾ã™")
                        dim_indices = (0, min(1, encoded.shape[1]-1))
                        print(f"ğŸ“‹ æ¬¡å…ƒã‚’èª¿æ•´: {dim_indices}")

                    # æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆã®ã¿ï¼ˆç°¡ç•¥ç‰ˆï¼‰
                    plt.figure(figsize=(12, 6))

                    plt.plot(encoded[:, dim_indices[0]].cpu().numpy(),
                            label=f'Dim {dim_indices[0]}', linewidth=2)
                    plt.plot(encoded[:, dim_indices[1]].cpu().numpy(),
                            label=f'Dim {dim_indices[1]}', linewidth=2)

                    plt.title(f'Feature Trajectory (Dims {dim_indices[0]}, {dim_indices[1]})')
                    plt.xlabel('Time Step')
                    plt.ylabel('Feature Value')
                    plt.legend()
                    plt.grid(True, alpha=0.3)

                    # # æ•£å¸ƒå›³éƒ¨åˆ†ã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
                    # plt.subplot(1, 2, 2)
                    # plt.scatter(encoded[:, dim_indices[0]].cpu().numpy(),
                    #           encoded[:, dim_indices[1]].cpu().numpy(),
                    #           c=np.arange(len(encoded)), cmap='viridis', alpha=0.6)
                    # plt.colorbar(label='Time')
                    # plt.title('State Space Plot')
                    # plt.xlabel(f'Dim {dim_indices[0]}')
                    # plt.ylabel(f'Dim {dim_indices[1]}')
                    # plt.grid(True)

                    plt.tight_layout()
                    plt.savefig(self.output_dir / 'plots' / 'encoded_feature_space_visualization.png', dpi=300)
                    plt.close()

                    print("ğŸ“Š ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ç‰¹å¾´ç©ºé–“å¯è¦–åŒ–å®Œäº†")

        except Exception as e:
            import traceback
            print(f"âš ï¸  ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ç‰¹å¾´ç©ºé–“å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            print(f"ğŸ“‹ è©³ç´°ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")

    def _perform_mode_decomposition_analysis(self, trainer: TwoStageTrainer) -> Dict[str, Any]:
        """ãƒ¢ãƒ¼ãƒ‰åˆ†è§£åˆ†æå®Ÿè¡Œ"""
        mode_decomp_info = {}

        try:
            # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°é–“éš”å–å¾—ï¼ˆè¨­å®šã‹ã‚‰ã€ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼‰
            sampling_interval = self.config.get('evaluation', {}).get('spectrum_analysis', {}).get('sampling_interval', 0.1)

            print(f"ğŸ“Š ãƒ¢ãƒ¼ãƒ‰åˆ†è§£åˆ†æé–‹å§‹ (Î”t={sampling_interval})")

            # ãƒ¢ãƒ‡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ«åˆ†æå™¨ä½œæˆ
            model_spectrum_analyzer = TrainedModelSpectrumAnalysis(sampling_interval)

            # V_Aè¡Œåˆ—æŠ½å‡ºãƒ»ã‚¹ãƒšã‚¯ãƒˆãƒ«åˆ†æ
            if hasattr(trainer, 'df_state') and trainer.df_state is not None:
                try:
                    # DF-AçŠ¶æ…‹å±¤ã‹ã‚‰V_AæŠ½å‡ºï¼ˆè¤‡æ•°ã®æ–¹æ³•ã§è©¦è¡Œï¼‰
                    V_A = None

                    # æ–¹æ³•1: get_state_dict()ã‚’ä½¿ç”¨
                    state_dict = trainer.df_state.get_state_dict()
                    if 'V_A' in state_dict:
                        V_A = state_dict['V_A']
                        print(f"ğŸ“‹ V_Aè¡Œåˆ—ã‚’state_dictã‹ã‚‰å–å¾—: shape={V_A.shape}")

                    # æ–¹æ³•2: ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹
                    elif hasattr(trainer.df_state, 'V_A') and trainer.df_state.V_A is not None:
                        V_A = trainer.df_state.V_A
                        print(f"ğŸ“‹ V_Aè¡Œåˆ—ã‚’ç›´æ¥å–å¾—: shape={V_A.shape}")

                    # æ–¹æ³•3: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—
                    elif hasattr(trainer.df_state, '_stage1_cache') and 'V_A' in trainer.df_state._stage1_cache:
                        V_A = trainer.df_state._stage1_cache['V_A']
                        print(f"ğŸ“‹ V_Aè¡Œåˆ—ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—: shape={V_A.shape}")

                    if V_A is not None:

                        # ã‚¹ãƒšã‚¯ãƒˆãƒ«åˆ†æå®Ÿè¡Œ
                        spectrum_analysis = model_spectrum_analyzer.analyzer.analyze_spectrum(V_A)

                        # çµæœçµ±è¨ˆ
                        mode_decomp_info = {
                            'V_A_shape': list(V_A.shape),
                            'spectral_radius': spectrum_analysis['spectral_radius'],
                            'n_stable_modes': spectrum_analysis['n_stable_modes'],
                            'n_dominant_modes': spectrum_analysis['n_dominant_modes'],
                            'dominant_indices': spectrum_analysis['dominant_indices'],
                            'stable_indices': spectrum_analysis['stable_indices'],
                            'sampling_interval': sampling_interval
                        }

                        # å›ºæœ‰å€¤çµ±è¨ˆï¼ˆè¤‡ç´ æ•°ã¯åˆ†é›¢ã—ã¦ä¿å­˜ï¼‰
                        eigenvals_continuous = spectrum_analysis['eigenvalues_continuous']
                        mode_decomp_info['eigenvalues_statistics'] = {
                            'mean_growth_rate': float(eigenvals_continuous.real.mean().item()),
                            'std_growth_rate': float(eigenvals_continuous.real.std().item()),
                            'mean_frequency_hz': float(spectrum_analysis['frequencies_hz'].mean().item()),
                            'std_frequency_hz': float(spectrum_analysis['frequencies_hz'].std().item())
                        }

                        # ã‚¹ãƒšã‚¯ãƒˆãƒ«åˆ†æçµæœã®è©³ç´°ä¿å­˜
                        spectrum_save_path = self.output_dir / 'artifacts' / 'mode_decomposition'
                        SpectrumResultsSaver.save_results(
                            {'spectrum': spectrum_analysis, 'V_A': V_A, 'sampling_interval': sampling_interval},
                            str(spectrum_save_path),
                            save_format='both'
                        )

                        mode_decomp_info['detailed_results_saved'] = True
                        mode_decomp_info['save_path'] = str(spectrum_save_path)

                        print(f"âœ… ãƒ¢ãƒ¼ãƒ‰åˆ†è§£å®Œäº†:")
                        print(f"  - ã‚¹ãƒšã‚¯ãƒˆãƒ«åŠå¾„: {spectrum_analysis['spectral_radius']:.4f}")
                        print(f"  - å®‰å®šãƒ¢ãƒ¼ãƒ‰æ•°: {spectrum_analysis['n_stable_modes']}")
                        print(f"  - ä¸»è¦ãƒ¢ãƒ¼ãƒ‰æ•°: {spectrum_analysis['n_dominant_modes']}")
                        print(f"  - è©³ç´°çµæœä¿å­˜: {spectrum_save_path}")

                    else:
                        # è©³ç´°ãªãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’å‡ºåŠ›
                        print(f"âš ï¸  V_Aè¡Œåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        # print(f"ğŸ“‹ ãƒ‡ãƒãƒƒã‚°æƒ…å ±:")
                        # print(f"  - df_state._is_fitted: {getattr(trainer.df_state, '_is_fitted', 'N/A')}")
                        # print(f"  - hasattr(df_state, 'V_A'): {hasattr(trainer.df_state, 'V_A')}")
                        # if hasattr(trainer.df_state, 'V_A'):
                        #     print(f"  - df_state.V_A is None: {trainer.df_state.V_A is None}")
                        # print(f"  - state_dict keys: {list(state_dict.keys())}")
                        if hasattr(trainer.df_state, '_stage1_cache'):
                            print(f"  - _stage1_cache keys: {list(trainer.df_state._stage1_cache.keys()) if trainer.df_state._stage1_cache else 'None'}")
                        mode_decomp_info['error'] = 'V_A not found in df_state'
                        mode_decomp_info['debug_info'] = {
                            'is_fitted': getattr(trainer.df_state, '_is_fitted', False),
                            'has_V_A_attr': hasattr(trainer.df_state, 'V_A'),
                            'state_dict_keys': list(state_dict.keys())
                        }

                except Exception as e:
                    print(f"âš ï¸  ãƒ¢ãƒ¼ãƒ‰åˆ†è§£åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                    mode_decomp_info['error'] = str(e)
            else:
                print(f"âš ï¸  DF-AçŠ¶æ…‹å±¤ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                mode_decomp_info['error'] = 'df_state layer not found'

        except Exception as e:
            print(f"âš ï¸  ãƒ¢ãƒ¼ãƒ‰åˆ†è§£åˆ†æåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            mode_decomp_info['error'] = str(e)

        return mode_decomp_info

    def _extract_targets_from_dict(self, data_dict: Dict[str, torch.Tensor], split: str) -> torch.Tensor:
        """
        ãƒ‡ãƒ¼ã‚¿è¾æ›¸ã‹ã‚‰ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæƒ…å ±æŠ½å‡ºï¼ˆåŒ…æ‹¬çš„å¯¾å¿œï¼‰

        Args:
            data_dict: å…¨ãƒ‡ãƒ¼ã‚¿è¾æ›¸ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿å«ã‚€ï¼‰
            split: ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å ('train', 'val', 'test')

        Returns:
            æŠ½å‡ºã•ã‚ŒãŸã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿
        """
        try:
            # Step 1: ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ãŒè¿½åŠ ã—ãŸã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å„ªå…ˆä½¿ç”¨
            target_key = f'{split}_targets'
            if target_key in data_dict:
                target_data = data_dict[target_key]
                print(f"âœ… {split}åˆ†å‰²å°‚ç”¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ä½¿ç”¨: shape={target_data.shape}")
                return target_data

            # Step 2: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæŠ½å‡ºï¼ˆå¾“æ¥å®Ÿè£…ã®ä¿æŒï¼‰
            data = data_dict[split]
            metadata = data_dict.get('metadata')
            if hasattr(metadata, 'has_target_data') and metadata.has_target_data:
                if hasattr(metadata, 'target_indices'):
                    target_indices = metadata.target_indices
                    if isinstance(target_indices, (list, tuple, torch.Tensor)):
                        targets = data[:, target_indices] if len(data.shape) >= 2 else data[target_indices]
                        print(f"ğŸ“‹ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæŠ½å‡º: shape={targets.shape}")
                        return targets

            # Step 3: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ - å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå·±äºˆæ¸¬ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã—ã¦ä½¿ç”¨
            print(f"âš ï¸  å°‚ç”¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã—ã¦ä½¿ç”¨: shape={data.shape}")
            return data

        except Exception as e:
            # print(f"âš ï¸  ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            # print(f"ğŸ“‹ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã—ã¦ä½¿ç”¨")
            return data_dict[split]

    def _extract_targets(self, data: torch.Tensor, metadata: Optional[DataMetadata] = None) -> torch.Tensor:
        """
        ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæƒ…å ±æŠ½å‡ºï¼ˆæ—¢å­˜ãƒ¡ã‚½ãƒƒãƒ‰ä¿æŒãƒ»å¾Œæ–¹äº’æ›æ€§ï¼‰

        Args:
            data: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ³ã‚½ãƒ«
            metadata: ãƒ‡ãƒ¼ã‚¿ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿

        Returns:
            æŠ½å‡ºã•ã‚ŒãŸã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿
        """
        try:
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæŠ½å‡º
            if hasattr(metadata, 'has_target_data') and metadata.has_target_data:
                if hasattr(metadata, 'target_indices'):
                    target_indices = metadata.target_indices
                    if isinstance(target_indices, (list, tuple, torch.Tensor)):
                        targets = data[:, target_indices] if len(data.shape) >= 2 else data[target_indices]
                        print(f"ğŸ“‹ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿æŠ½å‡ºæˆåŠŸ: shape={targets.shape}")
                        return targets

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ‡ãƒ¼ã‚¿å…¨ä½“ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã—ã¦ä½¿ç”¨ï¼ˆè‡ªå·±äºˆæ¸¬ï¼‰
            # print(f"âš ï¸  å°‚ç”¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã—ã¦ä½¿ç”¨: shape={data.shape}")
            return data

        except Exception as e:
            # print(f"âš ï¸  ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            # print(f"ğŸ“‹ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã—ã¦ä½¿ç”¨")
            return data

    def _predict_targets(self, test_data: torch.Tensor, trainer: TwoStageTrainer) -> torch.Tensor:
        """
        ã‚¿ãƒ¼ã‚²ãƒƒãƒˆäºˆæ¸¬å®Ÿè¡Œï¼ˆStep 10: å®šå¼åŒ–æº–æ‹ ãƒ—ãƒ­ã‚»ã‚¹çµ±ä¸€ï¼‰

        æ—¢å­˜ã®_perform_reconstruction_with_existing_process()ã¨åŒä¸€ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã€
        æœ€å¾Œã®ãƒ‡ã‚³ãƒ¼ãƒ‰éƒ¨åˆ†ã®ã¿target_decoderã«å¤‰æ›´ã—ã¦çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«å®Œå…¨æ´»ç”¨

        Args:
            test_data: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ³ã‚½ãƒ«
            trainer: å­¦ç¿’æ¸ˆã¿å­¦ç¿’å™¨

        Returns:
            äºˆæ¸¬ã•ã‚ŒãŸã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿
        """
        trainer.encoder.eval()
        if hasattr(trainer, 'decoder'):
            trainer.decoder.eval()
        if hasattr(trainer, 'target_decoder') and trainer.target_decoder is not None:
            trainer.target_decoder.eval()

        with torch.no_grad():
            try:
                # æ—¢å­˜å†æ§‹æˆãƒ—ãƒ­ã‚»ã‚¹ã®å†ç¾ï¼ˆ_perform_reconstruction_with_existing_processã¨åŒã˜æ§‹é€ ï¼‰

                # æ™‚ç³»åˆ—é•·ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—
                T = test_data.shape[0]
                h = trainer.realization.h

                if T <= 2 * h:
                    # çŸ­æ™‚ç³»åˆ—ã®å ´åˆï¼šç°¡å˜ãªencoderâ†’target_decoder
                    M_features = trainer.encoder(test_data)
                    if M_features.dim() == 1:
                        M_features = M_features.unsqueeze(1)
                    if hasattr(trainer, 'target_decoder') and trainer.target_decoder is not None:
                        return trainer.target_decoder(M_features)
                    else:
                        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç°¡æ˜“ãƒ—ãƒ­ã‚»ã‚¹
                        encoded = trainer.encoder(test_data)
                        if hasattr(trainer, 'target_decoder') and trainer.target_decoder is not None:
                            return trainer.target_decoder(encoded)
                        elif hasattr(trainer, 'decoder') and trainer.decoder is not None:
                            return trainer.decoder(encoded)
                        else:
                            return encoded

                # Step 1: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ y_t â†’ m_tï¼ˆæ—¢å­˜ãƒ—ãƒ­ã‚»ã‚¹æº–æ‹ ï¼‰
                M_features = trainer.encoder(test_data)
                if M_features.dim() == 1:
                    M_features = M_features.unsqueeze(1)

                # Step 2: ç¢ºç‡çš„å®Ÿç¾ï¼ˆæ—¢å­˜ã®å®Ÿè£…ã‚’æ´»ç”¨ï¼‰
                try:
                    from src.ssm.realization import StochasticRealizationWithEncoder
                    if isinstance(trainer.realization, StochasticRealizationWithEncoder):
                        trainer.realization.fit(test_data, trainer.encoder)
                        X_states = trainer.realization.estimate_states(test_data)
                    else:
                        # ã‚¹ã‚«ãƒ©ãƒ¼åŒ–å‡¦ç†ï¼ˆæ—¢å­˜å®Ÿè£…æº–æ‹ ï¼‰
                        m_series_scalar = M_features.mean(dim=1)
                        X_states = trainer.realization.estimate_states(m_series_scalar.unsqueeze(1))
                except Exception:
                    # ç¢ºç‡å®Ÿç¾ã‚¨ãƒ©ãƒ¼æ™‚ã®ç°¡ç•¥åŒ–
                    X_states = M_features

                # Step 3: DF-Aäºˆæ¸¬ x_{t-1} â†’ xÌ‚_{t|t-1}ï¼ˆå­¦ç¿’æ™‚ãƒ•ãƒ­ãƒ¼å®Œå…¨æº–æ‹ ï¼‰
                print(f"ğŸ“Š [DF-A] å…¥åŠ›çŠ¶æ…‹: X_states.shape={X_states.shape}")
                X_hat_states = trainer.df_state.predict_sequence(X_states)
                T_pred = X_hat_states.size(0)
                print(f"ğŸ“Š [DF-A] äºˆæ¸¬çŠ¶æ…‹: X_hat_states.shape={X_hat_states.shape}, T_pred={T_pred}")

                # Step 4: DF-Bäºˆæ¸¬ xÌ‚_{t|t-1} â†’ mÌ‚_{t|t-1}ï¼ˆå­¦ç¿’æ™‚ãƒ•ãƒ­ãƒ¼å®Œå…¨æº–æ‹ ï¼‰
                M_hat_series = []
                for t in range(T_pred):
                    m_hat_t = trainer.df_obs.predict_one_step(X_hat_states[t])
                    M_hat_series.append(m_hat_t)
                M_hat_tensor = torch.stack(M_hat_series)  # (T_pred, 50æ¬¡å…ƒ)
                M_hat_tensor = trainer._ensure_device(M_hat_tensor)  # GPUæ•´åˆæ€§ç¢ºä¿

                # Step 5: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆäºˆæ¸¬ mÌ‚_{t|t-1} â†’ target_tï¼ˆå­¦ç¿’ã¨å®Œå…¨åŒä¸€å…¥åŠ›ï¼‰
                targets = trainer.target_decoder(M_hat_tensor)
                print(f"âœ… [DF-Flow] å®šå¼åŒ–æº–æ‹ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆäºˆæ¸¬å®Œäº†: {targets.shape}")
                return targets

            except Exception as e:
                print(f"âš ï¸  å®šå¼åŒ–æº–æ‹ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆäºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
                # TODO: ç‰¹ç•°å€¤åˆ†è§£ç­‰ã®æ•°å€¤ã‚¨ãƒ©ãƒ¼ç”¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè£…å¯èƒ½æ€§ã‚ã‚Š
                # ç¾åœ¨ã¯å®šå¼åŒ–æº–æ‹ ã®ãŸã‚ã€ã‚¨ãƒ©ãƒ¼ã‚’ä¸Šä½ã«ä¼æ¬
                raise RuntimeError(f"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆäºˆæ¸¬ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œå¤±æ•—ï¼ˆå®šå¼åŒ–æº–æ‹ å®Ÿè£…ï¼‰: {e}") from e

    def _perform_target_prediction_evaluation(
        self,
        trainer: TwoStageTrainer,
        data_dict: Dict[str, torch.Tensor]
    ) -> Dict[str, Any]:
        """
        ã‚¿ãƒ¼ã‚²ãƒƒãƒˆäºˆæ¸¬è©•ä¾¡å®Ÿè¡Œï¼ˆStep 6æ©Ÿèƒ½ï¼‰

        Args:
            trainer: å­¦ç¿’æ¸ˆã¿å­¦ç¿’å™¨
            data_dict: ãƒ‡ãƒ¼ã‚¿è¾æ›¸

        Returns:
            ã‚¿ãƒ¼ã‚²ãƒƒãƒˆäºˆæ¸¬è©•ä¾¡çµæœ
        """
        print("\n" + "-"*40)
        print("ğŸ¯ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆäºˆæ¸¬è©•ä¾¡é–‹å§‹")
        print("-"*40)

        evaluation_results = {}

        try:
            # æ—¢å­˜ã®è©•ä¾¡ã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            from src.evaluation.metrics import TargetPredictionMetrics

            # è©•ä¾¡è¨­å®šèª­ã¿è¾¼ã¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆRMSEï¼‰
            evaluation_config = self.config.get('evaluation', {}).get('target_metrics', {})
            selected_metrics = evaluation_config.get('metrics', ['rmse'])
            print(f"ğŸ“Š è©•ä¾¡æŒ‡æ¨™: {selected_metrics}")

            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆäºˆæ¸¬è©•ä¾¡å™¨ä½œæˆï¼ˆæ—¢å­˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨çµ±ä¸€ï¼‰
            target_evaluator = TargetPredictionMetrics(device=str(self.device))

            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬å®Ÿè¡Œ
            test_predictions = self._predict_targets(data_dict['test'], trainer)
            # data_dictã‹ã‚‰ç›´æ¥ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºï¼ˆä¿®æ­£ï¼‰
            test_targets = self._extract_targets_from_dict(data_dict, 'test')

            # å½¢çŠ¶ç¢ºèªãƒ»èª¿æ•´ï¼ˆåŒ…æ‹¬çš„å¯¾å¿œï¼‰
            print(f"ğŸ“Š [Step1] äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {test_predictions.shape}")
            print(f"ğŸ“Š [Step1] ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {test_targets.shape}")

            if test_predictions.shape != test_targets.shape:
                print(f"ğŸ“Š [Step2] å½¢çŠ¶èª¿æ•´é–‹å§‹: predictions {test_predictions.shape} vs targets {test_targets.shape}")

                # ç”»åƒãƒ‡ãƒ¼ã‚¿ â†’ ãƒ™ã‚¯ãƒˆãƒ«å¤‰æ›ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ™‚ã®å¯¾å¿œï¼‰
                if len(test_predictions.shape) > 2:
                    test_predictions = test_predictions.view(test_predictions.shape[0], -1)
                if len(test_targets.shape) > 2:
                    test_targets = test_targets.view(test_targets.shape[0], -1)

                # past_horizonå‡¦ç†çµ±ä¸€ï¼ˆå­¦ç¿’æ™‚ãƒ•ãƒ­ãƒ¼æº–æ‹ ï¼‰
                if test_predictions.shape[0] != test_targets.shape[0]:
                    pred_samples = test_predictions.shape[0]  # T_pred (111)
                    target_samples = test_targets.shape[0]    # T (151)

                    # å­¦ç¿’æ™‚å‡¦ç†æº–æ‹ : target_data[h+1:h+1+T_pred] ç›¸å½“ã®èª¿æ•´
                    # ä»®å®š: h=past_horizon=20, T_pred=111
                    # å­¦ç¿’æ™‚: target_data[21:21+111] = target_data[21:132]
                    # æ¨è«–æ™‚: test_targets[21:132] ã«åˆã‚ã›ã‚‹
                    if pred_samples < target_samples:
                        # past_horizon + 1 ã‹ã‚‰é–‹å§‹ã—ã¦ T_pred ã‚µãƒ³ãƒ—ãƒ«å–å¾—ï¼ˆå­¦ç¿’æ™‚ãƒ•ãƒ­ãƒ¼æº–æ‹ ï¼‰
                        h = self.config.get('ssm', {}).get('realization', {}).get('past_horizon', 20)  # configé§†å‹•past_horizonå–å¾—
                        start_idx = h + 1  # 21
                        end_idx = start_idx + pred_samples  # 21 + 111 = 132
                        if end_idx <= target_samples:
                            test_targets = test_targets[start_idx:end_idx]
                            print(f"ğŸ“Š [Step3] past_horizonèª¿æ•´å®Œäº†: target[{start_idx}:{end_idx}] â†’ {test_targets.shape}")
                        else:
                            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€å¾Œã‹ã‚‰ T_pred ã‚µãƒ³ãƒ—ãƒ«
                            test_targets = test_targets[-pred_samples:]
                            print(f"ğŸ“Š [Step3] ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯èª¿æ•´: æœ€å¾Œ{pred_samples}ã‚µãƒ³ãƒ—ãƒ« â†’ {test_targets.shape}")
                    else:
                        test_predictions = test_predictions[:target_samples]
                        print(f"ğŸ“Š [Step3] äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿çŸ­ç¸®: {target_samples}ã‚µãƒ³ãƒ—ãƒ«ã«èª¿æ•´")

            # æœ€çµ‚å½¢çŠ¶ç¢ºèª
            print(f"ğŸ“Š [Step4] æœ€çµ‚ç¢ºèª: predictions={test_predictions.shape}, targets={test_targets.shape}")
            if test_predictions.shape != test_targets.shape:
                print(f"âŒ [Step4] ã¾ã å½¢çŠ¶ä¸ä¸€è‡´ã‚ã‚Š - æ¬¡å…ƒèª¿æ•´å®Ÿè¡Œ")
                min_dim = min(test_predictions.shape[1], test_targets.shape[1])
                test_predictions = test_predictions[:, :min_dim]
                test_targets = test_targets[:, :min_dim]
                print(f"ğŸ“Š [Step4] æ¬¡å…ƒèª¿æ•´å®Œäº†: {test_predictions.shape}")
            else:
                print(f"âœ… [Step4] å½¢çŠ¶ä¸€è‡´ç¢ºèªOKï¼è©•ä¾¡å®Ÿè¡Œã—ã¾ã™")

            # è©•ä¾¡æŒ‡æ¨™è¨ˆç®—ãƒ»è¡¨ç¤ºï¼ˆæ—¢å­˜verboseãƒ‘ã‚¿ãƒ¼ãƒ³ã¨çµ±ä¸€ï¼‰
            target_metrics = target_evaluator.compute_target_metrics(
                test_targets, test_predictions, metrics=selected_metrics, verbose=True
            )

            # å¯è¦–åŒ–ç”Ÿæˆï¼ˆä¸€æ—¦ã‚¹ã‚­ãƒƒãƒ—ã€æ•°å€¤å‡ºåŠ›ãƒ»ä¿å­˜ã§ä»£æ›¿ï¼‰
            generated_files = target_evaluator.create_target_visualizations(
                test_targets, test_predictions,
                metrics=selected_metrics,
                output_dir=str(self.output_dir / 'plots')
            )

            # è©•ä¾¡çµæœã®JSONãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            experiment_info = {
                'experiment_mode': 'target_prediction',
                'test_data_shape': list(test_targets.shape),
                'predictions_shape': list(test_predictions.shape),
                'selected_metrics': selected_metrics,
                'model_architecture': 'RKN'
            }

            saved_metrics_file = target_evaluator.save_target_metrics_results(
                results=target_metrics,
                output_dir=str(self.output_dir / 'logs'),
                experiment_info=experiment_info
            )

            # çµæœæ ¼ç´
            evaluation_results = {
                'metrics': target_metrics,
                'selected_metrics': selected_metrics,
                'generated_visualizations': generated_files,
                'saved_metrics_file': saved_metrics_file,
                'test_data_shape': list(test_targets.shape),
                'predictions_shape': list(test_predictions.shape),
                'evaluation_success': True
            }

            print(f"âœ… ã‚¿ãƒ¼ã‚²ãƒƒãƒˆäºˆæ¸¬è©•ä¾¡å®Œäº†")

        except Exception as e:
            print(f"âš ï¸  ã‚¿ãƒ¼ã‚²ãƒƒãƒˆäºˆæ¸¬è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            print(f"ğŸ“‹ è©³ç´°ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")

            evaluation_results = {
                'error': str(e),
                'evaluation_success': False
            }

        return evaluation_results

    def _perform_reconstruction_evaluation(
        self,
        trainer: TwoStageTrainer,
        data_dict: Dict[str, torch.Tensor]
    ) -> Dict[str, Any]:
        """
        å†æ§‹æˆè©•ä¾¡å®Ÿè¡Œï¼ˆStep 8æ©Ÿèƒ½ã€TargetPredictionãƒ‘ã‚¿ãƒ¼ãƒ³ç¶™æ‰¿ï¼‰

        Args:
            trainer: å­¦ç¿’æ¸ˆã¿å­¦ç¿’å™¨
            data_dict: ãƒ‡ãƒ¼ã‚¿è¾æ›¸

        Returns:
            å†æ§‹æˆè©•ä¾¡çµæœ
        """
        print("\n" + "-"*40)
        print("ğŸ–¼ï¸  ãƒ‡ãƒ¼ã‚¿å†æ§‹æˆè©•ä¾¡é–‹å§‹")
        print("-"*40)

        evaluation_results = {}

        try:
            # Step 8ã§å®Ÿè£…ã—ãŸè©•ä¾¡ã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            from src.evaluation.metrics import ReconstructionMetrics

            # è©•ä¾¡è¨­å®šèª­ã¿è¾¼ã¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆreconstruction_rmseï¼‰
            evaluation_config = self.config.get('evaluation', {}).get('reconstruction_metrics', {})
            selected_metrics = evaluation_config.get('metrics', ['reconstruction_rmse'])
            print(f"ğŸ“Š è©•ä¾¡æŒ‡æ¨™: {selected_metrics}")

            # å†æ§‹æˆè©•ä¾¡å™¨ä½œæˆï¼ˆçµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼‰
            reconstruction_evaluator = ReconstructionMetrics(device=str(self.device))

            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®å†æ§‹æˆå®Ÿè¡Œ
            test_reconstructions = self._reconstruct_data(data_dict['test'], trainer)
            test_originals = data_dict['test']

            # å½¢çŠ¶ç¢ºèªãƒ»èª¿æ•´ï¼ˆTargetPredictionãƒ‘ã‚¿ãƒ¼ãƒ³ç¶™æ‰¿ï¼‰
            print(f"ğŸ“Š [Step1] å†æ§‹æˆãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {test_reconstructions.shape}")
            print(f"ğŸ“Š [Step1] å…ƒãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {test_originals.shape}")

            if test_reconstructions.shape != test_originals.shape:
                print(f"ğŸ“Š [Step2] å½¢çŠ¶èª¿æ•´é–‹å§‹: reconstructions {test_reconstructions.shape} vs originals {test_originals.shape}")

                # å½¢çŠ¶èª¿æ•´ï¼ˆä»»æ„ãƒ‡ãƒ¼ã‚¿å‹å¯¾å¿œï¼‰
                if len(test_reconstructions.shape) > 2:
                    test_reconstructions = test_reconstructions.view(test_reconstructions.shape[0], -1)
                if len(test_originals.shape) > 2:
                    test_originals = test_originals.view(test_originals.shape[0], -1)

                # past_horizonå½±éŸ¿ã«ã‚ˆã‚‹ã‚µã‚¤ã‚ºèª¿æ•´ï¼ˆå†æ§‹æˆç‰¹æœ‰ã®å‡¦ç†ï¼‰
                if test_reconstructions.shape[0] != test_originals.shape[0]:
                    rec_samples = test_reconstructions.shape[0]  # 130
                    orig_samples = test_originals.shape[0]       # 151

                    if rec_samples < orig_samples:
                        # past_horizonå½±éŸ¿ã§å†æ§‹æˆãƒ‡ãƒ¼ã‚¿ãŒçŸ­ã„å ´åˆã€å…ƒãƒ‡ãƒ¼ã‚¿ã‚‚åŒã˜ã‚µã‚¤ã‚ºã«èª¿æ•´
                        # æœ€åˆã®past_horizon+1ã‚µãƒ³ãƒ—ãƒ«ã‚’å‰Šé™¤ï¼ˆæ™‚ç³»åˆ—é–‹å§‹éƒ¨åˆ†ï¼‰
                        trim_start = orig_samples - rec_samples  # 151 - 111 = 40
                        test_originals = test_originals[trim_start:]
                        print(f"ğŸ“Š [Step3] past_horizonèª¿æ•´å®Œäº†: å…ƒãƒ‡ãƒ¼ã‚¿æœ€åˆ{trim_start}ã‚µãƒ³ãƒ—ãƒ«å‰Šé™¤ â†’ {test_originals.shape}")
                    else:
                        # å†æ§‹æˆãƒ‡ãƒ¼ã‚¿ãŒé•·ã„å ´åˆï¼ˆç¨€ãªã‚±ãƒ¼ã‚¹ï¼‰
                        test_reconstructions = test_reconstructions[:orig_samples]
                        print(f"ğŸ“Š [Step3] å†æ§‹æˆãƒ‡ãƒ¼ã‚¿çŸ­ç¸®: {orig_samples}ã‚µãƒ³ãƒ—ãƒ«ã«èª¿æ•´")

            # æœ€çµ‚å½¢çŠ¶ç¢ºèª
            print(f"ğŸ“Š [Step4] æœ€çµ‚ç¢ºèª: reconstructions={test_reconstructions.shape}, originals={test_originals.shape}")
            if test_reconstructions.shape != test_originals.shape:
                print(f"âŒ [Step4] ã¾ã å½¢çŠ¶ä¸ä¸€è‡´ã‚ã‚Š - æ¬¡å…ƒèª¿æ•´å®Ÿè¡Œ")
                min_dim = min(test_reconstructions.shape[1], test_originals.shape[1])
                test_reconstructions = test_reconstructions[:, :min_dim]
                test_originals = test_originals[:, :min_dim]
                print(f"ğŸ“Š [Step4] æ¬¡å…ƒèª¿æ•´å®Œäº†: {test_reconstructions.shape}")
            else:
                print(f"âœ… [Step4] å½¢çŠ¶ä¸€è‡´ç¢ºèªOKï¼è©•ä¾¡å®Ÿè¡Œã—ã¾ã™")

            # è©•ä¾¡æŒ‡æ¨™è¨ˆç®—ãƒ»è¡¨ç¤ºï¼ˆçµ±ä¸€verboseãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
            reconstruction_metrics = reconstruction_evaluator.compute_reconstruction_metrics(
                test_originals, test_reconstructions, metrics=selected_metrics, verbose=True
            )

            # å¯è¦–åŒ–ç”Ÿæˆï¼ˆæ®µéšçš„å®Ÿè£…ã€æ•°å€¤å‡ºåŠ›ãƒ»ä¿å­˜ã§ä»£æ›¿ï¼‰
            generated_files = reconstruction_evaluator.create_reconstruction_visualizations(
                test_originals, test_reconstructions,
                metrics=selected_metrics,
                output_dir=str(self.output_dir / 'plots')
            )

            # è©•ä¾¡çµæœã®JSONãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ï¼ˆTargetPredictionãƒ‘ã‚¿ãƒ¼ãƒ³ç¶™æ‰¿ï¼‰
            experiment_info = {
                'experiment_mode': 'reconstruction',
                'test_data_shape': list(test_originals.shape),
                'reconstructions_shape': list(test_reconstructions.shape),
                'selected_metrics': selected_metrics,
                'model_architecture': 'RKN'
            }

            # çµæœä¿å­˜ï¼ˆæ—¢å­˜ãƒ‘ã‚¿ãƒ¼ãƒ³ç¶™æ‰¿ï¼‰
            saved_metrics_file = reconstruction_evaluator.save_reconstruction_metrics_results(
                results=reconstruction_metrics,
                output_dir=str(self.output_dir / 'logs'),
                experiment_info=experiment_info
            )

            # çµæœæ ¼ç´ï¼ˆçµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰
            evaluation_results = {
                'metrics': reconstruction_metrics,
                'selected_metrics': selected_metrics,
                'generated_visualizations': generated_files,
                'saved_metrics_file': saved_metrics_file,
                'test_data_shape': list(test_originals.shape),
                'reconstructions_shape': list(test_reconstructions.shape),
                'evaluation_success': True
            }

            print(f"âœ… ãƒ‡ãƒ¼ã‚¿å†æ§‹æˆè©•ä¾¡å®Œäº†")

        except Exception as e:
            print(f"âš ï¸  ãƒ‡ãƒ¼ã‚¿å†æ§‹æˆè©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            print(f"ğŸ“‹ è©³ç´°ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")

            evaluation_results = {
                'error': str(e),
                'evaluation_success': False
            }

        return evaluation_results

    def _reconstruct_data(self, test_data: torch.Tensor, trainer: TwoStageTrainer) -> torch.Tensor:
        """
        ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å†æ§‹æˆå®Ÿè¡Œï¼ˆæ—¢å­˜TwoStageTrainerå†æ§‹æˆãƒ—ãƒ­ã‚»ã‚¹æ´»ç”¨ï¼‰

        Args:
            test_data: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
            trainer: å­¦ç¿’æ¸ˆã¿å­¦ç¿’å™¨

        Returns:
            å†æ§‹æˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
        """
        try:
            with torch.no_grad():
                # æ—¢å­˜ã®å†æ§‹æˆãƒ—ãƒ­ã‚»ã‚¹ã‚’æ´»ç”¨
                trainer.encoder.eval()
                trainer.decoder.eval()

                # æ—¢å­˜ã®_forward_and_loss_phase2_reconstruction()ãƒ—ãƒ­ã‚»ã‚¹ã‚’éƒ¨åˆ†å®Ÿè¡Œ
                reconstructed_data = self._perform_reconstruction_with_existing_process(test_data, trainer)

                return reconstructed_data

        except Exception as e:
            print(f"âš ï¸  æ—¢å­˜å†æ§‹æˆãƒ—ãƒ­ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯1: æ—¢å­˜ãƒ¡ã‚½ãƒƒãƒ‰ã§ã®å®Œå…¨å†æ§‹æˆè©¦è¡Œ
            try:
                with torch.no_grad():
                    trainer.encoder.eval()
                    trainer.decoder.eval()
                    loss_total, loss_rec, loss_cca = trainer._forward_and_loss_phase2_reconstruction(test_data)

                    # æ—¢å­˜ãƒ—ãƒ­ã‚»ã‚¹ã‹ã‚‰å†æ§‹æˆãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºï¼ˆéƒ¨åˆ†çš„ã«å†å®Ÿè¡Œï¼‰
                    M_features = trainer.encoder(test_data)
                    if M_features.dim() == 1:
                        M_features = M_features.unsqueeze(1)

                    # ç°¡ç•¥åŒ–: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰â†’ãƒ‡ã‚³ãƒ¼ãƒ‰ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ™‚ï¼‰
                    reconstructed_data = trainer.decoder(M_features)
                    print("âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å†æ§‹æˆæˆåŠŸ")
                    return reconstructed_data

            except Exception as e2:
                print(f"âš ï¸  ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å†æ§‹æˆã‚¨ãƒ©ãƒ¼: {e2}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯2: å…ƒãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
                return test_data

    def _perform_reconstruction_with_existing_process(self, test_data: torch.Tensor, trainer: TwoStageTrainer) -> torch.Tensor:
        """
        å®šå¼åŒ–æº–æ‹ å†æ§‹æˆãƒ•ãƒ­ãƒ¼å®Ÿè¡Œï¼ˆStep 11ä¿®æ­£ï¼‰
        å­¦ç¿’æ™‚ãƒ•ãƒ­ãƒ¼ï¼ˆsrc/training/two_stage_trainer.py:1532-1545ï¼‰ã¨å®Œå…¨åŒä¸€
        """
        # æ™‚ç³»åˆ—é•·ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—
        T = test_data.shape[0]
        h = trainer.realization.h

        if T <= 2 * h:
            # TODO: çŸ­æ™‚ç³»åˆ—ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè£…å¯èƒ½æ€§ã‚ã‚Š
            raise RuntimeError(f"æ™‚ç³»åˆ—é•·({T})ãŒçŸ­ã™ãã¾ã™: T <= 2*h({2*h})ã€‚å®šå¼åŒ–æº–æ‹ ã®ãŸã‚ã‚¨ãƒ©ãƒ¼ã€‚")

        # Step 1: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ y_t â†’ m_tï¼ˆå­¦ç¿’æ™‚ãƒ•ãƒ­ãƒ¼æº–æ‹ ï¼‰
        M_features = trainer.encoder(test_data)
        if M_features.dim() == 1:
            M_features = M_features.unsqueeze(1)

        # Step 2: ç¢ºç‡çš„å®Ÿç¾ m_t â†’ x_tï¼ˆå­¦ç¿’æ™‚ãƒ•ãƒ­ãƒ¼æº–æ‹ ï¼‰
        from src.ssm.realization import StochasticRealizationWithEncoder
        if isinstance(trainer.realization, StochasticRealizationWithEncoder):
            trainer.realization.fit(test_data, trainer.encoder)
            X_states = trainer.realization.estimate_states(test_data)
        else:
            # ã‚¹ã‚«ãƒ©ãƒ¼åŒ–å‡¦ç†ï¼ˆæ—¢å­˜å®Ÿè£…æº–æ‹ ï¼‰
            m_series_scalar = M_features.mean(dim=1)
            trainer.realization.fit(m_series_scalar.unsqueeze(1))
            X_states = trainer.realization.filter(m_series_scalar.unsqueeze(1))

        # Step 3: DF-Aäºˆæ¸¬ x_{t-1} â†’ xÌ‚_{t|t-1}ï¼ˆå­¦ç¿’æ™‚ãƒ•ãƒ­ãƒ¼å®Œå…¨æº–æ‹ ï¼‰
        X_hat_states = trainer.df_state.predict_sequence(X_states)
        T_pred = X_hat_states.size(0)

        # Step 4: DF-Bäºˆæ¸¬ xÌ‚_{t|t-1} â†’ mÌ‚_{t|t-1}ï¼ˆå­¦ç¿’æ™‚ãƒ•ãƒ­ãƒ¼å®Œå…¨æº–æ‹ ï¼‰
        M_hat_series = []
        for t in range(T_pred):
            m_hat_t = trainer.df_obs.predict_one_step(X_hat_states[t])
            M_hat_series.append(m_hat_t)
        M_hat_tensor = torch.stack(M_hat_series)  # (T_pred, 50æ¬¡å…ƒ)
        M_hat_tensor = trainer._ensure_device(M_hat_tensor)  # GPUæ•´åˆæ€§ç¢ºä¿

        # Step 5: å†æ§‹æˆ mÌ‚_{t|t-1} â†’ Å·_{t|t-1}ï¼ˆå­¦ç¿’ã¨å®Œå…¨åŒä¸€å…¥åŠ›ï¼‰
        Y_hat = trainer.decoder(M_hat_tensor)
        print(f"âœ… [DF-Flow] å®šå¼åŒ–æº–æ‹ å†æ§‹æˆå®Œäº†: {Y_hat.shape}")
        return Y_hat

    def _make_json_serializable(self, obj):
        """JSONå¯¾å¿œå½¢å¼ã«å¤‰æ›"""
        if isinstance(obj, dict):
            return {k: self._make_json_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._make_json_serializable(v) for v in obj]
        elif isinstance(obj, torch.Tensor):
            return obj.cpu().numpy().tolist()
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.integer):
            return int(obj)
        else:
            return obj


def parse_args():
    """å¼•æ•°è§£æ"""
    parser = argparse.ArgumentParser(description="ã‚¿ã‚¹ã‚¯3: å®Œå…¨å®Ÿé¨“ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ")
    
    parser.add_argument(
        '--config', '-c', type=str, required=True,
        help='å®Ÿé¨“è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« (.yaml)'
    )
    parser.add_argument(
        '--data', '-d', type=str, required=True,
        help='ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹'
    )
    parser.add_argument(
        '--output', '-o', type=str, required=True,
        help='çµæœå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª'
    )
    parser.add_argument(
        '--device', type=str, default=None,
        help='è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹ (autoé¸æŠæ™‚ã¯None)'
    )
    parser.add_argument(
        '--use-kalman', action='store_true',
        help='Kalmanãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æœ‰åŠ¹åŒ–'
    )
    parser.add_argument(
        '--skip-analysis', action='store_true',
        help='Step 3.3 è¡¨ç¾åˆ†æã‚’ã‚¹ã‚­ãƒƒãƒ—'
    )
    
    return parser.parse_args()


def load_experiment_config(config_path: str) -> Dict[str, Any]:
    """å®Ÿé¨“è¨­å®šèª­ã¿è¾¼ã¿"""
    if not Path(config_path).exists():
        raise FileNotFoundError(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}")
    
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯
    required_sections = ['model', 'training']
    for section in required_sections:
        if section not in config:
            raise ValueError(f"è¨­å®šã« {section} ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒå¿…è¦ã§ã™")
    
    return config


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    args = parse_args()
    
    print("ğŸš€ ã‚¿ã‚¹ã‚¯3: å®Œå…¨å®Ÿé¨“ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹")
    print("="*60)
    
    # è¨­å®šèª­ã¿è¾¼ã¿
    config = load_experiment_config(args.config)
    
    # Kalmanãƒ•ãƒ©ã‚°è¨­å®š
    if args.use_kalman:
        config.setdefault('training', {})['use_kalman_filtering'] = True
    
    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
    device = torch.device(args.device) if args.device else select_device()
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    output_dir = Path(args.output)
    
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
    pipeline = FullExperimentPipeline(config, output_dir, device)
    
    try:
        # Step 3.1: ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
        data_dict = pipeline.step_1_data_loading(args.data)
        
        # Step 3.2: å®Œå…¨å­¦ç¿’å®Ÿè¡Œ
        training_result = pipeline.step_2_training_execution(data_dict)
        
        # Step 3.3: è¡¨ç¾åˆ†æï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if not args.skip_analysis:
            pipeline.step_3_model_analysis(training_result['trainer'], data_dict)
        
        # å®Ÿé¨“å®Œäº†å‡¦ç†
        pipeline.finalize_experiment(training_result['trainer'])
        
        print("\nğŸ‰ å®Œå…¨å®Ÿé¨“ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ­£å¸¸çµ‚äº†ï¼")
        print(f"ğŸ“ çµæœ: {output_dir}")
        
    except Exception as e:
        print(f"\nâŒ å®Ÿé¨“ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())